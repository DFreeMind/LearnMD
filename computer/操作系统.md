# 操作系统

## 简介

操作系统的主要任务是记录哪个程序在使用什么资源，对资源请求进行分配，评估使用代价，并且为不同的程序和用户调解互相冲突的资源请求。
资源管理包括用以下两种不同方式实现多路复用(共享)资源: 在时间上复用和在空间上复用。当一种资源在时间上复用时，不同的程序或用户轮流使用它。先是第一个获得资源的使用，然后下一个，以此类推。例如，若在系统中只有一个CPU，而多个程序需要在该CPU上运行，操作系统则首先把该CPU分配给某个程序，在它运行了足够长的时间之后，另一个程序得到CPU，然后是下一个，如此进行下去，最终，轮到第-一个程序再次运行。至于资源是如何实现时间复用的一谁应该是下一个以及运行多长时间等一-则 是操作系统的任务。还有一个有关时间复用的例子是打印机的共享。当多个打印作业在一台打印机上排队等待打印时，必须决定将轮到打印的是哪个作业。

另一类复用是空间复用。每个客户都得到资源的部分，从而取代了客户排队。例如，通常在若干运行程序之间分割内存，这样每一个运行程序都可同时人驻内存(例如，为了轮流使用CPU)。假设有足够的内存可以存放多个程序，那么在内存中同时存放若千个程序的效率，比把所有内存都分给一个程序的效率要高得多，特别是，如果一个程序只需要整个内存的一小部分，结果更是这样。当然，如此的做法会引起公平、保护等问题，这有赖于操作系统解决它们。有关空间复用的其他资源还有磁盘。在许多系统中，一个磁盘同时为许多用户保存文件。分配磁盘空间并记录谁正在使用哪个磁盘块，是操作系统的典型任务。

**多道程序设计**

若当前作业因等待磁带或其他I/O操作而暂停， CPU就只能简单地踏步直至该I/O完成。对于CPU操作密集的科学计算问题，I/O操作较少，因此浪费的时间很少。然而，对于商业数据处理，I/O操作等待的时间通常占到80%~90%，所以必须采取某种措施减少(昂贵的)CPU空闲时间的浪费。
解决方案是将内存分几个部分，每一部分存放不同的作业，如图1-5所示

![image](https://wx2.sinaimg.cn/large/69d4185bly1g2swpz9qzoj207507i3zf.jpg)

当一个作业等待I/O操作完成时，另一个作业可以使用CPU。如果内存中可以同时存放足够多的作业，则CPU利用率可以接近100%。在内存中同时驻留多个作业需要特殊的硬件来对其进行保护，以避免作业的信息被窃取或受到攻击。

## 硬件

一台机计算机的组成

![image](https://ws2.sinaimg.cn/large/69d4185bly1g2sxa1hah3j20hx09r0wh.jpg)

### 处理器

计算机的“大脑”是CPU，它从内存中取出指令并执行之。在每个CPU基本周期中，首先从内存中取出指令，解码以确定其类型和操作数，接着执行之，然后取指、解码并执行下一条指令。按照这一方式，程序被执行完成。

每个CPU都有一套可执行的专门指令集。所以，x86处理器不能执行ARM程序，而ARM处理器也不能执行x86程序。由于用来访问内存以得到指令或数据的时间要比执行指令花费的时间长得多，因此，所有的CPU内都有一些用来保存关键变量和临时数据的寄存器。这样，通常在指令集中提供一些指令，用以将一个字从内存调入寄存器，以及将-一个字从寄存器存人内存。其他的指令可以把来自寄存器、内存的操作数组合，或者用两者产生一个结果，如将两个字相加并把结果存在寄存器或内存中。

除了用来保存变量和临时结果的通用寄存器之外，多数计算机还有一些对程序员可见的专用寄存器。其中之一是**程序计数器**，它保存了将要取出的下一条指令的内存地址。在指令取出之后，程序计数器就被更新以便指向后继的指令。
另一个寄存器是**堆栈指针**，它指向内存中当前栈的顶端。该栈包含了每个执行过程的栈帧。一个过程的栈帧中保存了有关的输入参数、局部变量以及那些没有保存在寄存器中的临时变量。

当然还有**程序状态字**(Program Status Word， PSW)寄存器。这个寄存器包含了条件码位( 由比较指令设置)、CPU优先级、模式(用户态或内核态)，以及各种其他控制位。用户程序通常读入整个PSW，但是，只对其中的少量字段写人。在系统调用和I/O中，PSW的作用很重要。
操作系统必须知晓所有的寄存器。在时间多路复用(time multiplexing) CPU中，操作系统经常会中止正在运行的某个程序并启动(或再启动)另一个程序。每次停止一个运行着的程序时，操作系统必须保存所有的寄存器值，这样在稍后该程序被再次运行时，可以把这些寄存器重新装入。

------

为了改善性能，CPU设计师早就放弃了同时读取、解码和执行- 条指令的简单模型。许多现代CPU具有同时取出多条指令的机制。例如，一个CPU可以有单独的取指单元、解码单元和执行单元，于是当它执行指令n时，还可以对指令n+ 1解码，并且读取指令n + 2。这样的机制称为流水线(pipeline)， 图1-7a是一个有着三个阶段的流水线示意图。更长的流水线也是常见的。在多数的流水线设计中，一旦一条指令被取进流水线中，它就必须被执行完毕，即便前一条取出的指令是条件转移，它也必须被执行完毕。流水线使得编译器和操作系统的编写者很头疼，因为它造成了在机器中实现这些软件的复杂性问题，而机器必须处理这些问题。

![image](https://wx1.sinaimg.cn/large/69d4185bly1g2t4tmmr9zj20jl07bq5w.jpg)

比流水线更先进的设计是超标量CPU，如图1-7b所示。在这种设计中，有多个执行单元，例如，一个CPU用于整数算术运算，一个CPU用于浮点算术运算，一个CPU用于布尔运算。两个或更多的指令被同时取出、解码并装人暂存缓冲区中，直至它们执行完毕。只要有一个执行单元空闲，就检查保持缓冲区中是否还有可处理的指令，如果有，就把指令从缓冲区中移出并执行之。这种设计存在一种隐含的作用，即程序的指令经常不按顺序执行。在多数情况下，硬件负责保证这种运算的结果与顺序执行指令时的结果相同，但是，仍然有部分令人烦恼的复杂情形被强加给操作系统处理，我们在后面会讨论这种情况。

### 多线程和多核芯片

多线程允许CPU保持两个不同的线程状态，然后在纳秒级的时间尺度内来回切换。(线程是一种轻量级进程，即
一个运行中的程序)例如，如果某个进程需要从内存中读出一个字(需要花费多个时钟周期)，多线程CPU则可以切换至另一个线程。多线程不提供真正的并行处理。在一个时刻只有一个进程在运行，但是线程的切换时间则减少到纳秒数量级。

多线程对操作系统而言是有意义的，因为每个线程在操作系统看来就像是单个的CPU。考虑一个实际有两个CPU的系统，每个CPU有两个线程。这样操作系统将把它看成是4个CPU。如果在某个特定时间点上，只有能够维持两个CPU忙碌的工作量，那么在同一个CPU上调度两个线程，而让另一个CPU完全空转，就没有优势了。这种选择远远不如在每个CPU上运行一个线程的效率高。

![image](https://ws3.sinaimg.cn/large/69d4185bly1g2t51igzq4j20bu09b41l.jpg)

除了多线程，还出现了包含2个或4个完整处理器或内核的CPU芯片。图1-8中的多核芯片上有效地装有4个小芯片，每个小芯片都是一个独立的CPU(后面将解释缓存)。Intel Xeon Phi和Tilera TilePro等处理器，已经炫技般地在一枚芯片上集成了60多个核。要使用这类多核芯片肯定需要多处理器操作系统。
其实在绝对数目方面，没什么能赢过现代的GPU (Graphics Processing Unit)。 GPU指的是由成千上万个微核组成的处理器。它们擅长处理大量并行的简单计算，比如在图像应用中渲染多边形。它们不太能胜任串行任务，并且很难编程。虽然GPU对操作系统很有用(比如加密或者处理网络传输)，但操作系统本身不太可能运行在GPU上。

### 存储器

![image](https://ws3.sinaimg.cn/large/69d4185bly1g2t57s0t8tj20ek057402.jpg)

**寄存器**

存储器系统的顶层是CPU中的寄存器。它们用与CPU相同的材料制成，所以和CPU-样快。显然，访问它们是没有时延的。其典型的存储容量是，在32位CPU中为32x32位，而在64位CPU中为64 x 64位。在这两种情形下，其存储容量都小于1 KB。程序必须在软件中自行管理这些寄存器( 即决定如何使用它们)。

**高速缓存**

下一层是高速缓存，它多数由硬件控制。主存被分割成**高速缓存行**(cache line)，其典型大小为64字节，地址0至63对应高速缓存行0，地址64至127对应高速缓存行1，以此类推。最常用的高速缓存行放置在CPU内部或者非常接近CPU的高速缓存中。当某个程序需要读一个存储字时，高速缓存硬件检查所需要的高速缓存行是否在高速缓存中。如果是，称为**高速缓存命中**，缓存满足了请求，就不需要通过总线把访问请求送往主存。高速缓存命中通常需要两个时钟周期。高速缓存未命中就必须访问内存，这要付出大量的时间代价。由于高速缓存的价格昂贵，所以其大小有限。有些机器具有两级甚至三级高速缓存，每一级高速缓存比前一-级慢且容量更大。

在任何缓存系统中，都有若千需要尽快考虑的问题，包括:
1) 何时把一个新的内容放入缓存。
2 )把新内容放在缓存的哪行上。
3) 在需要时，应该把哪个内容从缓存中移走。
4) 应该把新移走的内容放在某个较大存储器的何处。
并不是每个问题的解决方案都符合每种缓存处理。对于CPU缓存中的主存缓存行，每当有缓存未命中时，就会调入新的内容。通常通过所引用内存地址的高位计算应该使用的缓存行。例如，对于64字节的4096个缓存行以及32位地址，其中6~17位用来定位缓存行，而0~ 5位则用来确定缓存行中的字节。在这个例子中，被移走内容的位置就是新数据要进入的位置，但是在有的系统中未必是这样。最后，当将一个缓存行的内容重写进主存时(该内容被缓存后，可能会被修改)，通过该地址来唯一确定需 重写的主存位置。

缓存是一种好方法，所以现代CPU中设计了两个缓存。第一级或称为**L1缓存**总是在CPU中，通常用来将已解码的指令调入CPU的执行引擎。对于那些频繁使用的数据字，多数芯片安排有第二个L1缓存。典型的L1缓存大小为16KB。另外，往往还设计有二级缓存，称为**L2缓存**，用来存放近来使用过的若千兆字节的内存字。L1和L2缓存之间的差别在于时序。对L1缓存的访问，不存在任何延时：而对L2缓存的访问，则会延时1或2个时钟周期。

**主存**

在图1-9的层次结构中，再往下一层是主存。这是存储器系统的主力。主存通常称为**随机访问存储器**(Random Access Memory， RAM)。过去有时称之为**磁芯存储器**，因为在20世纪50年代和60年代，使用很小的可磁化的铁磁体制作主存。虽然它们已经绝迹了很多年，但名称还是传承了下来。目前，存储器的容量在几百兆字节到若干吉字节之间，并且其容量正在迅速增长。所有不能在高速缓存中得到满足的访问请求都会转往主存。
除了主存之外，许多计算机已经在使用少量的非易失性随机访问存储器。它们与RAM不同，在电源切断之后，非易失性随机访问存储器并不丢失其内容。**只读存储器**(Read Only Memory， ROM)在工厂中就被编程完毕，然后再也不能被修改。ROM速度快且便宜。在有些计算机中，用于启动计算机的引导加载模块就存放在ROM中。另外，一些I/O卡也采用ROM处理底层设备控制。
**EEPROM** ( Electrically Erasable PROM，电可擦除可编程ROM)和闪存(flash memory)也是非易失性的，但是与ROM相反，它们可以擦除和重写。不过重写它们需要比写入RAM更高数量级的时间，所以它们的使用方式与ROM相同，而其与众不同的特点使它们有可能通过字段重写的方式纠正所保存程序中的错误。

**磁盘**

![image](https://ws1.sinaimg.cn/large/69d4185bly1g2t5o6l7muj20bm08iace.jpg)

下一个层次是磁盘! (硬盘)。磁盘同RAM相比，每个二进制位的成本低了两个数量级，而且经常也有两个数量级大的容量。磁盘唯一的问题是随机访问数据时间大约慢了三个数量级。其低速的原因是因为磁盘是一种机械装置，如图1-10所示。

![image](https://wx2.sinaimg.cn/large/69d4185bly1g2t5u5aycyj20et0bh0vc.jpg)

在一个磁盘中有一个或多个金属盘片，它们以5400rpm、7200rpm、 10 800rpm或更高的速度旋转。从边缘开始有一个机械臂悬横在盘面上，这类似于老式播放塑料唱片33转唱机上的拾音臂。信息写在磁盘的一系列同心上。在任意一个给定臂的位置，每个磁头可以读取一段环形区域，称为**磁道**(track)。 把一个给定臂的位置上的所有磁道合并起来，组成了一个**柱面**(cylinder)。

每个磁道划分为若千扇区，扇区的典型值是512字节。在现代磁盘中，较外部的柱面比较内部的柱 面有更多的扇区。机械臂从一个柱面移到相邻的柱面大约需要lms。而随机移到一个柱面的典型时间为 5ms至10ms，其具体时间取决于驱动器。一且磁臂到达正确的磁道上，驱动器必须等待所需的扇区旋转 到磁头之下，这就增加了5ms至10ms的时延，其具体延时取决于驱动器的转速。一日所需要的扇区移到 磁头之下，就开始读写，低端硬盘的速率是50MB/s，而高速磁盘的速率是160 MB/s。

许多计算机支持-种著名的**虚拟内存**机制，这将在第3章中讨论。这种机制使得期望运行大于物理 内存的程序成为可能，其方法是将程序放在磁盘上，而将主存作为一种缓存，用来保存最频繁使用的部! 分程序。这种机制需要快速地映像内存地址，以便把程字生成的地址转换为有关字节在RAM中的物理 地址。这种映像由CPU中的一个称为**存储器管理单元**(Memory Management Unit， MMU)的部件来完 成，如图1-6所示。 

缓存和MMU的出现对系统的性能有着重要的影响。在多道程序系统中，从一个程序切换到另一个 程序，有时称为**上下文切换**(context switch)，有必要对来自缓存的所有修改过的块进行写回磁盘操作， 并修改MMU中的映像寄存器。但是这两种操作的代价很昂贵，所以程序员努力避免使用这些操作。我们稍后将看到这些操作产生的影响。

### 总线

![image](https://wx4.sinaimg.cn/large/69d4185bly1g2u3irraomj20hj0ce43o.jpg)

图中的系统有很多总线( 例如高速缓存、内存、PCle、 PCI、USB、SATA和DMI)，每条总线的传 输速度和功能都不同。操作系统必须了解所有总线的配置和管理。其中主要的总线是PCle ( Peripheral Component Interconnect Express)总线。

Intel发明的PCIe总线是陈旧的PCI总线的继承者，而PCI总线则是为了取代原来的ISA (IndustryStandard Architecture) 总线。数十Gb/s的传输能力使得PCIe比它的前身快得多。它们在本质上也十分不同。直到发明PCIe总线的2004年，大多数总线都是并行且共享的。**共享总线架构**(shared bus architecture)表示多个设备使用一些相同的导线传输数据。因此，当多个设备同时需要发送数据时，需要仲裁器决定哪个设备可以使用总线。PCIe恰好相反，它使用分离的端到端的链路。传统PCI使用的**并行总线架构**( parallel bus architecture) 表示通过多条导线发送数据的每个字。例如，在传统的PCI总线上，一个32位数据通过32条并行的导线发送。与之相反，PCIe使用**串行总线架构**(serial busarchitecture)，通过一条被称为数据通路的链路传递集合了所有位的一条消息，这非常像网络包。这样做简单了很多，因为不用再确保所有32位在同一时刻精确地到达目的地。通过将多个数据通路并行起来，并行性仍可有效利用。例如，可以使用32个数据通路并行传输32条消息。随着网卡和图形适配器这些外围设备速度的迅速增长，PCle标准每3~5年进行一次更新。例如，PCle 2.0规格的16个数据通路提供64Gb/s的速度，升级到PCIe 3.0后会提速2倍，而PCIe 4.0会再提速2倍。

在图中，CPU通过DDR3总线与内存对话，通过PCIe总线与外围图形设备对话，通过**DMI** (Direct Media Interface)总线经集成中心与所有其他设备对话。而集成中心通过通用串行总线与USB设备对话，通过SATA总线与硬盘和DVD驱动器对话，通过PCIe传输以太网络帧。我们已经提到过使用传统PCI总线的旧的PCI设备。



## 操作系统概念

### 进程

在所有操作系统中，一个重要的概念是**进程(process)**。 进程本质上是正在执行的一个程序。与每 个进程相关的是**地址空间(**address space)，这是从某个最小值的存储位置(通常是零)到某个最大值的 存储位置的列表。在这个地址空间中，进程可以进行读写。该地址空间中存放有可执行程序、程序的数 据以及程序的堆栈。与每个进程相关的还有资源集，通常包括寄存器(含有程序计数器和堆栈指针)、 打开文件的清单、突出的报警、有关进程清单，以及运行该程序所需要的所有其他信息。进程基本上是 容纳运行一个程序所需要所有信息的容器。

进程的概念将在第2章详细讨论，不过，对进程建立一种直观感觉的最便利方式是分析一一个多道程序设计系统。用户启动一个视频编辑程序，指示它按照某个格式转换小时的视频(有时会花费数小时)，然后离开去浏览网页。同时，一个被周期性唤醒、用来检查进来的电子邮件的后台进程会开始运行。这样，我们就有了(至少)三个活动进程:视频编辑器、Web浏览器以及电子邮件接收程序。操作系统周期性地挂起一个进程然后启动运行另一个进程，这可能是由于在过去的一两秒钟内，第一个进程已使用完分配给它的时间片。

一个进程暂时被挂起后，在随后的某个时刻里，该进程再次启动时的状态必须与先前暂停时完全相同，这就意味着在挂起时该进程的所有信息都要保存下来。例如，为了同时读入信息，进程打开了若干文件。与每个被打开文件有关的是指向当前位置的指针(即下一个将读出的字节或记录)。在一个进程暂时被挂起时，所有这些指针都必须保存起来，这样在该进程重新启动之后，所执行的读调用才能读到正确的数据。在许多操作系统中，与一个进程有关的所有信息，除了该进程自身地址空间的内容以外，均存放在操作系统的一张表中，称为**进程表**(process table)， 进程表是数组(或链表)结构，当前存在的每个进程都要占用其中一项。

与进程管理有关的最关键的系统调用是那些进行进程创建和进程终止的系统调用。考虑一个典型的例子。有一个称为**命令解释器**(command interpreter) 或 **shell** 的进程从终端上读命令。此时，用户刚键入一条命令要求编译一个程序。shell必须先创建一个新进程来执行编译程序。当执行编译的进程结束时，它执行一一个系统调用来终止自己。

![image](https://ws3.sinaimg.cn/large/69d4185bly1g2u5xed2v9j20a106q0u7.jpg)

若一个进程能够创建一个或多个进程(称为**子进程**)，而且这些进程又可以创建子进程，则很容易得到进程树，如图1-13所示。合作完成某些作业的相关进程经常需要彼此通信以便同步它们的行为。这种通信称为**进程间通信**(interprocess communication)，将在第2章中详细讨论。其他可用的进程系统调用包括:申请更多的内存(或释放不再需要的内存)、等待一个子进程结束、用另一个程序覆盖该程序等。



### 地址空间

每台计算机都有一些主存，用来保存正在执行的程序。在非常简单的操作系统中，内存中一次只能有一个程序。如果要运行第二个程序，第一个程序就必须被移出内存，再把第二个程序装入内存。

较复杂的操作系统允许在内存中同时运行多道程序。为了避免它们互相干扰(包括操作系统)，需要有某种保护机制。虽然这种机制必然是硬件形式的，但是由操作系统掌控。
上述的观点涉及对计算机主存的管理和保护。另种不同但是同样重要并与存储器有关的内容，是管理进程的地址空间。<u>通常，每个进程有一些可以使用的地址集合，典型值从0开始直到某个最大值。在最简单的情形下，一个进程可拥有的最大地址空间小于主存。在这种方式下，进程可以用满其地址空间，而且内存中也有足够的空间容纳该进程</u>。
但是，在许多32位或64位地址的计算机中，分别有 $2^{32}$ 或 $2^{64}$ 字节的地址空间。如果一个进程有比计算机拥有的主存还大的地址空间，而且该进程希望使用全部的内存，那怎么办呢?在早期的计算机中，这个进程只好“认命”了。<u>现在，有了一种称为虚拟内存的技术，正如前面已经介绍过的，操作系统可以把部分地址空间装人主存，部分留在磁盘上，并且在需要时来回交换它们。在本质上，操作系统创建了一个地址空间的抽象，作为进程可以引用地址的集合。该地址空间与机器的物理内存解耦，可能大于也可能小于该物理空间</u>。对地址空间和物理空间的管理组成了操作系统功能的一一个重要部分，整个第3章都与这个主题有关。



### 文件

实际上，支持操作系统的另一个关键概念是文件系统。如前所述，操作系统的一项主要功能是隐藏磁盘和其他I/O设备的细节特性，给提供程序员一个良好、清晰的独立于设备的抽象文件模型。显然，创建文件、删除文件、读文件和写文件等都需要系统调用。在文件可以读取之前，必须先在磁盘上定位和打开文件，在文件读过之后应该关闭该文件，有关的系统调用则用于完成这类操作。

为了提供保存文件的地方，大多数操作系统支持**目录**(directory)的概念，从而可把文件分类成组。比如，学生可给所选的每个课程创建一个目录(用于保存该课程所需的程序)，另设一个目录存放电子邮件，再有一个目录用于保存万维网主页。这就需要系统调用创建和删除目录、将已有的文件放入目录中、从目录中删除文件等。目录项可以是文件或者目录，这样就产生了层次结构一文件 系统，如图1-14所示。

![image](https://wx1.sinaimg.cn/large/69d4185bly1g2vg53bxdlj20jr0efdlz.jpg)

进程和文件层次都可以组织成树状结构，但这两种树状结构有不少不同之处。一般进程的树状结构层次不深(很少超过三层)，而文件树状结构的层次常常多达四层、五层或更多层。进程树层次结构是暂时的，通常最多存在几分钟，而目录层次则可能存在数年之久。进程和文件在所有权及保护方面也是有区别的。典型地，只有父进程能控制和访问子进程，而在文件和目录中通常存在一种机制，使文件所有者之外的其他用户也可以访问该文件。

UNIX中的另一个重要概念是安装文件系统。大多数台式机都有一个或多个光盘驱动器，可以插入CD-ROM、DVD和蓝光光盘。它们几乎都有USB接口，可以插入USB存储棒(实际是固态磁盘驱动器)。为了提供一个出色的方式处理可移动介质，UNIX允许把光盘上的文件系统接到主文件树上。考虑图1-15a的情形。在mount调用之前，根文件系统在硬盘上，而第二个文件系统在CD-ROM上，它们是分离且无关的。

![image](https://ws2.sinaimg.cn/large/69d4185bly1g2vgbrmcy4j20lp072dj9.jpg)

然而，不能使用CD-ROM上的文件系统，因为上面没有可指定的路径。UNIX不允许在路径前面加上驱动器名称或代码，那样做就完全成了设备相关类型了，这是操作系统应该消除的。代替的方法是，mount系统调用允许把在CD-ROM上的文件系统连接到程序所希望的根文件系统上。在图1-15b中，CD-ROM上的文件系统安装到了目录b上，这样就允许访问文件/b/x以及/b/y。如果CD-ROM已安装好，但目录b中有任何不能访问的文件，则是因为/b指向了CD-ROM的根目录。(在开始时，不能访问这些文件似乎并不是一个严重问题:文件系统几乎总是安装在空目录上。)如果系统有多个硬盘，它们可以都安装在单个树上。

在UNIX中，另一个重要的概念是**特殊文件**(special file)。 提供特殊文件是为了使I/O设备看起来像文件一般。这样，就像使用系统调用读写文件一样，I/O设备也可通过同样的系统调用进行读写。有两类特殊文件:**块特殊文件**(block special file)和**字符特殊文件**(character special file)。块特殊文件指那些由可随机存取的块组成的设备，如磁盘等。比如打开一个块特殊文件，然后读第4块，程序可以直接访问设备的第4块而不必考虑存放该文件的文件系统结构。类似地，字符特殊文件用于打印机、调制解调器和其他接收或输出字符流的设备。按照惯例，特殊文件保存在/dev目录中。例如，/dev/p是打印机(曾经称为行式打印机)。

![image](https://ws3.sinaimg.cn/large/69d4185bly1g2vgjqoxgkj207y03qjrz.jpg)

本小节中 讨论的最后一个特性既与进程有关也与文件有关:管道。管道(pipe) 是一种虚文件，它可连接两个进程，如图1-16所示。如果进程A和B希望通过管道对话，它们必须提前设置该管道。当进程A想对进程B发送数据时，它把数据写到管道上，仿佛管道就是输出文件一样。进程B可以通过读该管道而得到数据，仿佛该管道就是一一个输入文件一样。这样，在UNIX中两个进程之间的通信就非常类似于普通文件的读写了。更为强大的是，若进程想发现它所写入的输出文件不是真正的文件而是管道，则需要使用特殊的系统调用。

## 系统调用

记住下列事项是有益的。任何单CPU计算机-次只能执行.条指令。如果一个进程正在用户态运行一一个用户程序，并且需要一个系统服务，比如从一个文件读数据，那么它就必须执行.个陷阱或系统调用指令，将控制转移到操作系统。操作系统接着通过参数检查找出所需要的调用进程。然后，它执行系统调用，并把控制返回给在系统调用后面跟随着的指令。在某种意义上，进行系统调用就像进行一个特殊的过程调用，但是只有系统调用可以进人内核，而过程调用则不能。
为了使系统调用机制更清晰，我们简要地考察read系统调用。如上所述，它有三个参数:第一个参数指定文件，第二个指向缓冲区，第三个说明要读出的字节数。几乎与所有的系统调用样， 它的调用由C程序完成，方法是调用一个与该系统调用名称相同的库过程: read。 由C程序进行的调用形式如下:

```c
count = read(fd， buffer， nbytes)；
```

系统调用(以及库过程)在count中返回实际读出的字节数。这个值通常和nbytes相同，但也可能更小，例如，如果在读过程中遇到了文件尾的情形就是如此。

如果系统调用不能执行，不论是因为无效的参数还是磁盘错误，count都会被置为-1，而在全局变量errno中放入错误号。程序应该经常检查系统调用的结果，以了解是否出错。
系统调用是通过一系列的步骤实现的。为了更清楚地说明这个概念，考察上面的read调用。在准备调用这个实际用来进行read系统调用的read库过程时，调用程序首先把参数压进堆栈，如图1-17中步骤1~步骤3所示。

![image](https://ws4.sinaimg.cn/large/69d4185bly1g2vh7zi3n7j20hk0gbq9k.jpg)

### 用于进程管理的系统调用

![image](https://wx1.sinaimg.cn/large/69d4185bly1g2waa06zlcj208e07ydhb.jpg)

发在UNIX中的进程将其存储空间划分为三段:**正文段**(如程序代码)、**数据段**(如变量)以及**堆栈段**。数据向上增长而堆栈向下增长，如图1-20所示。夹在中间的是未使用的地址空间。堆栈在需要时自动地向中间增长，不过数据段的扩展是显式地通过系统调用brk进行的，在数据段扩充后，该系统调用指定-一个新地址。但是，这个调用不是POSIX标准中定义的，对于存储器的动态分配，鼓励程序员使用malloc库过程，而malloc的内部实现则不是一个适合标准化的主题，因为几乎没有程序员直接使用它，我们有理由怀疑是否会有人注意到brk实际不是属于POSIX的。



# 进程与线程

进程是操作系统提供的最古老的也是最重要的抽象概念之-。即使可以使用的CPU只有一个，但它们也具有支持(伪)并发操作的能力，它们将一个单独的CPU变换成多个虚拟的CPU。没有进程的抽象，现代计算将不复存在。

## 进程

所有现代的计算机经常会在同一时间做许多件事。习惯于在个人计算机上工作的人们也许不会十分注意这个事实，因此列举-.些例子可以更清楚地说明这一问题。先考虑:一个网络服务器，一些网页请求从各处进入。当一个请求进入时，服务器检查其需要的网页是否在缓存中。如果是，则把网页发送回去；如果不是，则启动一个磁盘请求以获取网页。然而，从CPU的角度来看，磁盘请求需要漫长的时间。当等待磁盘请求完成时，其他更多的请求将会进入。如果有多个磁盘存在，可以在满足第一个请求之前就接二连三地对其他的磁盘发出部分或全部请求。很明显，需要一些方法去模拟并控制这种并发。进程(特别是线程)在这里就可以发挥作用。

在任何多道程序设计系统中，CPU由一个进程快速切换至另-个进程，使每个进程各运行几十或几百毫秒。严格地说，在某一个瞬间，CPU只能运行一个进程。但在1秒钟内，它可能运行多个进程，这样就产生并行的错觉。有时人们所说的**伪并行**就是指这种情形，以此来区分**多处理器系统**(该系统有两个或多个CPU共享同一个物理内存)的真正硬件并行。人们很难对多个并行活动进行跟踪，因此，经过多年的努力，操作系统的设计者开发了用于描述并行的一种概念模型(顺序进程)，使得并行更容易处理。



### 进程模型

在进程模型中， 计算机上所有可运行的软件，通常也包括操作 系统，被组织成若干**顺序进程**(sequential process)，简称**进程**(process)。 一个进程就是-个正在执行程序的实例，包括程序计数器、寄存器和变量的当前值。从概念上说，每个进程拥有它自己的虚拟CPU。当然，实际上真正的CPU在各进程之间来回切换。但为了理解这种系统，考虑在(伪)并行情况下运行的进程集，要比试图跟踪CPU如何在程序间来回切换简单得多。正如在第1章所看到的，这种快速的切换称作**多道程序设计**。

![image-20190510224911328](/Users/weduoo/Library/Application Support/typora-user-images/image-20190510224911328.png)

在图2-1a中可以看到，在一台多道程序计算机的内存中有4道程序。在图2-1b中，这4道程序被抽象为4个各自拥有自已控制流程(即每个程序自己的逻辑程序计数器)的进程，并且每个程序都独立地运行。当然，实际上只有一个物理程序计数器，所以在每个程序运行时，它的逻辑程序计数器被装人实际的程序计数器中。当该程序执行结束(或暂停执行)时，物理程序计数器被保存在内存中该进程的逻辑程序计数器中。在图2-1c中可以看到，在观察足够长的一段时间后，所有的进程都运行了，但在任何一个给定的瞬间仅有一个进程真正在运行。

由于CPU在各进程之间来回快速切换，所以每个进程执行其运算的速度是不确定的。而且当同一进程再次运行时，其运算速度通常也不可再现。所以，在对进程编程时决不能对时序做任何想当然的假设。例如，考虑一个I/O进程，它用流式磁带机恢复备份的文件，它执行一个10000次的空循环以等待磁带机达到正常速度，然后发出命令读取第一个记录。如果CPU决定在空循环期间切换到其他进程，则磁带机进程可能在第一条记录通过磁头之后还未被再次运行。当一个进程具有此类严格的实时要求时，也就是一些特定事件一定要在所指定的若于毫秒内发生，那么必须采取特殊措施以保证它们一定在这段时间中发生。然而，通常大多数进程并不受CPU多道程字设计或其他进程相对速度的影响。

------

进程和程序间的区别是很微妙的，但非常重要。用一个比喻可以更容易理解这一点。想象一位有一手好厨艺的计算机科学家正在为他的女儿烘制生日蛋糕。他有做生日蛋糕的食谱，厨房里有所需的原料:面粉、鸡蛋、糖、香草汁等。在这个比喻中，做蛋糕的食谱就是程序(即用适当形式描述的算法)，计算机科学家就是处理器(CPU)， 而做蛋糕的各种原料就是输人数据。进程就是厨师阅读食谱、取来各种原料以及烘制蛋糕等-系列动作的总和。
现在假设计算机科学家的儿子哭着跑了进来，说他的头被一只蜜蜂蛰了。计算机科学家就记录下他照着食谱做到哪儿了(保存进程的当前状态)，然后拿出一本急救手册，按照其中的指示处理蛰伤。这里，处理机从一一个进程(做蛋糕)切换到另一个高优先级的进程(实施医疗救治)，每个进程拥有各自的程序(食谱和急救手册)。当蜜蜂蛰伤处理完之后，这位计算机科学家又回来做蛋糕，从他离开时的那一步继续做下去。
这里的关键思想是:一个进程是某种类型的个活动，它有程序、输入、输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另一个进程提供服务。
值得注意的是，如果一个程序运行了两遍，则算作两个进程。例如，人们可能经常两次启动同一个字处理软件，或在有两个可用的打印机的情况下同时打印两个文件。像“两个进程恰好运行同一个程序”这样的事实其实无关紧要，因为它们是不同的进程。操作系统能够使它们共享代码，因此只有一个副本放在内存中，但那只是一个技术性的细节，不会改变有两个进程正在运行的概念。

### 进程创建

4种主要事件会导致进程的创建:
1)系统初始化。
2)正在运行的程序执行了创建进程的系统调用。
3)用户请求创建一个新进程。
4)一个批处理作业的初始化。

启动操作系统时，通常会创建若千个进程。其中有些是前台进程，也就是同用户(人类)交互并且替他们完成工作的那些进程。其他的是后台进程，这些进程与特定的用户没有关系，相反，却具有某些专门的功能。例如，设计一个后台进程来接收发来的电子邮件，这个进程在一天的大 部分时间都在睡眠，但是当电子邮件到达时就突然被唤醒了。也可以设计另一个后台进程来接收对该机器中Web页面的访问请求，在请求到达时唤醒该进程以便服务该请求。停留在后台处理诸如电子邮件、Web页面、新闻、打印之类活动的进程称为**守护进程**(daemon)。 在大型系统中通常有很多守护进程。在UNIX日中，可以用ps程序列出正在运行的进程；在Windows中，可使用任务管理器。

在UNIX和Windows中，进程创建之后，父进程和子进程有各自不同的地址空间。如果其中某个进程在其地址空间中修改了一个字，这个修改对其他进程而言是不可见的。在UNIX中，子进程的初始地址空间是父进程的-一个副本，但是这里涉及两个不同的地址空间，不可写的内存区是共享的。某些UNIX的实现使程序正文在两者间共享，因为它不能被修改。或者，子进程共享父进程的所有内存，但这种情况下内存通过写时复制(copy-on-write) 共享，这意味着一旦两者之一想要修改部分内存，则这块内存首先被明确地复制，以确保修改发生在私有内存区域。再次强调，可写的内存是不可以共享的。但是，对于一个新创建的进程而言，确实有可能共享其创建者的其他资源，诸如打开的文件等。在Windows中，从一开始父进程的地址空间和子进程的地址空间就是不同的。

### 进程的终止

引起终止的几个条件：

1)正常退出(自愿的)。
2)出错退出(自愿的)。
3)严重错误(非自愿)。
4)被其他进程杀死(非自愿)。

进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所致。例如，执行了一条非法指令、引用不存在的内存，或除数是零等。有些系统中(如UNIX)， 进程可以通知操作系统，它希望自行处理某些类型的错误，在这类错误中，进程会收到信号(被中断)，而不是在这类错误出现时终止。

第四种终止进程的原因是，某个进程执行一个系统调用通知操作系统杀死某个其他进程。在UNIX中，这个系统调用是ill在Win32中对应的函数是TerminateProcess。在这两种情形中，“杀手”都必须获得确定的授权以便进行动作。在有些系统中，当一个进程终止时，不论是自愿的还是其他原因，由该进程所创建的所有进程也- -律立即被杀死。不过，UNIX和Windows都不是这种工作方式。

### 进程的层次结构

某些系统中，当进程创建了另一个进程后，父进程和子进程就以某种形式继续保持关联。子进程自身可以创建更多的进程，组成一个进程的层次结构。请注意，这与植物和动物的有性繁殖不同，进程只有一个父进程(但是可以有零个、一一个、两个或多个子进程)。

在UNIX中，进程和它的所有子进程以及后裔共同组成一个进程组。当用户从键盘发出一个信号时，该信号被送给当前与键盘相关的进程组中的所有成员(它们通常是在当前窗口创建的所有活动进程)。每个进程可以分别捕获该信号.忽略该信号或采取默认的动作，即被该信号杀死。

这里有另一个例子，可以用来说明进程层次的作用，考虑UNIX在启动时如何初始化自己。一个称为init的特殊进程出现在启动映像中。当它开始运行时，读入一个说明终端数量的文件。接着，为每个终端创建一个新进程。这些进程等待用户登录。如果有一一个用户登录成功，该登录进程就执行一个shell准备接收命令。所接收的这些命令会启动更多的进程，以此类推。这样，在整个系统中，所有的进程都属于以init为根的一棵树。

相反，Windows中没有进程层次的概念，所有的进程都是地位相同的。唯一类似于进程层次的暗示是在创建进程的时候，父进程得到一个特别的令牌(称为句柄)，该句柄可以用来控制子进程。但是，它有权把这个令牌传送给某个其他进程，这样就不存在进程层次了。在UNIX中，进程就不能剥夺其子继承的“继承权”。

### 进程的状态

尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间经常需要相互作用。一个进程的输出结果可能作为另一个进程的输人。在shell命令

```bash
cat chapter1 chapter2 chapter3 | grep tree
```

中，第一个进程运行cat，将三个文件连接并输出。第二个进程运行grep，它从输人中选择所有包含单词"tree”的那些行。根据这两个进程的相对速度(这取决于这两个程序的相对复杂度和各自所分配到的CPU时间)，可能发生这种情况: grep准备就绪可以运行，但输入还没有完成。于是必须阻塞grep， 直到输入到来。

当一个进程在逻辑上不能继续运行时，它就会被阻塞，典型的例子是它在等待可以使用的输入。还可能有这样的情况:一个概念上能够运行的进程被迫停止，因为操作系统调度另一个进程占用了CPU。这两种情况是完全不同的。在第一种情况下，进程挂起是程序自身固有的原因(在键入用户命令行之前，无法执行命令)。第二种情况则是由系统技术上的原因引起的(由于没有足够的CPU，所以不能使每个进程都有一台私用的处理器)。在图2-2中 可以看到显示进程的三种状态的状态图，这三种状态是:

![image](https://wx3.sinaimg.cn/large/69d4185bly1g2xqx0jm2tj20ej071jtv.jpg)

1) 运行态(该时刻进程实际占用CPU)。

2) 就绪态(可运行，但因为其他进程正在运行而暂时停止)。

3) 阻塞态(除非某种外部事件发 生，否则进程不能运行)。

转换2和3是由进程调度程序引起的，进程调度程序是操作系统的一部分，进程甚至感觉不到调度程序的存在。系统认为一个运行进程占用处理器的时间已经过长，决定让其他进程使用CPU时间时，会发生转换2。在系统已经让所有其他进程享有了它们应有的公平待遇而重新轮到第一个进程再次占用CPU运行时，会发生转换3。调度程序的主要工作就是决定应当运行哪个进程、何时运行及它应该运行多长时间，这是很重要的一点，我们将在本章的后面部分进行讨论。目前已经提出了许多算法，这些算法力图在整体效率和进程的竞争公平性之间取得平衡。我们将在本章稍后部分研究其中的一些问题。

当进程等待的一个外部事件发生时(如一-些输入到达)，则发生转换4。如果此时没有其他进程运行，则该进程将处于就绪态，等待CPU空闲并则该进程将处于就绪态，等待CPU空闲并且轮到它运行。

从这个观点引出了图2-3所示的模型。在图2-3中，操作系统的最底层是调度程序，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中。实际上，调度程序是一段非常短小的程序。操作系统的其他部分被简单地组织成进程的形式。不过，很少有真实的系统是以这样的理想方式构造的。

![image](https://wx3.sinaimg.cn/large/69d4185bly1g2xr34pfyzj20ev070wgr.jpg)



### 进程的实现

[cnblogs - 中断和中断处理程序](https://www.cnblogs.com/frankyou/p/8649435.html)

[Interrupts， Exceptions， and System Calls]([http://www.cse.iitm.ac.in/~chester/courses/15o_os/slides/5_Interrupts.pdf](http://www.cse.iitm.ac.in/~chester/courses/15o_os/slides/5_Interrupts.pdf))

为了实现进程模型，操作系统维护着一张表格(一个结构数组)，即**进程表**(process table)。每个进程占用一个进程表项。(有些作者称这些表项为**进程控制块**。)该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。

图2-4中展示了在一个典型系统中的关键字段。第一列中的字段与进程管理有关。其他两列分别与存储管理和文件管理有关。应该注意到进程表中的字段是与系统密切相关的，不过该图给出了所需要信息的大致介绍。

![image](https://wx2.sinaimg.cn/large/69d4185bly1g2xrh3d3rcj20h80bs43h.jpg)

在了解进程表后，就可以对在单个(或每一个) CPU上如何维持多个顺序进程的错觉做更多的阐述。与每一I/O类关联的是一个称作**中断向量**(interrupt vector)的位置(靠近内存底部的固定区域)。它包含中断服务程序的人口地址。假设当一个磁盘中断发生时，用户进程3正在运行，则中断硬件将程序计数器、程序状态字、有时还有一个或多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的地址。这些是硬件完成的所有操作，然后软件，特别是中断服务例程就接管一切剩余的工作。

> **什么是中断？**简单地说就是CPU在忙着作自己的事情，这时候硬件（比如说键盘按了一下）触发了一个电信号，这个信号**通过中断线**到达**中断控制器i8259A，i8259A**接受到这个信号后，向**CPU**发送**INT信号**申请CPU来执行刚才的硬件操作，并且将**中断类型号**也发给CPU，此时CPU保存当前正在做的事情（**REST指令**把程序计数器**PC**中的下一条待执行的指令的内存地址保存到**栈**）的情景现场，然后去处理这个申请，根据**中断类型号**找到它的**中断向量**（**即中断程序在内存中的地址**），然后去执行这段程序（这段程序已经写好，在内存中），执行完后再向i8259A发送一个**INTA**信号表示其已经处理完刚才的申请。此时CPU就可以继续做它刚才被打断做的事情了，将刚才保存的情景现场恢复出来，CPU继续执行接下来下面的程序。
>
> ——《cnblogs - 中断和中断处理程序》

所有的中断都从保存寄存器开始，对于当前进程而言，通常是保存在进程表项中。随后，会从堆栈中刪除由中断硬件机制存人堆栈的那部分信息，并将堆栈指针指向一个由进程处理程序所使用的临时堆栈。一些诸如保存寄存器值和设置堆栈指针等操作，无法用C语言这一类高级语言描述，所以这些操作通过一个短小的汇编语言例程来完成，通常该例程可以供所有的中断使用，因为无论中断是怎样引起的，有关保存寄存器的工作则是完全一样的。

![image](https://wx1.sinaimg.cn/large/69d4185bly1g2yl1j93loj20cc06sgo7.jpg)

当该例程结束后，它调用一个C过程处理某个特定的中断类型剩下的工作。(假定操作系统由C语言编写，通常这是所有真实操作系统的选择)。在完成有关工作之后，大概就会使某些进程就绪，接着调用调度程序，决定随后该运行哪个进程。随后将控制转给一段汇编语言代码，为当前的进程装入寄存器值以及内存映射并启动该进程运行。图2-5中总结了中断处理和调度的过程。值得注意的是，各种系统之间某些细节会有所不同。

### 多道程序设计模型

采用多道程序设计可以提高CPU的利用率。严格地说，如果进程用于计算的平均时间是进程在内存中停留时间的20%，且内存中同时有5个进程，则CPU将一直满负载运行。然而，这个模型在现实中过于乐观，因为它假设这5个进程不会同时等待I/O。

更好的模型是从概率的角度来看CPU的利用率。假设一个进程等待I/O操作的时间与其停留在内存中时间的比为p。当内存中同时有n个进程时，则所有n个进程都在等待I/O(此时CPU空转)的概率是$p^n$。CPU的利用率由下面的公式给出:
$$
CPU利用率= 1-p^n
$$
![image](https://wx4.sinaimg.cn/large/69d4185bly1g2yl74l33lj20e609q0vg.jpg)

图2-6以n为变量的函数表示了CPU的利用率，n 称为**多道程序设计的道数**(degree of multiprogramming)。

从图2-6中可以清楚地看到，如果进程花费80%的时间等待I/O，为使CPU的浪费低于10%，至少要有10个进程同时在内存中。当读者认识到一个等待用户从终端输入的交互式进程是处于IO等待状态时，那么很明显，80%甚至更多的I/O等待时间是普遍的。即使是在服务器中，做大量磁盘I/O操作的进程也会花费同样或更多的等待时间。

从完全精确的角度考虑，应该指出此概率模型只是描述了一个大致的状况。它假设所有n个进程是独立的，即内存中的5个进程中，3个运行，2个等待，是完全可接受的。但在单CPU中，不能同时运行3个进程，所以当CPU忙时，已就绪的进程也必须等待CPU。因而，进程不是独立的。更精确的模型应该用排队论构建，但我们的模型(当进程就绪时，给进程分配CPU，否则让CPU空转)仍然是有效的，即使真实曲线会与图2-6中所画的略有不同。

虽然图2-6的模型很简单、很粗略，它依然对预测CPU的性能很有效。例如，假设计算机有8GB内存，操作系统及相关表格占用2GB，每个用户程序也占用2GB。这些内存空间允许3个用户程序同时驻留在内存中。若80%的时间用于I/O等待，则CPU的利用率(忽略操作系统开销)大约是1-0.8，即大约49%。在增加8GB字节的内存后，可从3道程序设计提高到7道程序设计，因而CPU利用率提高到79%。换言之，第二个8GB内存提高了30%的吞吐量。

增加第三个8GB内存只能将CPU利用率从79%提高到91%，吞吐量的提高仅为12%。通过这一模型，计算机用户可以确定，第一次增加内存是一个划算的投资，而第二个则不是。

## 线程

在传统操作系统中，每个进程有一个地址空间和一个控制线程。事实上，这几乎就是进程的定义。不过，经常存在在同一个地址空间中准并行运行多个控制线程的情形，这些线程就像(差不多)分离的进程(共享地址空间除外)。

### 线程的使用

为什么人们需要在一个进程中再有一类进程?有若千理由说明产生这些迷你进程(称为线程)的必要性。下面我们来讨论其中一些理由。人们需要多线程的主要原因是，在许多应用中同时发生着多种活动。其中某些活动随着时间的推移会被阻塞。通过将这些应用程序分解成可以准并行运行的多个顺序线程，程序设计模型会变得更简单。

前面已经进行了有关讨论。准确地说，这正是之前关于进程模型的讨论。有了这样的抽象，我们才不必考虑中断、定时器和上下文切换，而只需考察并行进程。类似地，只是在有了多线程概念之后，我们才加入了一种新的元素:并行实体拥有共享同一个地址空间和所有可用数据的能力。对于某些应用而言，这种能力是必需的，而这正是多进程模型(它们具有不同的地址空间)所无法表达的。

第二个关于需要多线程的理由是，由于线程比进程更轻量级，所以它们比进程更容易(即更快)创建，也更容易撤销。在许多系统中，创建一个线程较创建一个进程要快10~100倍。在有大量线程需要动态和快速修改时，具有这一特性是很有用的。

需要多线程的第三个原因涉及性能方面的讨论。若多个线程都是CPU密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的I/O处理，拥有多个线程允许这些活动彼此重叠进行，从而会加快应用程序执行的速度。

最后，在多CPU系统中，多线程是有益的，在这样的系统中，真正的并行有了实现的可能。

------

通过考察一些典型例子，我们可以更清楚地看出引入多线程的好处。作为第一个例子，考虑一个字处理软件。字处理软件通常按照出现在打印页上的格式在屏幕上精确显示文档。特别地，所有的行分隔符和页分隔符都在正确的最终位置上，这样在需要时用户可以检查和修改文档(比如，消除孤行一在一页上不完整的顶部行和底部行，因为这些行不甚美观)。

假设用户正在写一本书。从作者的观点来看，最容易的方法是把整本书作为一个文件，这样一来，查询内容、完成全局替换等都非常容易。另一种方法是，把每一章都处理成单独一个文件。但是，在把每个小节和子小节都分成单个的文件之后，若必须对全书进行全局的修改时，那就真是麻烦了，因为有成百个文件必须一个个地编辑。例如，如果所建议的某个标准x x x x正好在书付印之前被批准了，于是“标准草案xx x x”一类的字眼就必须改为“标准xx x x”。如果整本书是一个文件，那么只要一个命令就可以完成全部的替换处理。相反，如果一本书分成了300个文件，那么就必须分别对每个文件进行编辑。

现在考虑，如果有一一个用户突然在一个有800页的文件的第页上删掉了一个语句之后，会发生什么情形。在检查了所修改的页面并确认正确后，这个用户现在打算接着在第600页上进行另-个修改，并键人一条命令通知字处理软件转到该页面(可能要查阅只在那里出现的一个短语)。于是字处理软件被强制对整本书的前600页重新进行格式处理，这是因为在排列该页前面的所有页面之前，字处理软件并不知道第600页的第一行应该在哪里。而在第600页的页面可以真正在屏幕上显示出来之前，计算机可能要拖延相当一段时间，从而令用户不甚满意。

多线程在这里可以发挥作用。假设字处理软件被编写成含有两个线程的程序。一个线程与用户交互，而另一个在后台重新进行格式处理。一旦在第1页中的语句被删除掉，交互线程就立即通知格式化线程对整本书重新进行处理。同时，交互线程继续监控键盘和鼠标，并响应诸如滚动第1页之类的简单命令，此刻，另一个线程正在后台疯狂地运算。如果有点运气的话，重新格式化会在用户请求查看第600页之前完成，这样，第600页页面就立即可以在屏幕上显示出来。

如果已经做到了这一步，那么为什么不再进一步增加个线程呢?许多字处理软件都有每隔若千分钟自动在磁盘上保存整个文件的特点，用于避免由于程序崩溃、系统崩溃或电源故障而造成用户整天的工作丢失的情况。第三个线程可以处理磁盘备份，而不必干扰其他两个线程。拥有三个线程的情形，如图2-7所示。

![image](https://ws2.sinaimg.cn/large/69d4185bly1g2yn1l1ulsj20hx0agq6o.jpg)

如果程序是单线程的，那么在进行磁盘备份时，来自键盘和鼠标的命令就会被忽略，直到备份工作完成为止。用户当然会认为性能很差。另一个方法是，为了获得好的性能，可以让键盘和鼠标事件中断磁盘备份，但这样却引入了复杂的中断驱动程序设计模型。如果使用三个线程，程序设计模型就很简单了。第一个线程只是和用户交互:第二个线程在得到通知时进行文档的重新格式化:第三个线程周期性地将RAM中的内容写到磁盘上。

很显然，在这里用三个不同的进程是不能工作的，这是因为三个线程都需要对同一个文件进行操作。由于多个线程可以共享公共内存，所以通过用三个线程替换三个进程，使得它们可以访问同一个正在编辑的文件，而三个进程是做不到的。

------

现在考虑另一个多线程发挥作用的例子:一个万维网服务器。对页面的请求发给服务器，而所请求的页面发回给客户机。在多数Web站点上，某些页面较其他页面相比，有更多的访问。例如，对Sony主页的访问就远远超过对深藏在页面树里的任何特定摄像机的技术说明书页面的访问。利用这一事实，Web服务器可以把获得大量访问的页面集合保存在内存中，避免到磁盘去调入这些页面，从而改善性能。这样的一-种页面集合称为**高速缓存**(cache)， 高速缓存也运用在其他许多场合中。例如在第1章中介绍的CPU缓存。

![image](https://wx3.sinaimg.cn/large/69d4185bly1g2zrhjkyjpj20d809atbr.jpg)

一种组织Web服务器的方式如图2-8所示。在这里，一个称为**分派程序**(dispatcher) 的线程从网络中读入工作请求。在检查请求之后，分派线程挑选一个空转的(即被阻塞的)**工作线程**(worker thread)，提交该请求，通常是在每个线程所配有的某个专门字中写人一个消息指针。接着分派线程唤醒睡眠的工作线程，将它从阻塞状态转为就绪状态。

在工作线程被唤醒之后，它检查有关的请求是否在Web页面高速缓存之中，这个高速缓存是所有线程都可以访问的。如果没有，该线程开始一个从磁盘调入页面的read操作，并且阻塞直到该磁盘操作完成。当上述线程阻塞在磁盘操作上时，为了完成更多的工作，分派线程可能挑选另一个线程运行，也可能把另一个当前就绪的工作线程投人运行。

现在考虑在没有多线程的情形下，如何编写Web服务器。一种可能的方式是，使其像一个线程- -样运行。Web服务器的主循环获得请求，检查请求，并且在取下一个请求之前完成整个工作。在等待磁盘操作时，服务器就空转，并且不处理任何到来的其他请求。如果该Web服务器运行在唯一的机器上，通常情形都是这样，那么在等待磁盘操作时CPU只能空转。结果导致每秒钟只有很少的请求被处理。可见线程较好地改善了Web服务器的性能，而且每个线程是按通常方式顺序编程的。

到现在为止，我们有了两个可能的设计方案:多线程Web服务器和单线程Web服务器。假设没有多线程可用，而系统设计者又认为由于单线程所造成的性能降低是不能接受的，那么如果可以使用**read**系统调用的非阻塞版本，还存在第三种可能的设计。在请求到来时，这个唯一的线程对请求进行考察。如果该请求能够在高速缓存中得到满足，那么一切都好，如果不能，则启动一个非阻塞的磁盘操作。
服务器在表格中记录当前请求的状态，然后去处理下一个事件。下一个事件可能是-一个新工作的请求，或是磁对先前操作的回答。如果是新工作的请求，就开始该工作。如果是磁盘的回答，就从表格中取出对应的信息，并处理该回答。对于非阻塞磁盘I/O而言，这种回答多数会以信号或中断的形式出现。
在这一设计中，前面两个例子中的“顺序进程”模型消失了。每次服务器从为某个请求工作的状态切换到另一个状态时，都必须显式地保存或重新装人相应的计算状态。事实上，我们以一种困难的方式模拟了线程及其堆栈。这里，每个计算都有一个被保存的状态，存在一个会发生且使得相关状态发生改变的事件集合，我们把这类设计称为**有限状态机**(finite-state machine)。有限状态机这一概念广 泛地应用在计算机科学中。

现在很清楚多线程必须提供的是什么了。多线程使得顺序进程的思想得以保留下来，这种顺序进程阻塞了系统调用( 如磁盘I/O)，但是仍旧实现了并行性。对系统调用进行阻塞使程序设计变的较为简单，而且并行性改善了性能。单线程服务器虽然保留了阻塞系统调用的简易性，但是却放弃了性能。第三种处理方法运用了非阻塞调用和中断，通过并行性实现了高性能，但是给编程增加了困难。在图2-10中给出了上述模式的总结。

![image](https://ws2.sinaimg.cn/large/69d4185bly1g2zrozpjucj20g104itah.jpg)

有关多线程作用的第三个例子是那些必须处理极大量数据的应用。通常的处理方式是，读进一块数据，对其处理，然后再写出数据。这里的问题是，如果只能使用阻塞系统调用，那么在数据进人和数据输出时，会阻塞进程。在有大量计算需要处理的时候，让CPU空转显然是浪费，应该尽可能避免。
多线程提供了一种解决方案，有关的进程可以用一个输入线程、-.个处理线程和-个输出线程构造。输入线程把数据读人到输人缓冲区中；处理线程从输入缓冲区中取出数据，处理数据，并把结果放到输出缓冲区中:输出线程把这些结果写到磁盘上。按照这种工作方式，输入、处理和输出可以全部同时进行。当然，这种模型只有当系统调用只阻塞调用线程而不是阻塞整个进程时，才能正常工作。

### 经典的线程模型

既然已经清楚为什么线程会有用以及如何使用它们，不如让我们用更进一步的眼光来审查一下上面的想法。进程模型基于两种独立的概念:资源分组处理与执行。有时，将这两种概念分开会更好，这就引人了“线程”这一概念。下面先介绍经典的线程模型；之后我们会来研究“模糊进程与线程分界线”的Linux线程模型。

理解进程的一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。这些资源中包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把它们都放到进程中可以更容易管理。
另一个概念是，进程拥有一个执行的线程，通常简写为**线程**(thread)。 在线程中有一个程序计数器，用来记录接着要执行哪一条指令。线程拥有寄存器，用来保存线程当前的工作变量。线程还拥有一个堆栈，用来记录执行历史，其中每一帧保存了一个已调用的但是还没有从中返回的过程。尽管线程必须在某个进程中执行，但是线程和它的进程是不同的概念，并且可以分别处理。进程用于把资源集中到一起，而线程则是在CPU上被调度执行的实体。

线程给进程模型增加了一项内容，即在同一个进程环境中，允许彼此之间有较大独立性的多个线程执行。在同一个进程中并行运行多个线程，是对在同一台计算机上并行运行多个进程的模拟。在前一种情形下，多个线程共享同一个地址空间和其他资源。而在后一种情形中，多个进程共享物理内存、磁盘、打印机和其他资源。由于线程具有进程的某些性质，所以有时被称为**轻量级进程**(lightweight process)。**多线程**这个术语，也用来描述在同一个进程中允许多个线程的情形。正如在第1章中看到的，一些CPU已经有直接硬件支持多线程，并允许线程切换在纳秒级完成。

在图2-11a中，可以看到三个传统的进程。每个进程有自己的地址空间和单个控制线程。相反，在图2-11b中，可以看到一个进程带有三个控制线程。尽管在两种情形中都有三个线程，但是在图2-11a中，每一个线程都在不同的地址空间中运行，而在图2-11b中，这三个线程全部在相同的地址空间中运行。
当多线程进程在单CPU系统中运行时，线程轮流运行。从图2-1中，我们已经看到了进程的多道程序设计是如何工作的。通过在多个进程之间来回切换，系统制造了不同的顺序进程并行运行的假象。多线程的工作方式也是类似的。CPU在线程之间的快速切换，制造了线程并行运行的假象，好似它们在一个比实际CPU慢一-些的CPU上同时运行。在个有三个计算密集型线程的进程中，线程以并行方式运行，每个线程在一个CPU上得到了真实CPU速度的三分之一。

![image](https://wx4.sinaimg.cn/large/69d4185bly1g2zs02g39gj20ht08f77k.jpg)

进程中的不同线程不像不同进程之间那样存在很大的独立性。所有的线程都有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于各个线程都可以访问进程地址空间中的每-一个内存地址，所以一个线程可以读、写或甚至清除另一个线程的堆栈。线程之间是没有保护的，原因是: 1)不可能，2)也没有必要。这与不同进程是有差别的。不同的进程会来自不同的用户，它们彼此之间可能有敌意，一个进程总是由某个用户所拥有，该用户创建多个线程应该是为了它们之间的合作而不是彼此间争斗。除了共享地址空间之外，所有线程还共享同一个打开文件集、子进程、定时器以及相关信号等，如图2-12所示。这样，对于三个没有关系的线程而言，应该使用图2-11a的结构，而在三个线程实际完成同一个作业，并彼此积极密切合作的情形中，图2-11b则比较合适。

![image](https://ws2.sinaimg.cn/large/69d4185bly1g2zs35l2smj20nf06fwi1.jpg)

图2-12中，第一列表项是进程的属性，而不是线程的属性。例如，如果一个线程打开了一个文件，该文件对该进程中的其他线程都可见，这些线程可以对该文件进行读写。由于资源管理的单位是进程而非线程，所以这种情形是合理的。如果每个线程有其自己的地址空间、打开文件、即将发生的定时器等，那么它们就应该是不同的进程了。<u>线程概念试图实现的是，共享一组资源的多个线程的执行能力，以便这些线程可以为完成某一任务而共同工作</u>。

和传统进程一样(即只有一个线程的进程)，线程可以处于若干种状态的任何一个:运行、阻塞、就绪或终止。正在运行的线程拥有CPU并且是活跃的。被阻塞的线程正在等待某个释放它的事件。例如，当一个线程执行从键盘读入数据的系统调用时，该线程就被阻塞直到键入了输人为止。线程可以被阻塞，以便等待某个外部事件的发生或者等待其他线程来释放它。就绪线程可被调度运行，并且只要轮到它就很快可以运行。线程状态之间的转换和进程状态之间的转换是一样的，如图2-2所示。

![image](https://wx4.sinaimg.cn/large/69d4185bly1g2zs9n7gkzj20cf09dq4y.jpg)

认识到每个线程有其自己的堆栈很重要，如图2-13所示。每个线程的堆栈有一帧，供各个被调用但是还没有从中返回的过程使用。在该栈帧中存放了相应过程的局部变量以及过程调用完成之后使用的返回地址。例如，如果过程X调用过程Y，而Y又调用Z，那么当Z执行时，供X、Y和Z使用的栈帧会全部存在堆栈中。通常每个线程会调用不同的过程，从而有一个各自不同的执行历史，这就是为什么每个线程需要有自己的堆栈的原因。

------

通常而言，线程是有益的，但是线程也在程序设计模式中引入了某种程度的复杂性。考虑一下UNIX中的fork系统调用。如果父进程有多个线程，那么它的子进程也应该拥有这些线程吗?如果不是，则该子进程可能会工作不正常，因为在该子进程中的线程都是绝对必要的。

然而，如果子进程拥有了与父进程一样的多个线程，如果父进程在read系统调用(比如键盘)上 被阻塞了会发生什么情况?是两个线程被阻塞在键盘上(一个属于父进程，另一个属于子进程)吗?在键入一行输入之后，这两个线程都得到该输人的副本吗?还是仅有父进程得到该输人的副本?或是仅有子进程得到?类似的问题在进行网络连接时也会出现。

另一类问题和线程共享许多数据结构的事实有关。如果-一个线程关闭了某个文件，而另一个线程还在该文件上进行读操作时会怎样?假设有一个线程注意到几乎没有内存了，并开始分配更多的内存。在工作一半的时候，发生线程切换，新线程也注意到几乎没有内存了，并且也开始分配更多的内存。这样，内存可能会被分配两次。不过这些问题通过努力是可以解决的。总之，要使多线程的程序正确工作，就需要仔细思考和设计。

### POSIX 线程

为实现可移植的线程程序，IEEE在IEEE标准1003.1c中定义了线程的标准。它定义的线程包叫作**pthread**。 大部分UNIX系统都支持该标准。城2所有pthread线程都有某些特性。每一个都含有一个标识符、一组寄存器(包括程序计数器)和一组存储在结构中的属性。这些属性包括堆栈大小、调度参数以及其他线程需要的项目。

![image](https://wx4.sinaimg.cn/large/69d4185bly1g2zsu9eoxyj20kw07kwie.jpg)

创建一个新线程需要使用pthread\_create调用。新创建的线程的线程标识符会作为函数值返回。这种调用有意看起来很像fork系统调用，其中线程标识符起着PID的作用，而这么做的目的主要是为了标识在其他调用中引用的线程。

当一个线程完成分配给它的工作时，可以通过调用pthread\_exit来终止。这个调用终止该线程并释放它的栈。

一般一个线程在继续运行前需要等待另一个线程完成它的工作并退出。可以通过pthread\_join线程调用来等待别的特定线程的终止。而要等待线程的线程标识符作为一个参数给出。

有时会出现这种情况:一个线程逻辑上没有阻塞，但感觉上它已经运行了足够长时间并且希望给另外一个线程机会去运行。这时可以通过调用pthread\_yield完成这一目标。而进程中没有这种调用，因为假设进程间会有激烈的竞争性，并且每--个进程都希望获得它所能得到的所有的CPU时间。但是，由于同一进程中的线程可以同时工作，并且它们的代码总是由同一个程序员编写的，因此，有时程序员希望它们能互相给对方一些机会去运行。
下面两个线程调用是处理属性的。pthread\_attr\_init建 立关联一个线程的属性结构并初始化成默认值。这些值(例如优先级)可以通过修改属性结构中的城值来改变。
最后，pthread\_attr\_destroy 刪除一个线程的属性结构，释放它占用的内存。它不会影响调用它的线程。这些线程会继续存在。

### 在用户空间实现线程

[为什么CPU需要时钟才能工作？](https://www.zhihu.com/question/21981280)



有两种主要的方法实现线程包:在用户空间中和在内核中。这两种方法互有利弊，不过混合实现方式也是可能的。我们现在介绍这些方法，并分析它们的优点和缺点。
第一种方法是把整个线程包放在用户空间中，内核对线程包一无所知。从内核角度考虑，就是按正常的方式管理，即单线程进程。*这种方法第一个也是最明显的优点是，用户级线程包可以在不支持线程的操作系统上实现。过去所有的操作系统都属于这个范围，即使现在也有一些操作系统还是不支持线程*。

所有的这类实现都有同样的通用结构，如图2-16a所示。 线程在一一个运行时系统的上层运行，该运行时系统是一个管理线程的过程的集合。前面已经介绍过其中的四个过程: pthread\_create， pthrea\_ exit， pthread\_join和pthread\_yield。 不过，一般还会有更多的过程。

![image](https://wx2.sinaimg.cn/large/69d4185bly1g2zt4tcdoij20jd0bln2u.jpg)

在用户空间管理线程时，每个进程需要有其专用的**线程表**(threadtable)，用来跟踪该进程中的线程。这些表和内核中的进程表类似，不过它仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态等。该线程表由运行时系统管理。当- 一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程所需的信息，与内核在进程表中存放进程的信息完全一样。

当某个线程做了一些会引起在本地阻塞的事情之后，例如，等待进程中另一个线程完成某项工作，它调用一个运行时系统的过程，这个过程检查该线程是否必须进人阻塞状态。如果是，它在线程表中保存该线程的寄存器(即它本身的)，查看表中可运行的就绪线程，并把新线程的保存值重新装入机器的寄存器中。只要堆栈指针和程序计数器一被切换，新的线程就又自动投入运行。如果机器有一条保存所有寄存器的指令和另-条装入全部寄存器的指令，那么整个线程的切换可以在几条指令内完成。进行类似于这样的线程切换至少比陷入内核要快一个数量级(或许更多)，这是使用用户级线程包的极大的优点。

不过，线程与进程有一个关键的差别。I在线程完成运行时，例如，在它调用`thread_yield`时 ，`pthread_yield`代码可以把该线程的信息保存在线程表中，进而，它可以调用线程调度程序来选择另一个要运行的线程。保存该线程状态的过程和调度程序都只是本地过程，所以启动它们比进行内核调用效率更高。另一方面，不需要陷入内核，不需要上下文切换，也不需要对内存高速缓存进行刷新，这就使得线程调度非常快捷。

用户级线程还有另一个优点。它允许每个进程有自己定制的调度算法。例如，在某些应用程序中，那些有垃圾收集线程的应用程序就不用担心线程会在不合适的时刻停止，这是一个长处。用户级线程还具有较好的可扩展性，这是因为在内核空间中内核线程需要一些固定表格空间和堆栈空间，如果内核线程的数量非常大，就会出现问题。

------

尽管用户级线程包有更好的性能，但它也存在一些明显的问题。其中第:个问题是如何实现阻塞系统调用。假设在还没有任何击键之前，-一个线程读取键盘。让该线程实际进行该系统调用是不可接受的，因为这会停止所有的线程。使用线程的一个主要目标是，首先要允许每个线程使用阻塞调用，但是还要避免被阻塞的线程影响其他的线程。有了阻塞系统调用，这个目标不是轻易地能够实现的。
系统调用可以全部改成非阻塞的(例如，如果没有被缓冲的字符，对键盘的read操作可以只返回0字节)，但是这需要修改操作系统，所以这个办法也不吸引人。而且，用户级线程的一个长处就是它可以在现有的操作系统上运行。另外，改变read操作的语义需要修改许多用户程序。
在这个过程中，还有一种可能的替代方案，就是如果某个调用会阻塞，就提前通知。在某些UNIX版本中，有一个系统调用select可以允许调用者通知预期的read是否会阻塞。若有这个调用，那么库过程read就可以被新的操作替代，首先进行select调用，然后只有在安全的情形下(即不会阻塞)才进行read调用。如果read调用会被阻塞，有关的调用就不进行，代之以运行另一个线程。到了下次有关的运行系统取得控制权之后，就可以再次检查看看现在进行read调用是否安全。这个处理方法需要重写部分系统调用库，所以效率不高也不优雅，不过没有其他的可选方案了。在系统调用周围从事检查的这类代码称为**包装器**(jacket或wrapper)。

与阻塞系统调用问题有些类似的是缺页中断问题，我们将在第3章讨论这些问题。此刻可以认为，把计算机设置成这样一种工作方式，即并不是所有的程序都一次性放在内存中。如果某个程序调用或者跳转到了一条不在内存的指令上，就会发生页面故障，而操作系统将到磁盘上取回这个丢失的指令(和该指令的“邻居们")，这就称为页面故障。在对所需的指令进行定位和读入时，相关的进程就被阻塞。如果有一个线程引起页面故障，内核由于甚至不知道有线程存在，通常会把整个进程阻塞直到磁盘I/O完成为止，尽管其他的线程是可以运行的。

用户级线程包的另一个问题是，如果一个线程开始运行，那么在该进程中的其他线程就不能运行，除非第一个线程自动放弃CPU。在一个单独的进程内部，没有时钟中断，所以不可能用轮转调度(轮流)的方式调度线程。除非某个线程能够按照自己的意志进入运行时系统，否则调度程序就没有任何机会。

对线程永久运行问题的一个可能的解决方案是让运行时系统请求每秒次的时钟信号(中断)，但是这样对程序也是生硬和无序的。不可能总是高频率地发生周期性的时钟中断，即使可能，总的开销也是可观的。而且，线程可能也需要时钟中断，这就会扰乱运行时系统使用的时钟。

再者，也许针对用户级线程的最大负面争论意见是，程序员通常在经常发生线程阻塞的应用中才希望使用多个线程。例如，在多线程Web服务器里。这些线程持续地进行系统调用，而一旦发生内核陷阱进行系统调用，如果原有的线程已经阻塞，就很难让内核进行线程的切换，如果要让内核消除这种情形，就要持续进行select系统调用，以便检查read系统调用是否安全。对于那些基本上是CPU密集型而且极少有阻塞的应用程序而言，使用多线程的目的又何在呢?由于这样的做法并不能得到任何益处，所以没有人会真正提出使用多线程来计算前n个素数或者下象棋等一类工作。

### 在内核实现线程

![image](https://wx2.sinaimg.cn/large/69d4185bly1g2zt4tcdoij20jd0bln2u.jpg)

现在考虑内核支持和管理线程的情形。如图2-16b所示，此时不再需要运行时系统了。另外，每个进程中也没有线程表。相反，在内核中有用来记录系统中所有线程的线程表。当某个线程希望创建一个新线程或撤销一个已有线程时，它进行一个系统调用，这个系统调用通过对线程表的更新完成线程创建或撤销工作。

内核的线程表保存了每个线程的寄存器、状态和其他信息。这些信息和在用户空间中(在运行时系统中)的线程是一样的，但是现在保存在内核中。这些信息是传统内核所维护的每个单线程进程信息(即进程状态)的子集。另外，内核还维护了传统的进程表，以便跟踪进程的状态。

所有能够阻塞线程的调用都以系统调用的形式实现，这与运行时系统过程相比，代价是相当可观的。当一个线程阻塞时，内核根据其选择，可以运行同一个进程中的另一个线程(若有一个就绪线程)或者运行另一个进程中的线程。而在用户级线程中，运行时系统始终运行自己进程中的线程，直到内核剥夺它的CPU (或者没有可运行的线程存在了)为止。

由于在内核中创建或撤销线程的代价比较大，某些系统采取“环保”的处理方式，回收其线程。当某个线程被撤销时，就把它标志为不可运行的，但是其内核数据结构没有受到影响。稍后，在必须创建一个新线程时，就重新启动某个旧线程，从而节省了一些开销。在用户级线程中线程回收也是可能的，但是由于其线程管理的代价很小，所以没有必要进行这项工作。

内核线程不需要任何新的、非阻塞系统调用。另外，如果某个进程中的线程引起了页面故障，内核可以很方便地检查该进程是否有任何其他可运行的线程，如果有，在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行。这样做的主要缺点是系统调用的代价比较大，所以如果线程的操作(创建、终止等)比较多，就会带来很大的开销。

虽然使用内核线程可以解决很多问题，但是也不会解决所有的问题。例如，当一个多线程进程创建新的进程时，会发生什么?新进程是拥有与原进程相同数量的线程，还是只有一个线程?在很多情况下，最好的选择取决于进程计划下步做什么。如果它要调用exec来启动一个新的程序，或许一个线程是正确的选择；但是如果它继续执行，则最好复制所有的线程。

另一个话题是信号。回忆一下，信号是发给进程而不是线程的，至少在经典模型中是这样的。当一个信号到达时，应该由哪一个线程处理它?线程可以“注册”它们感兴趣的某些信号，因此当一个信号到达的时候，可把它交给需要它的线程。但是如果两个或更多的线程注册了相同的信号，会发生什么?这只是线程引起的问题中的两个，但是还有更多的问题。

### 混合实现

人们已经研究了各种试图将用户级线程的优点和内核级线程的优点结合起来的方法。-种方法是使用内核级线程，然后将用户级线程与某些或者全部内核线程多路复用起来，如图2-17所示。如果采用这种方法，编程人员可以决定有多少个内核级线程和多少个用户级线程彼此多路复用。这一模型带来最大的灵活度。

![image](https://ws3.sinaimg.cn/large/69d4185bly1g30vg1jsd9j20cw08bdi9.jpg)

采用这种方法，内核只识别内核级线程，并对其进行调度。其中- -些内核级线程会被多个用户级线程多路复用。如同在没有多线程能力操作系统中某个进程中的用户级线程一样，可以创建、撤销和调度这些用户级线程。在这种模型中，每个内核级线程有一个可以轮流使用的用户级线程集合。

### 弹出式线程

在分布式系统中经常使用线程。一个有意义的例子是如何处理到来的消息，例如服务请求。传统的方法是将进程或线程阻塞在一个receive系统调用上，等待消息到来。当消息到达时，该系统调用接收消息，并打开消息检查其内容，然后进行处理。

不过，也可能有另一种完全不同的处理方式，在该处理方式中，-一个消息的到达导致系统创建一个处理该消息的线程，这种线程称为弹出式线程，如图2-18所示。弹出式线程的关键好处是，由于这种线程相当新，没有历史一一没有必须存 储的寄存器、堆栈诸如此类的内容，每个线程从全新开始，每一个线程彼此之间都完全一样。这样，就有可能快速创建这类线程。对该新线程指定所要处理的消息。使用弹出式线程的结果是，消息到达与处理开始之间的时间非常短。

![image](https://wx4.sinaimg.cn/large/69d4185bly1g30voen19nj20jh0atwj6.jpg)

在使用弹出式线程之前，需要提前进行计划。例如， 哪个进程中的线程先运行?如果系统支持 在内核上下文中运行线程，线程就有可能在那里运行(这是图2-18中没有画出内核的原因)。在内核空间中运行弹出式线程通常比在用户空间中容易且快捷，而且内核空间中的弹出式线程可以很容易访问所有的表格和I/O设备，这些也许在中断处理时有用。而另一方面，出错的内核线程会比出错的用户线程造成更大的损害。例如，如果某个线程运行时间太长，又没有办法抢占它，就可能造成进来的信息丢失。

## 进程间通讯

进程经常需要与其他进程通信。例如，在-一个shell管道中，第一个进程的输出必须传送给第二个进程，这样沿着管道传递下去。因此在进程之间需要通信，而且最好使用一种结构良好的方式而不要使用中断。在下面几节中，我们就来讨论一些有关**进程间通信**(Inter Process Communication， IPC)的问题。

简要地说，有三个问题。第一个问题与上面的叙述有关，即一个进程如何把信息传递给另一个。*第二个*要处理的问题是，确保两个或更多的进程在关键活动中不会出现交叉，例如，在飞机订票系统中的两个进程为不同的客户试图争夺飞机上的最后一个座位。*第三*个问题与正确的顺序有关( 如果该顺序是有关联的话)，比如，如果进程A产生数据而进程B打印数据，那么B在打印之前必须等待，直到A已经产生一些数据。我们将从下一节开始考察所有这三个问题。

有必要说明，这三个问题中的两个问题对于线程来说是同样适用的。第一个问题(即传递信息)对线程而言比较容易，因为它们共享-一个地址空间(在不同地址空间需要通信的线程属于不同进程之间通信的情形)。但是另外两个问题(需要梳理清楚并保持恰当的顺序)同样适用于线程。同样的问题可用同样的方法解决。下面开始讨论进程间通信问题，不过请记住，同样的问题和解决方法也适用于线程。

### 竞争条件

在一些操作系统中，协作的进程可能共享一些彼此都能读写的公用存储区。这个公用存储区可能在内存中(可能是在内核数据结构中)，也可能是一个共享文件。这里共享存储区的位置并不影响通信的本质及其带来的问题。为了理解实际中进程间通信如何工作，我们考虑一个简单但很普遍的例子:一个假脱机打印程序。当一个进程需要打印一个文件时，它将文件名放在一个特殊的假脱机目录(spooler directory)下。另一个进程(打印机守护进程)则周期性地检查是否有文件需要打印，若有就打印并将该文件名从目录下删掉。

![image](https://ws4.sinaimg.cn/large/69d4185bly1g30w0aqaa8j20c108oabq.jpg)

设想假脱机目录中有许多槽位，编号依次为0， 1，2，…… ，”每个槽位存放一个文件名。同时假设有两个共享变量: out，指向下一个要打印的文件； in， 指向目录中下一个空闲槽位。可以把这两个变量保存在一个所有进程都能访问的文件中，该文件的长度为两个字。在某一时刻，0号至3号槽位空(其中的文件已经打印完毕)，4号至6号槽位被占用(其中存有排好队列的要打印的文件名)。几乎在同一时刻，进程A和进程B都决定将一个文件排队打印，这种情况如图2-21所示。

在Murphy法则(任何可能出错的地方终将出错)生效时，可能发生以下的情况。进程A读到in的值为7，将7存在一个局部变量`next_free_slot`中。此时发生-次时钟中断，CPU认为进程A已运行了足够长的时间，决定切换到进程B。进程B也读取in，同样得到值为7，于是将7存在B的局部变量`next_ free_ slot`中。 在这一时刻两个进程都认为下一个可用槽位是7。进程B现在继续运行，它将其文件名存在槽位7中并将in的值更新为8。然后它离开，继续执行其他操作。

最后进程A接着从上次中断的地方再次运行。它检查变量`next_ free_ slot`， 发现其值为7，于是将打印文件名存入7号槽位，这样就把进程B存在那里的文件名覆盖掉。然后它将`next_ free_ slot`加1， 得到值为8，就将8存到in中。此时，假脱机目录内部是致的，所以打印机守护进程发现不了任何错误，但进程B却永远得不到任何打印输出。类似这样的情况，**即两个或多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序，称为竞争条件(race condition)**。调试包含有竞争条件的程序是一件很头痛的事。大多数的测试运行结果都很好，但在极少数情况下会发生一些无法解释的奇怪现象。不幸的 是，多核增长带来的并行使得竞争条件越来越普遍。

### 临界区

怎样避免竞争条件?实际上凡涉及共享内存、共享文件以及共享任何资源的情况都会引发与前面类似的错误，要避免这种错误，关键是要找出某种途径来阻止多个进程同时读写共享的数据。换言之，我们需要的是**互斥**(mutual exclusion)，即以某种手段确保当一个进程在使用一个共享变量或文件时，其他进程不能做同样的操作。前述问题的症结就在于，在进程A对共享变量的使用未结束之前进程B就使用它。为实现互斥而选择适当的原语是任何操作系统的主要设计内容之一。

避免竞争条件的问题也可以用一种抽象的方式进行描述。一个进程的一部分时间做内部计算或另外一些不会引发竞争条件的操作。在某些时候进程可能需要访问共享内存或共享文件，或执行另外一些会导致竞争的操作。**我们把对共享内存进行访问的程序片段称作临界区域(critical region)或临界区( criticalsection)**。如果我们能够适当地安排，使得两个进程不可能同时处于临界区中，就能够避免竞争条件。

尽管这样的要求避免了竞争条件，但它还不能保证使用共享数据的并发进程能够正确和高效地进行协作。对于一个好的解决方案，需要满足以下4个条件:

1） 任何两个进程不能同时处于其临界区。
2）不应对CPU的速度和数量做任何假设。
3）临界区外运行的进程不得阻塞其他进程。
4）不得使进程无限期等待进入临界区。

![image](https://wx4.sinaimg.cn/large/69d4185bly1g30wazk83fj20hh0a9gp8.jpg)

从抽象的角度看，人们所希望的进程行为如图2-22所示。图2-22中进程A在$T_1$，时刻进入临界区。稍后，在$T_2$时刻进程B试图进人临界区，但是失败了，因为另一个进程已经在该临界区内，而一个时刻只允许一个进程在临界区内。随后，B被暂时挂起直到$T_3$，时刻A离开临界区为止，从而允许B立即进入。最后，B离开(在时刻$T_4$)，回到了在临界区中没有进程的原始状态。

###  忙等待的互斥

本节将讨论几种实现互斥的方案。在这些方案中，当一个进程在临界区中更新共享内存时，其他进程将不会进入其临界区，也不会带来任何麻烦。

#### 屏蔽中断

在单处理器系统中，最简单的方法是使每个进程在刚刚进入临界区后立即屏蔽所有中断，并在就要离开之前再打开中断。屏蔽中断后，时钟中断也被屏蔽。CPU只有发生时钟中断或其他中断时才会进行进程切换，这样，在屏蔽中断之后CPU将不会被切换到其他进程。于是，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不必担心其他进程介入。

这个方案并不好，因为把屏蔽中断的权力交给用户进程是不明智的。设想一下，若一个进程屏蔽中断后不再打开中断，其结果将会如何?整个系统可能会因此终止。而且，如果系统是多处理器(有两个或可能更多的处理器)，则屏蔽中断仅仅对执行disable指令的那个CPU有效。其他CPU仍将继续运行，并可以访问共享内存。

另一方面，对内核来说，当它在更新变量或列表的几条指令期间将中断屏蔽是很方便的。当就绪进程队列之类的数据状态不一.致时发生中断，则将导致竞争条件。所以结论是:屏蔽中断对于操作系统本身而言是一项很有用的技术，但对于用户进程则不是一种合适的通用互斥机制。

由于多核芯片的数量越来越多，即使在低端PC上也是如此。因此，通过屏蔽中断来达到互斥的可能性一甚至在内核中 变得日 益减少了。双核现在已经相当普遍，四核当前在高端机器中存在，而且离八或十六(核)也不久远了。在一个多核系统中(例如，多处理器系统)，屏蔽一个CPU的中断不会阻止其他CPU干预第- - 个CPU所做的操作。结果是人们需要更加复杂的计划。

#### 锁变量

作为第二种尝试，可以寻找一种软件解决方案。设想有一个共享(锁)变量，其初始值为0。当一个进程想进入人其临界区时，它首先测试这把锁。如果该锁的值为0，则该进程将其设置为I并进入临界区。若这把锁的值已经为1，则该进程将等待直到其值变为0。于是，0就表示临界区内没有进程，1表示已经有某个进程进人临界区。

但是，这种想法也包含了与假脱机目录一样的疏漏。假设一个进程读出锁变量的值并发现它为0，而恰好在它将其值设置为1之前，另一个进程被调度运行，将该锁变量设置为1。当第一个进程再次运行时，它同样也将该锁设置为1，则此时同时有两个进程进入临界区中。

可能读者会想，先读出锁变量，紧接着在改变其值之前再检查-遍它的值，这样便可以解决问题。但这实际上无济于事，如果第二个进程恰好在第一个进程完成第二次检查之后修改了锁变量的值，则同样还会发生竞争条件。

#### 严格轮换法

第三种互斥的方法如图2-23所示。几乎与本书中所有其他程序一样，这里的程序段用C语言编写。之所以选择C语言是由于实际的操作系统普遍用C语言编写(或偶尔用C++)，而基本上不用像Java、Modula3或Pascal这样的语言。对于编写操作系统而言，C语言是强大、有效、可预知和有特性的语言。而对于Java，它就不是可预知的，因为它在关键时刻会用完存储器，而在不合适的时候会调用垃圾收集程序回收内存。在C语言中，这种情形就不可能发生，因为C语言中不需要进行空间回收。

在图2-23中，整型变量turn，初始值为0，用于记录轮到哪个进程进入临界区，并检查或更新共享内存。开始时，进程0检查turn，发现其值为0，于是进入临界区。进程1也发现其值为0，所以在一个等待循环中不停地测试turn，看其值何时变为1。连续测试一个变量直到某个值出现为止，称为**忙等待**(busywaiting)。由于这种方武浪费CPU时间，所以通常应该避免。只有在有理由认为等待时间是非常短的情形下，才使用忙等待。用于忙等待的锁，称为**自旋锁**(spin lock)。

![image](https://ws1.sinaimg.cn/large/69d4185bly1g30x85upboj20p0067whs.jpg)

进程0离开临界区时，它将turn的值设置为1，以便允许进程1进入其临界区。假设进程I很快便离开了临界区，则此时两个进程都处于临界区之外，turn的值又被设置为0。现在进程0很快就执行完其整个循环，它退出临界区，并将turn的值设置为1。此时，turn的值为1， 两个进程都在其临界区外执行。

突然，进程0结束了非临界区的操作并且返回到循环的开始。但是，这时它不能进入临界区，因为turn的当前值为1，而此时进程1还在忙于非临界区的操作，进程0只有继续while循环，直到进程1把turn的值改为0。这说明，在一个进程比另一个慢了很多的情况下，轮流进人临界区并不是一个好办法。

这种情况违反了前面叙述的条件3:进程0被一个临界区之外的进程阻塞。再回到前面假脱机目录的问题，如果现在将临界区与读写假脱机目录相联系，则进程0有可能因为进程1在做其他事情而被禁止打印另一个文件。

实际上，该方案要求两个进程严格地轮流进人它们的临界区，如假脱机文件等。任何一个进程都不可能在一轮中打印两个文件。尽管该算法的确避免了所有的竞争条件，但由于它违反了条件3，所以不能作为一个很好的备选方案。

#### TSL 指令

现在来看需要硬件支持的一种方案。某些计算机中，特别是那些设计为多处理器的计算机，都有下面一条指令:

```basic
TSL RX, LOCK
```

称为**测试并加锁**(test and set lock)，它将一个内存字lock读到寄存器RX中，然后在该内存地址上存一.个非零值。读字和写字操作保证是不可分割的，即该指令结束之前其他处理器均不允许访问该内存字。执行TSL指令的CPU将锁住内存总线，以禁止其他CPU在本指令结東之前访问内存。

着重说明一下，锁住存储总线不同于屏蔽中断。屏蔽中断，然后在读内存字之后跟着写操作并不能阻止总线上的第二个处理器在读操作和写操作之间访问该内存字。事实上，在处理器1上屏蔽中断对处理器2根本没有任何影响。让处理器2远离内存直到处理器1完成的唯一方法就是锁住总线， 这需要一个特殊的硬件设施(基本上，一根总线就可以确保总线由锁住它的处理器使用，而其他的处理器不能用)。

为了使用TSL指令，要使用一个共享变量lock来协调对共享内存的访问。当lock 为0时，任何进程都可以使用TSL指令将其设置为1，并读写共享内存。当操作结束时，进程用一条普通的move指令将lock的值重新设置为0。

### 睡眠与唤醒

Peterson解法和TSL或XCHG解法都是正确的，但它们都有忙等待的缺点。这些解法在本质上是这样的: 当一个进程想进入临界区时，先检查是否允许进入，若不允许，则该进程将原地等待，直到允许为止。

这种方法不仅浪费了CPU时间，而且还可能引起预想不到的结果。考虑一台计算机有两个进程，H优先级较高，L优先级较低。调度规则规定，只要H处于就绪态它就可以运行。在某时刻，L处于临界区中，此时H变到就绪态，准备运行(例如，一条I/O操作结束)。现在H开始忙等待，但由于当H就绪时L不会被调度，也就无法离开临界区，所以H将永远忙等待下去。这种情况有时被称作**优先级反转问题**(priority inversion problem)。

现在来考察几条进程间通信原语，它们在无法进入临界区时将阻塞，而不是忙等待。最简单的是sleep和wakeup。sleep是一个将引起调用进程阻塞的系统调用，即被挂起，直到另外一个进程将其唤醒。wakeup调用有一个参数，即要被唤醒的进程。另一种方法是让sleep和wakeup各有一个参数，即有一个用于匹配sleep和wakeup的内存地址。

**生产者—消费者问题**

作为使用这些原语的一个例子，我们考虑**生产者—消费者**(producer-consumer) 问题，也称作**有界缓冲区**(bounded-buffer) 问题。两个进程共享一个公共的固定大小的缓冲区。 其中一个是生产者，将信息放入缓冲区;另一个是消费者，从缓冲区中取出信息。(也可以把这个问题一般化 为m个生产者和n个消费者问题，但是这里只讨论一个生产者和一个消费者的情况，这样可以简化解决方案。)

问题在于当缓冲区已满，而此时生产者还想向其中放入一个新的数据项的情况。其解决办法是让生产者睡眠，待消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样地，当消费者试图从缓冲区中取数据而发现缓冲区为空时，消费者就睡眠，直到生产者向其中放入一些数据时再将其唤醒。

这个方法听起来很简单，但它包含与前边假脱机目录问题一.样的竞争条件。为了跟踪缓冲区中的数据项数，需要一个变量count。如果缓冲区最多存放N个数据项，则生产者代码将首先检查count是否达到N，若是，则生产者睡眠;否则生产者向缓冲区中放入一个数据项并增量count的值。

消费者的代码与此类似:首先测试count是否为0，若是，则睡眠;否则从中取走一个 数据项并递减count的值。每个进程同时也检测另一个进程是否应被唤醒，若是则唤醒之。生产者和消费者的代码如下所示。

```c
#define N 100					/*缓冲区中的槽数目*/
int count = 0;					/*缓冲区中的数据项数目*/
void producer(void)
{
	int item;					/*无限循环*/
	while (TRUE) {
		item = produce item( );	/*产生下一新数据项*/
		if (count == N) sleep();/*如果缓冲区满了，就进入休眠状态
		insert_item(item);		/*将(新)数据项放入缓冲区中*/
		count = count + 1; 		/*将缓冲区的数据项计数器增1 */
		if (count == 1) wakeup(consumer);/*缓冲区空吗? */
	}
}
void consumer(void)
{
	int item;					/*无限循环*/
	while (TRUE) {				/*如果缓冲区空，则进入休眠状态*/
		if (count == 0) sleep();/*从缓冲区中取出一个数据项*/
		item = remove_ item( );
		count = count - 1;		/*将缓冲区的数据项计数器减I*/
		if (count == N - 1) wakeup(producer); /* 缓冲区满吗? */
		consume item(item);		/*打印数据项*/
	}
}
```

现在回到竞争条件的问题。这里有可能会出现竞争条件，其原因是对count的访问未加限制。有可能出现以下情况:缓冲区为空，消费者刚刚读取count的值发现它为0。此时调度程序决定暂停消费者并启动运行生产者。生产者向缓冲区中加入一个数据项，coun加1。 现在count的值变成了1。它推断认为由于count刚才为0，所以消费者此时-定在睡眠，于是生产者调用wakeup来唤醒消费者。

但是，消费者此时在逻辑上并未睡眠，所以wakeup信号丢失。当消费者下次运行时，它将测试先前读到的count值，发现它为0，于是睡眠。生产者迟早会填满整个缓冲区，然后睡眠。这样一来，两个进程都将永远睡眠下去。

问题的实质在于发给一个(尚)未睡眠进程的wakeup信号丢失了。如果它没有丢失，则一切都很正常。一种快速的弥补方法是修改规则，加上一个唤醒等待位。当一个wakeup信号发送给一个清醒的进程信号时，将该位置1。随后，当该进程要睡眠时，如果唤醒等待位为1，则将该位清除，而该进程仍然保持清醒。喚醒等待位实际上就是wakeup信号的一个小仓库。

尽管在这个简单例子中用唤醒等待位的方法解决了问题，但是我们可以很容易就构造出一一些例子，其中有三个或更多的进程，这时一个唤醒等待位就不够使用了。于是我们可以再打一个补丁，加入第二个唤醒等待位，甚至是8个、32个等，但原则上讲，这并没有从根本上解决问题。

### 信号量 @

@TO-DO 信号量

信号量是E. W. Dijkstra在1965年提出的一种方法，它使用一个整型变量来累计唤醒次数，供以后使用。在他的建议中引入了一个新的变量类型，称作**信号量**(semaphore)。 一个信号量的取值可以为0(表示没有保存下来的唤醒操作)或者为正值(表示有一个或多个唤醒操作)。

Dijkstra建议设立两种操作: `down`和`up` (分别为一般化后的`sleep`和`wakeup`)。对- 信号量执行down操作，则是检查其值是否大于0。若该值大于0，则将其值减1 (即用掉一个保存的唤醒信号)并继续;若该值为0，则进程将睡眠，而且此时`down`操作并未结束。检查数值、修改变量值以及可能发生的睡眠操作均作为一个单的、不可分割的**原子操作**完成。保证一旦一个信号量操作开始，则在该操作完成或阻塞之前，其他进程均不允许访问该信号量。这种原子性对于解决同步问题和避免竞争条件是绝对必要的。**所谓原子操作，是指一组相关联的操作要么都不间断地执行，要么都不执行**。原子操作在计算机科学的其他领域也是非常重要的。

`up`操作对信号量的值增1。如果-一个或多个进程在该信号量上睡眠，无法完成一个先前的 `down` 操作，则由系统选择其中的一个(如随机挑选)并允许该进程完成它的`down`操作。于是，对一个有进程在其上睡眠的信号量执行- .次up操作之后，该信号量的值仍旧是0，但在其上睡眠的进程却少了一个。信号量的值增I和唤醒--个进程同样也是不可分割的。不会有某个进程因执行up而阻塞，正如在前面的模型中不会有进程因执行`wakeup`而阻塞-样。

顺便提一下，在Dijkstra原来的论文中，他分别使用名称 P 和 V 而不是 down 和 up，荷兰语中，Proberen的意思是尝试，Verhogen的含 义是增加或升高。由于对于不讲荷兰语的读者来说采用什么记号并无大的干系，所以，这里将使用down和up名称。它们在程序设计语言Algol 68中首次引入。

**用信号量解决生产者-消费者问题**

用信号量解决丢失的wakeup问题，如下代码所示。为确保信号量能正确工作，最重要的是要采用-一种不可分割的方式来实现它。通常是将up和down作为系统调用实现，而且操作系统只需在执行以下操作时暂时屏蔽全部中断:测试信号量、更新信号量以及在需要时使某个进程睡眠。由于这些动作只需要几条指令，所以屏蔽中断不会带来什么副作用。如果使用多个CPU，则每个信号量应由一个锁变量进行保护。通过TSL或XCHG指令来确保同时刻只有一个CPU在对信号量进行操作。

读者必须搞清楚，使用TSL或XCHG指令来防止几个CPU同时访问一个信号量，这与生产者或消费者使用忙等待来等待对方腾出或填充缓冲区是完全不同的。信号量操作仅需几个毫秒，而生产者或消费者则可能需要任意长的时间。

该解决方案使用了三个信号量:一个称为`full`，用来记录充满的缓冲槽数目: 一个称为`empty`，记录空的缓冲槽数目:一个称为`mutex`，用来确保生产者和消费者不会同时访问缓冲区。full的初值为0，empty的初值为缓冲区中槽的数目，mutex初值为1。供两个或多个进程使用的信号量，其初值为1,保证同时只有一个进程可以进入临界区，称作**二元信号量**(binary semaphore)。**如果每个进程在进人临界区前都执行一个down操作，并在刚刚退出时执行一个up操作，就能够实现互斥**。

代码 2-28

```c
#define N 100							 /*缓冲区中的槽数目*/
typedef int semaphore;					 /*信号量是一种特殊的整型数据*/
semaphore mutex = 1;					 /*控制对临界区的访问*/
semaphore empty = N;					 /*计数缓冲区的空槽数目*/
semaphore full = 0;						 /*计数缓冲区的满槽数目*/
void producer(void)
{
	int item;
	while (TRUE) {							 /* TRUE是常量1 */
		item = produce_item();				 /*产生放在缓冲区中的一些数据*/
		down(&empty);						 /*将空槽数目减1 */
		down(&mutex);						 /*进人临界区*/
		insert_item(item);					 /*将新数据项放到缓冲区中*/
		up(&mutex);							 /*离开临界区*/
		up(&full);							 /*将满槽的数目加1 */
	}
}
void consumer(void)
{
	int item;
	while (TRUE) {						 /*无限循环*/
		down(&full);					 /*将满槽数目减1 */
		down(&mutex);					 /*进入临界区*/
		item = remove_item();			 /*从缓冲区中取出数据项*/
		up(&mutex);						 /*离开临界区*/
		up(&empty);						 /*将空槽数目加1 */
		consume item(item);				 /*处理数据项*/
	}
}
```

![image](https://wx1.sinaimg.cn/large/69d4185bly1g2yl1j93loj20cc06sgo7.jpg)

在有了进程间通信原语之后，我们观察一下图2-5中的中断顺序。在使用信号量的系统中，隐藏中断的最自然的方法是为每个I/O设备设置-一个信号量，其初值为0。在启动一个IO设备之后，管理进程就立即对相关联的信号量执行一个down操作，于是进程立即被阻塞。当中断到来时，中断处理程序随后对相关信号量执行一个up操作，从而将相关的进程设置为就绪状态。在该模型中，图2-5中的第5步包括在设备的信号量上执行up操作，这样在第6步中，调度程序将能执行设备管理程序。当然，如果这时有几个进程就绪，则调度程序下次可以选择一个更为重要的进程来运行。本章的后续内容中，我们将看到调度算法是如何进行的。

信号量的另种用途是用于实现**同步**(synchronization)。 信号量full和empty用来保证某种事件的顺序发生或不发生。在本例中，它们保证当缓冲区满的时候生产者停止运行，以及当缓冲区空的时候消费者停止运行。这种用法与互斥是不同的。

### 互斥量

如果不需要信号量的计数能力，有时可以使用信号量的一个简化版本，称为**互斥量**(mutex)。 互斥量仅仅适用于管理共享资源或一小段代码。由于互斥量在实现时既容易又有效，这使得互斥量在实现用户空间线程包时非常有用。

互斥量是一个可以处于两态之一的变量:解锁和加锁。这样，只需要一个二进制位表示它，不过实际上，常常使用一个整型量，0表示解锁，而其他所有的值则表示加锁。互斥量使用两个过程。当一个线程(或进程)需要访问临界区时，它调用 `mutex_lock`。 如果该互斥量当前是解锁的(即临界区可用)，此调用成功，调用线程可以自由进人该临界区。另一方面，如果该互斥量已经加锁，调用线程被阻塞，直到在临界区中的线程完成并调用`mutex_unlock`。 如果多个线程波阻塞在该互斥量上，将随机选择一个线程并允许它获得锁。

#### 快速用户区互斥量 futex

随着并行的增加，有效的同步和锁机制对性能而言非常重要。如果等待时间短的话，自旋锁会很快，但如果等待时间长，则会浪费CPU周期。如果有很多竞争，那么阻塞此进程，并仅当锁被释放的时候让内核解除阻塞会更加有效。然而，这却带来了相反的问题:它在竞争激烈的情况下效果不错，但如果-开始只有很小的竞争，那么不停地内核切换将花销很大。更糟的是，预测锁竟争的数量并不容易。

一个引人注意的致力于结合两者优点的解决方案称作“futex",或者“快速用户空间互斥”。futex是Linux的一个特性，它实现了基本的锁(很像互斥锁)，但避免了陷入内核，除非它真的不得不这样做。因为来回切换到内核花销很大，所以这样做可观地改善了性能。一个futex包含两个部分:一个内核服务和一个用户库。内核服务提供一个等待队列，它允许多个进程在一个锁上等待。它们将不会运行，除非内核明确地对它们解除阻塞。将一个进程放到等待队列需要(代价很大的)系统调用，我们应该避免这种情况。因此，没有竞争时，futex完 全在用户空间工作。特别地，这些进程共享通用的锁变量——一个对齐的32位整数锁的专业术语。假设锁初始值为1，即假设这意味着锁是释放状态。线程通过执行原子操作“减少并检验”来夺取锁(Linux的原子函数包含封装在C语言函数中的内联汇编并定义在头文件中)。接下来，这个线程检查结果，看锁是否被释放。如果未处于被锁状态，那么一切顺利，我们的线程成功夺取该锁。然而，如果该锁被另一个线程持有，那么线程必须等待。这种情况下，futex库不自 旋，而是使用一个系统调用把这个线程放在内核的等待队列上。可以期望的是，切换到内核的开销已是合乎情理的了,因为无论如何线程被阻塞了。当一个线程使用完该锁，它通过原子操作“增加并检验”来释放锁, 并检查结果，看是否仍有进程阻塞在内核等待队列上。如果有，它会通知内核可以对等待队列里的一个或多个进程解除阻塞。如果没有锁竞争，内核则不需要参与其中。

#### pthread 中的互斥量

Pthread提供许多可以用来同步线程的函数。其基本机制是使用一个可以被锁定和解锁的互斥量来保护每个临界区。一个线程如果想要进入临界区，它首先尝试锁住相关的互斥量。如果互斥量没有加锁，那么这个线程可以立即进入，并且该互斥量被自动锁定以防止其他线程进入。如果互斥量已经被加锁，则调用线程被阻塞，直到该互斥量被解锁。如果多个线程在等待同一个互斥量，当它被解锁时，这些等待的线程中只有一个被允许运行并将互斥量重新锁定。这些互斥锁不是强制性的，而是由程序员来保证线程正确地使用它们。与互斥量相关的主要函数调用如图2-30所示。

除互斥量之外，pthread提供了另一种同步机制:条件变量。互斥量在允许或阻塞对临界区的访问上是很有用的，条件变量则允许线程由于一些未达到的条件而阻塞。绝大部分情况下这两种方法是一起使用的。

![image](https://ws4.sinaimg.cn/large/69d4185bgy1g32293tdxej20px07on2r.jpg)

现在让我们进一步地研究线程、 互斥量、条件变量之间的关联。干被举一个简单的例子，再次考虑一下生产者一消费者问题:一一个线程将产品放在一个缓冲区内，由另一个线程将它们取出。如果生产者发现缓冲区中没有空槽可以使用了，它不得不阻塞起来直到有一个空槽可以使用。生产者使用互斥量可以进行原子性检查，而不受其他线程干扰。但是当发现缓冲区已经满了以后，生产者需要一种方法来阻塞自已并在以后被唤醒。这便是条件变量做的事了。

条件变量与互斥量经常- -起使用。这种模式用于让一个线程锁住一个互斥量，然后当它不能获得它期待的结果时等待一个条件变量。最后另一个线程会向它发信号，使它可以继续执行。`pthread_cond_wait`原子性地调用并解锁它持有的互斥量。由于这个原因，互斥量是参数之一。

值得指出的是，条件变量(不像信号量)不会存在内存中。如果将一个信号量传递给一个没有线程在等待的条件变量，那么这个信号就会丢失。程序员必须小心使用避免丢失信号。作为如何使用一个互斥量与条件变量的例子，图2-32展示了一个非常简单只有一个缓冲区的生产者-消费者问题。当生产者填满缓冲区时，它在生产下一个数据项之前必须等待，直到消费者清空了它。类似地，当消费者移走一个数据项时，它必须等待，直到生产者生产了另外一个数据项。尽管很简单，这个例子却说明了基本的机制。使个线程睡眠的语句应该总是要检查这个条件，以保证线程在继续执行前满足条件，因为线程可能已经因为一个UNIX信号或其他原因而被唤醒。

```c
#include <stdio.h>
#include <pthread.h>
#define MAX 1000000000 /*需要生产的数量*/
pthread_mutex_t the_mutex;
pthread_cond_t condc, condp;
int buffer = 0; /*生产者消费者使用的缓冲区*/
void *producer(void *ptr) /*生产数据*/
{	
	inti;
	for (i = 1; <= MAX; i++) {
		pthread. .mutex lock(&the_mutex); /* 互斥使用缓冲区*/
		while (buffer != 0) pthread_cond_wait(&condp, &the_ mutex);
		buffer = i; /*将数据放入缓冲区*/
		pthread_cond_signal(&condc); /* 唤醒消费者 */
		pthread_mutex_unlock(&the_mutex); /*释放缓冲区*/
	}
	pthread_ exit(0);
}
void *consumer(void *ptr)/*消费数据*/
{	
  inti;
	for (i = 1; i <= MAX; i++) {
		pthread mutex lock(&the_mutex); /*互斥 使用缓冲区*/
		while (buffer == 0) pthread_cond_wait(&condc, &the_mutex);
		buffer = O; /*从缓冲区中取出数据*/
		pthread_ cond signal(&condp); /*唤醒生产者*/
		pthread _mutex Lunlock(&the_mutex); /* 释放缓冲区*/
	}
	pthread exit(0);
}
int main(int argc, char **argv)
{
	pthread_t pro, con;
	pthread_mutex_init(&the_mutex, 0);
	pthread_cond_init(&condc, 0);
	pthread_cond_init(&condp, 0);
	pthread_create(&con, O, consumer, 0);
	pthread_create(&pro, 0, producer, 0);
	pthread_join(pro, 0);
	pthread_join(con, 0);
	pthread_cond_destroy(&condc);
	pthread_cond_destroy(&condp);
	pthread_mutex_destroy(&the_mutex);
}
```

### 管程

有了信号量和互斥量之后，进程间通信看来就很容易了，实际是这样的吗?答案是否定的。请仔细考察代码2-28中向缓冲区放入数据项以及从中删除数据项之前的down操作。假设将生产者代码中的两个down操作交换一下 次序，将使得mutex的值在empty之前而不是在其之后被减1。如果缓冲区完全满了，生产者将阻塞，mutex值为0。这样一来， 当消费者下次试图访问缓冲区时，它将对mutex执行一个down操作，由于mutex值为0，则消费者也将阻塞。两个进程都将永远地阻塞下去，无法再进行有效的工作，这种不幸的状况称作**死锁**(dead lock)。指出这个问题是为了说明使用信号量时要非常小心。一处很小的错误将导致很大的麻烦。这就像用汇编语言编程一样，甚至更糟，因为这里出现的错误都是竞争条件、死锁以及其他一些不可预测和不可再现的行为。

![image](https://ws1.sinaimg.cn/large/69d4185bgy1g322qs805uj208409975q.jpg)

为了更易于编写正确的程序，Brinch Hansen (1973)和Hoare (1974) 提出了一种高级同步原语，称为管程
(monitor)。在下面的介绍中会发现，他们两人提出的方案略有不同。-一个管程是-一个由过程、变量及数据结构等组成的一个集合，它们组成一个特殊的模块或软件包。进程可在任何需要的时候调用管程中的过程，但它们不能在管程之外声明的过程中直接访问管程内的数据结构。图2-33展示了用一种抽象的、类Pascal语 言描述的管程。这里不能使用C语言，因为管程是语言概念而C语言并不支持它。

管程有一个很重要的特性，即任一时刻管程中只能有一个活跃进程，这一特性使管程能有效地完成互斥。管程是编程语言的组成部分,编译器知道它们的特殊性，因此可以采用与其他过程调用不同的方法来处理对管程的调用。典型的处理方法是，当一个进程调用管程过程时，该过程中的前几条指令将检查在管程中是否有其他的活跃进程。如果有，调用进程将被挂起，直到另一个进程离开管程将其唤醒。如果没有活跃进程在使用管程，则该调用进程可以进人。

进入管程时的互斥由编译器负责，但通常的做法是用一个互斥量或二元信号量。因为是由编译器而非程序员来安排互斥，所以出错的可能性要小得多。在任一时刻，写管程的人无须关心编译器是如何实现互斥的。他只需知道将所有的临界区转换成管程过程即可，决不会有两个进程同时执行临界区中的代码。尽管管程提供了一种实现互斥的简便途径，但这还不够，还需要种办法使得进程在无法继续运行时被阻塞。在生产者消费者问题中，很容易将针对缓冲区满和缓冲区空的测试放到管程过程中，但是生产者在发现缓冲区满的时候如何阻塞呢?

解决的方法是引入条件变量(condition variables)以及相关的两个操作: wait和signal。 当一个管程过程发现它无法继续运行时(例如，生产者发现缓冲区满)，它会在某个条件变量上(如full)执行wait操作。该操作导致调用进程自身阻塞，并且还将另一个以前等在管程之外的进程调入管程。在前面介绍pthread时我们已经看到条件变量及其操作了。

另一个进程，比如消费者，可以唤醒正在睡眠的伙伴进程，这可以通过对其伙伴正在等待的一个条件变量执行signal完成。为了避免管程中同时有两个活跃进程，我们需要一条规则来通知在signal之后该怎么办。Hoare建议让新唤醒的进程运行，而挂起另一个进程。Brinch Hansen则建议执行signal的进程必须立即退出管程，即signal语句只可能作为一个管程过程的最后一条语句。这里将采纳Brinch Hansen的建议，因为它在概念上更简单，并且更容易实现。如果在一个条件变量上有若干进程正在等待，则在对该条件变量执行signal操作后，系统调度程序只能在其中选择一个使其恢复运行。

### 屏障

最后一个同步机制是准备用于进程组而不是用于双进程的生产者消费者类情形的。在有些应用中划分了若干阶段，并且规定，除非所有的进程都就绪准备着手下一个阶段，否则任何进程都不能进入下一个阶段。可以通过在每个阶段的结尾安置**屏障**(barrier) 来实现这种行为。当一个进程到达屏障时，它就被屏障阻拦，直到所有进程都到达该屏障为止。屏障可用于一-组进程同步,屏障的操作如图2-37所示。

![image](https://wx1.sinaimg.cn/large/69d4185bgy1g3230cpb5mj20pu09f0x5.jpg)

在图2-37a中可以看到有四个进程接近屏障，这意味着它们正在运算，但是还没有到达每个阶段的结尾。过了一会儿，第一个进程完成了所有需要在第阶段进行的计算。它接着执行barrier原语，这通常是调用一个库过程。于是该进程被挂起。一会儿，第二个和第三个进程也完成了第-阶段的计算，也接着执行barrier原语。这种情形如图2-37b所示。结果，当最后一个进程C到达屏障时，所有的进程就一起被释放，如图2-37c所示。



### 避免锁：读-复制-更新

最快的锁是根本没有锁。问题在于在没有锁的情况下，我们是否允许对共享数据结构的并发读写进行访问。在通常情况下，答案显然是否定的。假设进程A正在对一个数字数组进行排序，而进程B正在计算其均值。因为A在数组中将数值前后来回移动，所以B可能多次遇到某些数值，而某些数值则根本没有遇到过。得到的结果可能是任意值，而它几乎肯定是错的。

然而，在某些情况下，我们可以允许写操作来更新数据结构，即便还有其他的进程正在使用它。窍门在于确保每个读操作要么读取旧的数据版本，要么读取新的数据版本，但绝不能是新旧数据的一些奇怪组合。举例说明，考虑图2-38中的树。读操作从根部到叶子遍历整个树。在图的上半部分，加入一个新的节点X。为了实现这一操作，我们要让这个节点在树中可见之前使它“恰好正确”:我们对节点X中的所有值进行初始化，包括它的子节点指针。然后通过原子写操作，使X成为A的子节点。所有的读操作都不会读到前后不-致的版本。在图的下半部分，我们接着移除B和D。首先，将A的左子节点指针指向C。所有原本在A中的读操作将会后续读到节点C,而永远不会读B和D。也就是说，它们将只会读到新版数据。同样，所有当前在B和D中的读操作将继续依照原始的数据结构指针并且读取旧版数据。所有操作均正确进行，我们不需要锁住任何东西。而不需要锁住数据结构就能移去B和D的主要原因就是**读-复制-更新**(Read-Copy-Update, RCU),将更新过程中的移除和再分配过程分离开来。

![image](https://wx2.sinaimg.cn/large/69d4185bgy1g323c4yan9j20ns0ky7f5.jpg)

当然，还有一个问题。只要还不能确定没有对B和D更多的读操作，我们就不能真正释放它们。但是应该等待多久呢?一分钟?或者十分钟?我们不得不等到最后一个读操作读完这些节点。RCU谨慎地决定读操作持有-个数据结构引用的最大时间。在这段时间之后，就能安全地将内存回收。特别地，读者通过读端临界区访问数据结构，它可以包含任何代码，只要该代码不阻塞或者休眠。这样的话，就知道了需要等待的最大时长。特别地，我们定义一个任意时间段的宽限期( grace period),在这个时期内，每个线程至少有一-次在读端临界区之外。如果等待至少.个宽限期的时间段后进行回收，这切就会令人满意。由于读端临界区中的代码不允许阻塞或者休眠，因此一个简单的准则就是一.直等到所有的线程执行完一次上下文切换。

## 调度

当计算机系统是多道程序设计系统时，通常就会有多个进程或线程同时竞争CPU。只要有两个或更多的进程处于就绪状态，这种情形就会发生。如果只有一个CPU可用，那么就必须选择下一个要运行的进程。在操作系统中，完成选择工作的这一部分称为**调度程序**(scheduler), 该程序使用的算法称为**调度算法**(scheduling algorithm)。

尽管有一些不同，但许多适用于进程调度的处理方法也同样适用于线程调度。当内核管理线程的时候，调度经常是按线程级别的，与线程所属的进程基本或根本没有关联。下面我们将首先关注适用于进程与线程两者的调度问题，然后会明确地介绍线程调度以及它所产生的独特问题。

### 调度简介

让我们回到早期以磁带上的卡片作为输入的批处理系统时代，那时的调度算法很简单:依次运行磁带上的每一个作业。对于多道程序设计系统，调度算法要复杂一些，因为经常有多个用户等候服务。有些大型机系统仍旧将批处理和分时服务结合使用，需要调度程序决定下一个运行的是一个批处理作业还是终端上的一个交互用户。(顺便提及，一个批处理作业可能需要连续运行多个程序，不过在本节中，假设它只是一个运行单个程序的请求。)由于在这些机器中，CPU是稀缺资源，所以好的调度程序可以在提高性能和用户的满意度方面取得很大的成果。因此，大量的研究工作都花费在创造聪明而有效的调度算法上了。

在个人计算机出现之后，整个情形向两个方面发展。首先，在多数时间内只有一个活动进程。一个用户进入文字处理软件编辑个文件时，一般不会同时在后台编译一个程序。在用户向文字处理软件键入一条命令时，调度程序不用做多少工作来判定哪个进程要运行一唯一 -的候选者 是文字处理软件。

其次，同CPU是稀缺资源时的年代相比，现在计算机速度极快。个人计算机的多数程序受到的是用户当前输入速率(键入或敲击鼠标)的限制，而不是CPU处理速率的限制。即便对于编译(这是过去CPU周期的主要消耗者)现在大多数情况下也只要花费仅仅几秒钟。甚至两个实际同时运行的程序，诸如一个文字处理软件和一个电子表单，由于用户在等待两者完成工作，因此很难说需要哪一个先完成。这样的结果是，调度程序在简单的PC上并不重要。当然，总有应用程序会实际消耗掉CPU,例如，为绘制一小时高精度视频而调整107 892帧(NTSC制)或90 000帧(PAL制)中的每一 帧颜色就需要大量工业强度的计算能力。然而，类似的应用程序不在我们的考虑范围。

对于网络服务器，情况略微有些改变。这里，多个进程经常竞争CPU，因此调度功能再一次变得至关重要。例如，当CPU必须在运行一个收集每日统计数据的进程和服务用户需求的进程之间进行选择的时候，如果后者首先占用了CPU，用户将会更高兴。

“资源充足”这个论据在很多移动设备上也不成立，比如智能手机(可能除了最先进的几款)以及传感器网络的节点。这些情况下，CPU依然薄弱，内存也偏小。此外，因为电池寿命短是这些设备最重要的约束之一，所以一些调度算法(scheduler) 在努力优化电量损耗。

另外，为了选取正确的进程运行，调度程序还要考虑CPU的利用率，因为进程切换的代价是比较高的。首先用户态必须切换到内核态;然后要保存当前进程的状态，包括在进程表中存储寄存器值以便以后重新装载。在许多系统中，内存映像( 例如，页表内的内存访问位)也必须保存;接着，通过运行调度算法选定.一个新进程;之后，应该将新进程的内存映像重新装入MMU;最后新进程开始运行。除此之外，进程切换还要使整个内存高速缓存失效，强迫缓存从内存中动态重新装人两次(进入内核一次，离开内核一次)。总之，如果每秒钟切换进程的次数太多，会耗费大量CPU时间，所以有必要提醒注意。

#### 进程行为

几乎所有进程的(磁盘或网络) I/O请求和计算都是交替突发的，如图2-39所示。典型地，CPU不停顿地运行一段时间，然后发出一个系统调用以便读写文件。在完成系统调用之后，CPU又开始计算，直到它需要读更多的数据或写更多的数据为止。请注意，某些I/O活动可以看作计算。例如，当CPU向视频RAM复制数据以更新屏幕时，因为使用了CPU，所以这是计算，而不是I/O活动。按照这种观点，当一个进程等待外部设备完成工作而被阻塞时，才是I/O活动。

![image](https://wx4.sinaimg.cn/large/69d4185bly1g3245l1cyhj20mv07ejum.jpg)

图2-39中有一件值得注意的事，即某些进程(图2-39a的进程)花费了绝大多数时间在计算上，而其他进程(图2-39b的进程)则在等待I/O上花费了绝大多数时间。前者称为**计算密集型**(compute-bound),后者称为**I/O密集型**(I/O-bound)。典型的计算密集型进程具有较长时间的CPU集中使用和较小频度的I/O等待。I/O密集型进程具有较短时间的CPU集中使用和频繁的I/O等待。它是I/O类的，因为这种进程在I/O请求之间较少进行计算，并不是因为它们有特别长的I/O请求。在I/O开始后无论处理数据是多还是少，它们都花费同样的时间提出硬件请求读取磁盘块。

有必要指出，随着CPU变得越来越快，更多的进程倾向为I/O密集型。这种现象之所以发生是因为CPU的改进比磁盘的改进快得多，其结果是，未来对I/O密集型进程的调度处理似乎更为重要。这里的基本思想是，如果需要运行I/O密集型进程，那么就应该让它尽快得到机会，以便发出磁盘请求并保持磁盘始终忙碌。

#### 何时调度

有关调度处理的一个关键问题是何时进行调度决策。存在着需要调度处理的各种情形。第一，在创建一个新进程之后，需要决定是运行父进程还是运行子进程。由于这两种进程都处于就绪状态，所以这是一种正常的调度决策，可以任意决定，也就是说，调度程序可以合法选择先运行父进程还是先运行子进程。

第二，在一个进程退出时必须做出调度决策。一-个进程不再运行(因为它不再存在)，所以必须从就绪进程集中选择另外某个进程。如果没有就绪的进程，通常会运行个系统提供的空闲进程。

第三，当一个进程阻塞在I/O和信号量上或由于其他原因阻塞时，必须选择另一个进程运行。有时,阻塞的原因会成为选择的因素。例如，如果A是一个重要的进程，并正在等待B退出临界区，让B随后运行将会使得B退出临界区，从而可以让A运行。不过问题是，通常调度程序并不拥有做出这种相关考虑的必要信息。

第四，在一个I/O中断发生时，必须做出调度决策。如果中断来自I/O设备，而该设备现在完成了工作，某些被阻塞的等待该I/O的进程就成为可运行的就绪进程了。是否让新就绪的进程运行，这取决于调度程序的决定，或者让中断发生时运行的进程继续运行，或者应该让某个其他进程运行。

如果硬件时钟提供50Hz、60Hz或其他频率的周期性中断，可以在每个时钟中断或者在每k个时钟中断时做出调度决策。根据如何处理时钟中断，可以把调度算法分为两类。**非抢占式**调度算法挑选一个进程，然后让该进程运行直至被阻塞(阻塞在I/O上或等待另一个进程)，或者直到该进程自动释放CPU。即使该进程运行了若千个小时，它也不会被强迫挂起。这样做的结果是，在时钟中断发生时不会进行调度。在处理完时钟中断后，如果没有更高优先级的进程等待到时，则被中断的进程会继续执行。

相反，**抢占式**调度算法挑选一个进程，并且让该进程运行某个固定时段的最大值。如果在该时段结束时，该进程仍在运行，它就被挂起，而调度程序挑选另一个进程运行( 如果存在一个就绪进程)。进行抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把CPU控制返回给调度程序。如果没有可用的时钟，那么非抢占式调度就是唯一的选择了。

#### 调度算法的分类

这里有必要划分出 三种环境：

1）批处理。
2）交互式。
3）实时。

批处理系统在商业领域仍在广泛应用，用来处理薪水册、存货清单、账目收入、账目支出、利息计算(在银行)、索赔处理(在保险公司和其他的周期性的作业。在批处理系统中，不会有用户不耐烦地在终端旁等待一个短请求的快捷响应。因此，非抢占式算法，或对每个进程都有长时间周期的抢占式算法，通常都是可接受的。这种处理方式减少了进程的切换从而改善了性能。这些批处理算法实际上相当普及，并经常可以应用在其他场合，这使得人们值得去学习它们，甚至是对于那些没有接触过大型机计算的人们。

在交互式用户环境中，为了避免一个进程霸占CPU拒绝为其他进程服务，抢占是必需的。即便没有进程想永远运行，但是，某个进程由于一个程序错误也可能无限期地排斥所有其他进程。为了避免这种现象发生，抢占也是必要的。服务器也归于此类，因为通常它们要服务多个突发的(远程)用户。

然而在有实时限制的系统中，抢占有时是不需要的，因为进程了解它们可能会长时间得不到运行,所以通常很快地完成各自的工作并阻塞。实时系统与交互式系统的差别是，实时系统只运行那些用来推进现有应用的程序，而交互式系统是通用的，它可以运行任意的非协作甚至是有恶意的程序。

#### 调度算法的目标

为了设计调度算法，有必要考虑什么是一个好的调度算法。某些目标取决于环境(批处理、交互式或实时)，但是还有一些目标是适用于所有情形的。在图2-40中列出了一些目标，我们将在下面逐一讨论。

![image](https://ws1.sinaimg.cn/large/69d4185bly1g324p9plrgj20c50brtcs.jpg)

在所有的情形中，公平是很重要的。相似的进程应该得到相似的服务。对一个进程给予较其他等价的进程更多的CPU时间是不公平的。当然，不同类型的进程可以采用不同方式处理。可以考虑一下在核反应堆计算机中心安全控制与发放薪水处理之间的差别。

与公平有关的是系统策略的强制执行。如果局部策略是，只要需要就必须运行安全控制进程(即便这意味着推迟30秒钟发薪)，那么调度程序就必须保证能够强制执行该策略。

另一个共同的目标是保持系统的所有部分尽可能忙碌。如果CPU和所有I/O设备能够始终运行，那么，相对于让某些部件空转而言，每秒钟就可以完成更多的工作。例如，在批处理系统中，调度程序控制哪个作业调人内存运行。在内存中既有一些CPU密集型进程又有一些I/O密集型进程是一个较好的想法，好于先调入和运行所有的CPU密集型作业，然后在它们完成之后再调入和运行所有I/O密集型作业的做法。如果使用后面一种策略，在CPU密集型进程运行时，它们就要竞争CPU,而磁盘却在空转。稍后，当I/O密集型作业来了之后，它们要为磁盘而竞争，而CPU又空转了。显然，通过仔细组合进程，可以保持整个系统运行得更好一些。

运行大量批处理作业的大型计算中心的管理者们为了掌握其系统的工作状态，通常检查三个指标:吞吐量、周转时间以及CPU利用率。**吞吐量**(throughout) 是系统每小时完成的作业数量。把所有的因素考虑进去之后，每小时完成50个作业好于每小时完成40个作业。**周转时间**(turnaround time)是指从一个批处理作业提交时刻开始直到该作业完成时刻为止的统计平均时间。该数据度量了用户要得到输出所需的平均等待时间。其规则是:小就是好的。

能够使吞吐量最大化的调度算法不一定就有最小的周转时间。例如，对于确定的短作业和长作业的一个组合，总是运行短作业而不运行长作业的调度程序，可能会获得出色的吞吐性能( 每小时大量的短作业)，但是其代价是对于长的作业周转时间很差。如果短作业以一个稳定的速率不断到达，长作业可能根本运行不了，这样平均周转时间是无限长，但是得到了高的吞吐量。

**CPU利用率**常常用于对批处理系统的度量。尽管这样，CPU利用率并不是一一个好的度量参数。真正有价值的是，系统每小时可完成多少作业(吞吐量)，以及完成作业需要多长时间(周转时间)。把CPU利用率作为度量依据，就像用引擎每小时转动了多少次来比较汽车的好坏样。另一方面，知道什么时候CPU利用率接近100%比知道什么时候要求得到更多的计算能力要有用。

对于交互式系统，则有不同的指标。最重要的是**最小响应时间**，即从发出命令到得到响应之间的时间。在有后台进程运行( 例如，从网络上读取和存储电子邮件)的个人计算机上，用户请求启动一个程序或打开一个文件应该优先于后台的工作。能够让所有的交互式请求首先运行的则是好服务。

一个相关的问题是**均衡性**。用户对做一件事情需要多长时间总是有一种固有的(不过通常不正确)看法。当认为一个请求很复杂需要较多的时间时，用户会接受这个看法，但是当认为一个请求很简单，但也需要较多的时间时，用户就会急躁。例如，如果点击一个图标花费了60秒钟发送完成- -份传真，用户大概会接受这个事实，因为他没有期望花5秒钟得到传真，他知道这需要些时间。

另一方面，当传真发送完成，用户点击断开电话连接的图标时，该用户就有不一样的期待了。如果30秒之后还没有完成断开操作，用户就可能会抱怨，而60秒之后，他就要气得要命了。之所以有这种行为，其原因是:一般用户认为拿起听筒并建立通话连接所需的时间要比挂掉电话所需的时间长。在有些情形下(如本例)，调度程序对响应时间指标起不了作用;但是在另外些情形下，调度程序还是能够做一些事的，特别是在出现差的进程顺序选择时。

实时系统有着与交互式系统不一样的特性，所以有不同的调度目标。实时系统的特点是或多或少必须满足截止时间。例如，如果计算机正在控制一个以正常速率产生数据的设备，若一个按时运行的数据收集进程出现失败，会导致数据丢失。所以，实时系统最主要的要求是满足所有的(或大多数)截止时间要求。

在多数实时系统中，特别是那些涉及多媒体的实时系统中，可预测性是很重要的。偶尔不能满足截止时间要求的问题并不严重，但是如果音频进程运行的错误太多，那么音质就会下降得很快。视频品质也是一个问题，但是人的耳朵比眼睛对抖动要敏感得多。为了避免这些问题，进程调度程序必须是高度可预测和有规律的。

### 批处理系统中的调度

有必要指出，某些算法就可以用在批处理系统中，也可以用在交互式系统中。

#### 先来先服务

在所有调度算法中，最简单的是非抢占式的**先来先服务**(first-come first-served) 算法。使用该算法，进程按照它们请求CPU的顺序使用CPU。基本上，有一个就绪进程的单- -队列。上午，当第-一个作业从外部进人系统后，就立即开始并允许运行它所期望的时间长度，该作业不会因为运行太长时间而被中断。当其他作业进入时，它们排到就绪队列尾部。当正在运行的进程被阻塞时，就绪队列中的第一个进程接着运行。当在被阻塞的进程变为就绪时，就像一个新来到的作业一样，排到就绪队列的末尾，即排在所有进程最后。

这个算法的主要优点是易于理解并且便于在程序中运用。就难以得到的体育或音乐会票的分配问题而言，这对那些愿意在早上两点就去排队的人们也是公平的。在这个算法中，一个单链表记录了所有就绪进程。要选取一个进程运行，只要从该队列的头部移走一个进程即可;要添加一个新的作业或阻塞一个进程，只要把该作业或进程附加在相应队列的末尾即可。还有比这更简单的理解和实现吗?

不过，先来先服务也有明显的缺点。假设有一个一次运行1秒钟的计算密集型进程和很少使用CPU但是每个都要进行1000次磁盘读操作才能完成的大量I/O密集型进程存在。计算密集进程运行1秒钟，接着读一个磁盘块。所有的I/O进程开始运行并读磁盘。当该计算密集进程获得其磁盘块时，它运行下一个1秒钟，紧跟随着的是所有I/O进程。

这样做的结果是，每个I/O进程在每秒钟内读到-个磁盘块，要花费1000秒钟才能完成操作。如果有一个调度算法每10ms抢占计算密集型进程，那么I/O进程将在10秒钟内完成而不是1000秒钟，而且还不会对计算密集型进程产生多少延迟。

#### 最短作业优先

现在来看一种适用于运行时间可以预知的另-个非抢占式的批处理调度算法。例如，一家保险公司，因为每天都做类似的工作，所以人们可以相当精确地预测处理1000个索赔的一批作业需要多少时间。当输入队列中有若千个同等重要的作业被启动时，调度程序应使用**最短作业优先**(shortest job first) 算法，请看图2-41。这里有4个作业A、B、C、D,运行时间分别为8、4、4、4分钟。若按图中的次序运行，则A的周转时间为8分钟，B为12分钟，C为16分钟，D为20分钟，平均为14分钟。

现在考虑使用最短作业优先算法运行这4个作业，如图2-41b所示。目前周转时间分别为4、8、12和20分钟，平均为11分钟。可以证明最短作业优先是最优的。考虑有4个作业的情况，其运行时间分别为a、b、c. d。第一个作业在时间a结束，第二个在时间a + b结束，以此类推。平均周转时间为(4a+ 3b + 2c+d) 14。 显然a对平均值影响最大，所以它应是最短作业，其次是b，再次是c，最后的d只影响它自己的周转时间。对任意数目作业的情况，道理完全一样。

![image](https://wx2.sinaimg.cn/large/69d4185bly1g325b0rh7tj20nn04ltb5.jpg)

有必要指出，只有在所有的作业都可同时运行的情形下，最短作业优先算法才是最优化的。作为一个反例，考虑5个作业，从A到E,运行时间分别是2、4、1、1和1。它们的到达时间是0、0、3、3和3。开始，只能选择A或B,因为其他三个作业还没有到达。使用最短作业优先，将按照A、B、C、D、E的顺序运行作业，其平均等待时间是4.6。但是，按照B、C、D、E、A的顺序运行作业，其平均等待时间则是4.4。

#### 最短剩余时间

最短作业优先的抢占式版本是**最短剩余时间优**先(shortest remaining time next)算法。使用这个算法，调度程序总是选择剩余运行时间最短的那个进程运行。再次提醒，有关的运行时间必须提前掌握。当一个新的作业到达时，其整个时间同当前进程的剩余时间做比较。如果新的进程比当前运行进程需要更少的时间，当前进程就被挂起，而运行新的进程。这种方式可以使新的短作业获得良好的服务。

### 交互式系统中的调度

#### 轮转调度

灯一种最古老、最简单、最公平且使用最广的算法是**轮转调度**(round robin)。每个进程被分配一个时间段，称为**时间片**(quantum), 即允许该进程在该时间段中运行。如果在时间片结束时该进程还在运行，则将剥夺CPU并分配给另一个进程。如果该进程在时间片结束前阻塞或结束，则CPU立即进行切换。时间片轮转调度很容易实现，调度程序所要做的就是维护一张可运行进程列表，如图2-42a所示。当一个进程用完它的时间片后，就被移到队列的末尾，如图2-42b所示。

![image](https://wx2.sinaimg.cn/large/69d4185bly1g325eft6pmj20l305fju2.jpg)

时间片轮转调度中唯一有 趣的一点是时间片的长度。从一个进程切换到另-一个进程是需要定时间进行管理事务处理的一一保存和装入寄存器值及内存映像、更新各种表格和列表、清除和重新调入内存高速缓存等。假如**进程切换**(process switch), 有时称为**上下文切换**(context switch)，需要1ms,包括切换内存映像、清除和重新调人高速缓存等。再假设时间片设为4ms。有了这些参数，则CPU在做完4ms有用的工作之后，CPU将花费(即浪费) 1ms来 进行进程切换。因此，CPU时间的20%浪费在管理开销上。很明显，管理时间太多了。

为了提高CPU的效率，可以将时间片设置成，比方说100ms,这样浪费的时间只有1%。但是，如果在一段非常短的时间间隔内到达50个请求，并且对CPU有不同的需求，那么，考虑下，在一个服务器系统中会发生什么呢?50个进程会放在可运行进程的列表中。如果CPU是空闲的，第一个进程会立即开始执行，第二个直到100ms以后才会启动，以此类推。假设所有其他进程都用足了它们的时间片的话，最不幸的是最后一个进程在获得运行机会之前将不得不等待5秒钟。大部分用户会认为5秒的响应对于一个短命令来说是缓慢的。如果一些在就绪队列后边的请求仅需要几毫秒的CPU时间，上面的情况会变得尤其糟糕。如果使用较短的时间片的话，它们将会获得更好的服务。

另一个因素是，如果时间片设置长于平均的CPU突发时间，那么不会经常发生抢占。相反，在时间片耗费完之前多数进程会完成一个阻塞操作，引起进程的切换。抢占的消失改善了性能，因为进程切换只会发生在确实逻辑上有需要的时候，即进程被阻塞不能够继续运行。

可以归结如下结论:时间片设得太短会导致过多的进程切换，降低了CPU效率;而设得太长又可能引起对短的交互请求的响应时间变长。将时间片设为20~50ms通常是-一个比较合理的折中。

#### 优先级调度

轮转调度做了一个隐含的假设，即所有的进程同等重要，而拥有和操作多用户计算机系统的人对此常有不同的看法。例如，在一.所大学里，等级顺序可能是教务长首先，然后是教授、秘书、后勤人员，最后是学生。这种将外部因素考虑在内的需要就导致了优先级调度。其基本思想很清楚:每个进程被赋予一个优先级,允许优先级最高的可运行进程先运行。

即使在只有一个用户的PC上，也会有多个进程，其中一些比另一些更重要。例如，与在屏幕上实时显示视频电影的进程相比，在后台发送电子邮件的守护进程应该被赋予较低的优先级。为了防止高优先级进程无休止地运行下去，调度程序可能在每个时钟滴答(即每个时钟中断)降低当前进程的优先级。如果这一行为导致该进程的优先级低于次高优先级的进程，则进行进程切换。另一种方法是，给每个进程赋予一个允许运行的最大时间片，当用完这个时间片时，次高优先级的进程便获得运行机会。

优先级可以是静态赋予或动态赋予。在一台军用计算机上，可以把将军所启动的进程设为优先级100，上校为90， 少校为80,上尉为70， 中尉为60,以此类推。或者，在一个商业计算中心，高优先级作业每小时费用为100美元，中优先级每小时75美元，低优先级每小时50美元。UNIX系统中有二条命令nice,它允许用户为了照顾别人而自愿降低自已进程的优先级，但从未有人用过它。

为达到某种目的，优先级也可以由系统动态确定。例如，有些进程为I/O密集型，其多数时间用来等待I/O结束。当这样的进程需要CPU时，应立即分配给它CPU,以便启动下一个I/O请求，这样就可以在另一个进程计算的同时执行I/O操作。使这类I/O密集型进程长时间等待CPU只会造成它无谓地长时间占用内存。使I/O密集型进程获得较好服务的一种简单算法是，将其优先级设为1/f, f为该进程在上一时间片中所占的部分。一个在其50ms的时间片中只使用1ms的进程将获得优先级50,而在阻塞之前用掉25ms的进程将具有优先级2,而使用掉全部时间片的进程将得到优先级1。

![image](https://ws2.sinaimg.cn/large/69d4185bly1g325xf1ylbj20bf06bdhj.jpg)

国快可以很方便地将一组进程按优先级分成若干类，并且在各类之间采用优先级调度，而在各类进程的内部采用轮转调度。图2-43给出了一个有4类优先级的系统，其调度算法如下:只要存在优先级为第4类的可运行进程,就按照轮转法为每个进程运行一个时间片，此时不理会较低优先级的进程。若第4类进程为空，则按照轮转法运行第3类进程。若第4类和第3类均为空，则按轮转法运行第2类进程。如果不偶尔对优先级进行调整，则低优先级进程很可能会产生饥饿现象。

#### 多级队列

CTSS (Compatible Time Sharing System)， M.L.T.在IBM 7094上开发的兼容分时系统(Corbat6 等人，1962)，是最早使用优先级调度的系统之一-。但是在CTSS中存在进程切换速度太慢的问题，其原因是IBM 7094内存中只能放进一个 进程，每次切换都需要将当前进程换出到磁盘，并从磁盘上读入一个新进程。CTSS的设计者很快便认识到，为CPU密集型进程设置较长的时间片比频繁地分给它们很短的时间片要更为高效(减少交换次数)。另一方面，如前所述，长时间片的进程又会影响到响应时间，其解决办法是设立优先级类。属于最高优先级类的进程运行-个时间片，属于次高优先级类的进程运行2个时间片，再次一级运行4个时间片，以此类推。当一个进程用完分配的时间片后，它被移到下一类。

作为一个例子，考虑有一个进程需要连续计算100个时间片。它最初被分配1个时间片，然后被换出。下次它将获得2个时间片，接下来分别是4、8、16、 32和64。当然最后一次它只使用64个时间片中的37个便可以结束工作。该进程需要7次交换(包括最初的装入)，而如果采用纯粹的轮转算法则需要100次交换。而且，随着进程优先级的不断降低，它的运行频度逐渐放慢，从而为短的交互进程让出CPU。

对于那些刚开始运行一段长时间，而后来又需要交互的进程，为了防止真永远处于被惩罚状态，可以采取下面的策略。只要终端上有回车键(Enter键) 按下，则属于该终端的所有进程就都被移到最高优先级，这样做的原因是假设此时进程即将需要交互。但可能有一天，一台CPU密集的重载机器上有几个用户偶然发现，只需坐在那里随机地每隔几秒钟敲一下回车键就可以大大提高响应时间。于是他们又告诉他们的朋友....这个故事的寓意是:在实践上可行比理论上可行要困难得多。

#### 最短进程优先

对于批处理系统而言，由于最短作业优先常常伴随着最短响应时间，所以如果能够把它用于交互进程，那将是非常好的。在某种程度上，的确可以做到这一点。交互进程通常遵循下列模式:等待命令、执行命令、等待命令、执行命令，如此不断反复。如果将每- 条命令的执行看作是一个独立的“作业”，则我们可以通过首先运行最短的作业来使响应时间最短。这里唯-的问题是如何从当前可运行进程中找出最短的那一个进程。

一种办法是根据进程过去的行为进行推测，并执行估计运行时间最短的那一个。假设某个终端上每条命令的估计运行时间为$T_0$。现在假设测量到其下一次运行时间为$T_1$。可以用这两个值的加权和来改进
估计时间，即$aT_0 + (1-a)T_1$。通过选择a的值，可以决定是尽快忘掉老的运行时间，还是在一段长时间
内始终记住它们。当a= 1/2时，可以得到如下序列: 
$$
T_0,\quad T_0/2 + T_1/2, \quad T_0/4+ T_1/4+ T_2/2, \quad T_0/8 + T_1/8 + T_2/4+ T_3/2
$$
可以看到，在三轮过后，$T_0$在新的估计值中所占的比重下降到1/8。

有时把这种通过当前测量值和先前估计值进行加权平均而得到下一个估计值的技术称作**老化**(aging)。它适用于许多预测值必须基于先前值的情况。老化算法在a= 1/2时特别容易实现，只需将新值加到当前估计值上，然后除以2 (即右移一位)。

#### 保证调度

一种完全不同的调度算法是向用户作出明确的性能保证，然后去实现它。一种很实际并很容易实现的保证是:若用户工作时有n个用户登录，则用户将获得CPU处理能力的1/n。类似地，在一个有n个进程运行的单用户系统中，若所有的进程都等价，则每个进程将获得1/n的CPU时间。看上去足够公平了。

为了实现所做的保证，系统必须跟踪各个进程自创建以来已使用了多少CPU时间。然后它计算各个进程应获得的CPU时间,即自创建以来的时间除以n。由于各个进程实际获得的CPU时间是已知的，所以很容易计算出真正获得的CPU时间和应获得的CPU时间之比。比率为0.5说明一个进程只获得了应得时间的一半，而比率为2.0则说明它获得了应得时间的2倍。于是该算法随后转向比率最低的进程，直到该进程的比率超过它的最接近竞争者为止。

#### 彩票调度

给用户一个保证，然后兑现之，这是个好想法，不过很难实现。但是，有一个既可给出类似预测结果而又有非常简单的实现方法的算法，这个算法称为彩票调度(lottery scheduling; Waldspurger和Weihl, 1994)。其基本思想是为进程提供各种系统资源( 如CPU时间)的彩票。一旦需要做出一项调度决策时，就随机抽出一张彩票，拥有该彩票的进程获得该资源。在应用到CPU调度时，系统可以掌握每秒钟50次的种彩票，作为奖励每个获奖者可以得到20ms的CPU时间。

为了说明George Orwell关于“所有进程是平等的，但是某些进程更平等一些”的含义，可以给更重要的进程额外的彩票，以便增加它们获胜的机会。如果出售了100张彩票，而有一个进程持有其中的20张，那么在每一次抽奖中该进程就有20%的取胜机会。在较长的运行中，该进程会得到20%的CPU。相反，对于优先级调度程序，很难说明拥有优先级40究竟是什么意思，而这里的规则很清楚:拥有彩票f份额的进程大约得到系统资源的f份额。

彩票调度具有若干有趣的性质。例如，如果有一个新的进程出现并得到一些彩票，那么在下一次的抽奖中，该进程会有同它持有彩票数量成比例的机会贏得奖励。换句话说，彩票调度是反应迅速的。如果希望协作进程可以交换它们的彩票。例如，有一个客户进程向服务器进程发送消息后就被阻塞，该客户进程可以把它所有的彩票交给服务器，以便增加该服务器下次运行的机会。在服务器运行完成之后，该服务器再把彩票还给客户机，这样客户机又可以运行了。事实上，如果没有客户机，服务器根本就不需要彩票。

彩票调度可以用来解决用其他方法很难解决的问题。一个例子是，有一个视频服务器，在该视频服务器上若干进程正在向其客户提供视频流，每个视频流的帧速率都不相同。假设这些进程需要的帧速率分别是10、20和25帧/秒。如果给这些进程分别分配10、20和25张彩票，那么它们会自动地按照大致正确的比例(即10 : 20: 25)划分CPU的使用。

#### 公平分享调度

 到现在为止，我们假设被调度的都是各个进程自身，并不关注其所有者是谁。这样做的结果是，如果用户1启动9个进程而用户2启动1个进程，使用轮转或相同优先级调度算法，那么用户1将得到90%的CPU时间，而用户2只得到10%的CPU时间。

为了避免这种情形，某些系统在调度处理之前考虑谁拥有进程这一因素。在这种模式中，每个用户分配到CPU时间的一部分，而调度程序以一种强制的方式选择进程。这样，如果两个用户都得到获得50% CPU时间的保证，那么无论个用户有多少进程存在，每个用户都会得到应有的CPU份额。作为一个例子，考虑有两个用户的一个系统，每个用户都保证获得50% CPU时间。用户1有4个进程A、B、C和D,而用户2只有1个进程E。如果采用轮转调度，一个满足所有限制条件的可能序列是:

```
A E B E C E D E A E B E C E D E ...
```

另一方面，如果用户1得到比用户2两倍的CPU时间，我们会有

```
A B E C D E A B E C D E ....
```

当然，大量其他的可能也存在，可以进一步探讨，这取决于如何定义公平的含义。

当然，!大量其他的可能也存在，可以进一步探讨，这取决于如何定义公平的含义。

另一方面，如果用户1得到比用户2两倍的CPU时间，我们会有
A BECDEAB ECD E ....
当然，!大量其他的可能也存在，可以进一步探讨，这取决于如何定义公平的含义。

### 策略和机制

到目前为止，我们隐含地假设系统中所有进程分属不同的用户，并且，进程间相互竞争CPU。通常情况下确实如此，但有时也有这样的情况:一个进程有许多子进程并在其控制下运行。例如，一个数据库管理系统可能有许多子进程，每一个子进程可能处理不同的请求，或每一一个子进程实现不同的功能(如请求分析，磁盘访问等)。主进程完全可能掌握哪一个子进程最重要(或最紧迫)而哪一个最不重要。但是，以上讨论的调度算法中没有-一个算法从用户进程接收有关的调度决策信息，这就导致了调度程序很少能够做出最优的选择。

解决问题的方法是将**调度机制**(scheduling mechanism)与**调度策略**(scheduling policy)分离这个一贯的原则 (Levin等人，1975)。也就是将调度算法以某种形 式参数化，而参数可以由用户进程填写。再次考虑数据库的例子。假设内核使用优先级调度算法，并提供了一条可供进程设置(并改变)优先级的系统调用。这样，尽管父进程本身并不参与调度，但它可以控制如何调度子进程的细节。在这里，调度机制位于内核，而调度策略则由用户进程决定。策略与机制分离是一种关键性思路。

### 线程调度

当若干进程都有多个线程时，就存在两个层次的并行:进程和线程。在这样的系统中调度处理有本质差别，这取决于所支持的是用户级线程还是内核级线程(或两者都支持)。

首先考虑用户级线程。由于内核并不知道有线程存在，所以内核还是和以前一样地操作，选取一个进程，假设为A,并给予A以时间片控制。A中的线程调度程序决定哪个线程运行，假设为A1。由于多道线程并不存在时钟中断，所以这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全部时间片，内核就会选择另一个进程运行。在进程A终于又一次运行时，线程A1会接着运行。该线程会继续耗费A进程的所有时间，直到它完成工作。不过，该线程的这种不合群的行为不会影响到其他的进程。其他进程会得到调度程序所分配的合适份额，不会考虑进程A内部所发生的事。

现在考虑A线程每次CPU计算的工作比较少的情况，例如，在50ms的时间片中有5ms的计算工作。于是，每个线程运行一会儿，然后把CPU交回给线程调度程序。这样在内核切换到进程B之前，就会有序列A1, A2，A3，A1, A2，A3, A1, A2，A3, A1。这种情形可用图2-44a表示。

![image](https://ws4.sinaimg.cn/large/69d4185bly1g326xq6tppj20pw0caaho.jpg)

运行时系统使用的调度算法可以是上面介绍的算法中的任意种。从实用考虑，轮转调度和优先级调度更为常用。唯一的局限是，缺乏一个时钟中断运行过长的线程，但由于线程之间的合作关系，这通常也不是问题。

现在考虑使用内核级线程的情形。内核选择-一个特定的线程运行。它不用考虑该线程属于哪个进程，不过如果有必要的话，它可以这样做。对被选择的线程赋予一个时间片，而且如果超过了时间片，就会强制挂起该线程。一个线程在50ms的时间片内，5ms之后被阻塞，在30ms的时间段中，线程的顺序会是A1, B1，A2，B2，A3，B3，在这种参数和用户线程状态下，有些情形是不可能出现的。这种情形部分通过图2-44b刻画。

用户级线程和内核级线程之间的差别在于性能。用户级线程的线程切换需要少量的机器指令，而内核级线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这导致了若干数量级的延迟。另一方面，在使用内核级线程时，一旦线程阻塞在I/O上就不需要像在用户级线程中那样将整个进程挂起。从进程A的一个线程切换到进程B的一一个线程，其代价高于运行进程A的第2个线程( 因为必须修改内存映像，清除内存高速缓存的内容)，内核对此是了解的，并可运用这些信息做出决定。例如，给定两个在其他方面同等重要的线程，其中一个线程与刚好阻塞的线程属于同一个进程，而另个线程属于其他的进程，那么应该倾向前者。

![image](https://wx3.sinaimg.cn/large/69d4185bly1g2zrhjkyjpj20d809atbr.jpg)

另一个重要因素是用户级线程可以使用专为应用程序定制的线程调度程序。例如，考虑图2-8中的Web服务器。假设一个工作线程刚刚被阻塞，而分派线程和另外两个工作线程是就绪的。那么，应该运行哪个线程呢?由于运行时系统了解所有线程的作用，所以会直接选择分派线程接着运行，这样分派线程就会启动另一个工作线程运行。在一个工作线程经常阻塞在磁盘I/O上的环境中，这个策略将并行度最大化。而在内核级线程中，内核从来不了解每个线程的作用( 虽然它们被赋予了不同的优先级)。不过，一般而言，应用定制的线程调度程序能够比内核更好地满足应用的需要。



# 内存管理

经过多年探索，人们提出了分层存储器体系(memory hierarchy)的概念，即在这个体系中，计算机有若干兆(MB) 快速、昂贵且易失性的高速缓存(cache)， 数千兆(GB)速度与价格适中且同样易失性的内存，以及几兆兆(TB) 低速、廉价、非易失性的磁盘存储，另外还有诸如DVD和USB等可移动存储装置。操作系统的工作是将这个存储体系抽象为个有用的模型并管理这个抽象模型。

操作系统中管理分层存储器体系的部分称为存储管理器(memorymanager)。它的任务是有效地管理内存，即记录哪些内存是正在使用的，哪些内存是空闲的;在进程需要时为其分配内存，在进程使用完后释放内存。

本章我们会研究几个不同的存储管理方案，涵盖非常简单的方案到高度复杂的方案。由于最底层的高速缓存的管理由硬件来完成，本章将集中介绍针对编程人员的内存模型，以及怎样优化管理内存。至于永久性存储器一磁 盘一的抽象 和管理，则是下一章的主题。我们会从最简单的管理方案开始讨论，并逐步深人到更为缜密的方案。

## 无存储器抽象

最简单的存储器抽象就是根本没有抽象。早期大型计算机(20世纪60年代之前)、小型计算机(20世纪70年代之前)和个人计算机(20世纪80年代之前)都没有存储器抽象。每一个程序都直接访问物理内存。当一个程序执行如下指令:

```basic
MOV REGISTER1, 1000
```

计算机会将位置为1000的物理内存中的内容移到REGISTER1中。因此，那时呈现给编程人员的存储器模型就是简单的物理内存:从0到某个上限的地址集合，每一个地址对应一一个可容纳定数目二进制位的存储单元，通常是8个。

在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在2000的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。

不过即使存储器模型就是物理内存，还是存在一.些可行选项的。图3-1展示了三种变体。在图3-1a中，操作系统位于RAM (随机访问存储器)的底部;在图3-16中，操作系统位于内存顶端的ROM (只读存储器)中;而在图3-1c中，设备驱动程序位于内存顶端的ROM中，而操作系统的其他部分则位于下面的RAM的底部。第-种方案以前被用在大型机和小型计算机上，现在很少使用了。第二种方案被用在一些掌上电脑和嵌入式系统中。第三种方案用于早期的个人计算机中(例如运行MS-DOS的计算机)，在ROM中的系统部分称为BIOS (Basic Input Output System,基本输入输出系统)。第一种方案和第三种方案的缺点是用户程序出现的错误可能摧毁操作系统，引发灾难性后果。

![image](https://ws1.sinaimg.cn/large/69d4185bly1g33737j5s2j20nd08378u.jpg)

