# 操作系统

## 简介

操作系统的主要任务是记录哪个程序在使用什么资源，对资源请求进行分配，评估使用代价，并且为不同的程序和用户调解互相冲突的资源请求。
资源管理包括用以下两种不同方式实现多路复用(共享)资源: 在时间上复用和在空间上复用。当一种资源在时间上复用时，不同的程序或用户轮流使用它。先是第一个获得资源的使用，然后下一个，以此类推。例如，若在系统中只有一个CPU，而多个程序需要在该CPU上运行，操作系统则首先把该CPU分配给某个程序，在它运行了足够长的时间之后，另一个程序得到CPU，然后是下一个，如此进行下去，最终，轮到第-一个程序再次运行。至于资源是如何实现时间复用的一谁应该是下一个以及运行多长时间等一-则 是操作系统的任务。还有一个有关时间复用的例子是打印机的共享。当多个打印作业在一台打印机上排队等待打印时，必须决定将轮到打印的是哪个作业。

另一类复用是空间复用。每个客户都得到资源的部分，从而取代了客户排队。例如，通常在若干运行程序之间分割内存，这样每一个运行程序都可同时人驻内存(例如，为了轮流使用CPU)。假设有足够的内存可以存放多个程序，那么在内存中同时存放若千个程序的效率，比把所有内存都分给一个程序的效率要高得多，特别是，如果一个程序只需要整个内存的一小部分，结果更是这样。当然，如此的做法会引起公平、保护等问题，这有赖于操作系统解决它们。有关空间复用的其他资源还有磁盘。在许多系统中，一个磁盘同时为许多用户保存文件。分配磁盘空间并记录谁正在使用哪个磁盘块，是操作系统的典型任务。

**多道程序设计**

若当前作业因等待磁带或其他I/O操作而暂停， CPU就只能简单地踏步直至该I/O完成。对于CPU操作密集的科学计算问题，I/O操作较少，因此浪费的时间很少。然而，对于商业数据处理，I/O操作等待的时间通常占到80%~90%，所以必须采取某种措施减少(昂贵的)CPU空闲时间的浪费。
解决方案是将内存分几个部分，每一部分存放不同的作业，如图1-5所示

![image](https://wx2.sinaimg.cn/large/69d4185bly1g2swpz9qzoj207507i3zf.jpg)

当一个作业等待I/O操作完成时，另一个作业可以使用CPU。如果内存中可以同时存放足够多的作业，则CPU利用率可以接近100%。在内存中同时驻留多个作业需要特殊的硬件来对其进行保护，以避免作业的信息被窃取或受到攻击。

## 硬件

一台机计算机的组成

![image](https://ws2.sinaimg.cn/large/69d4185bly1g2sxa1hah3j20hx09r0wh.jpg)

### 处理器

计算机的“大脑”是CPU，它从内存中取出指令并执行之。在每个CPU基本周期中，首先从内存中取出指令，解码以确定其类型和操作数，接着执行之，然后取指、解码并执行下一条指令。按照这一方式，程序被执行完成。

每个CPU都有一套可执行的专门指令集。所以，x86处理器不能执行ARM程序，而ARM处理器也不能执行x86程序。由于用来访问内存以得到指令或数据的时间要比执行指令花费的时间长得多，因此，所有的CPU内都有一些用来保存关键变量和临时数据的寄存器。这样，通常在指令集中提供一些指令，用以将一个字从内存调入寄存器，以及将-一个字从寄存器存人内存。其他的指令可以把来自寄存器、内存的操作数组合，或者用两者产生一个结果，如将两个字相加并把结果存在寄存器或内存中。

除了用来保存变量和临时结果的通用寄存器之外，多数计算机还有一些对程序员可见的专用寄存器。其中之一是**程序计数器**，它保存了将要取出的下一条指令的内存地址。在指令取出之后，程序计数器就被更新以便指向后继的指令。
另一个寄存器是**堆栈指针**，它指向内存中当前栈的顶端。该栈包含了每个执行过程的栈帧。一个过程的栈帧中保存了有关的输入参数、局部变量以及那些没有保存在寄存器中的临时变量。

当然还有**程序状态字**(Program Status Word， PSW)寄存器。这个寄存器包含了条件码位( 由比较指令设置)、CPU优先级、模式(用户态或内核态)，以及各种其他控制位。用户程序通常读入整个PSW，但是，只对其中的少量字段写人。在系统调用和I/O中，PSW的作用很重要。
操作系统必须知晓所有的寄存器。在时间多路复用(time multiplexing) CPU中，操作系统经常会中止正在运行的某个程序并启动(或再启动)另一个程序。每次停止一个运行着的程序时，操作系统必须保存所有的寄存器值，这样在稍后该程序被再次运行时，可以把这些寄存器重新装入。

------

为了改善性能，CPU设计师早就放弃了同时读取、解码和执行- 条指令的简单模型。许多现代CPU具有同时取出多条指令的机制。例如，一个CPU可以有单独的取指单元、解码单元和执行单元，于是当它执行指令n时，还可以对指令n+ 1解码，并且读取指令n + 2。这样的机制称为流水线(pipeline)， 图1-7a是一个有着三个阶段的流水线示意图。更长的流水线也是常见的。在多数的流水线设计中，一旦一条指令被取进流水线中，它就必须被执行完毕，即便前一条取出的指令是条件转移，它也必须被执行完毕。流水线使得编译器和操作系统的编写者很头疼，因为它造成了在机器中实现这些软件的复杂性问题，而机器必须处理这些问题。

![image](https://wx1.sinaimg.cn/large/69d4185bly1g2t4tmmr9zj20jl07bq5w.jpg)

比流水线更先进的设计是超标量CPU，如图1-7b所示。在这种设计中，有多个执行单元，例如，一个CPU用于整数算术运算，一个CPU用于浮点算术运算，一个CPU用于布尔运算。两个或更多的指令被同时取出、解码并装人暂存缓冲区中，直至它们执行完毕。只要有一个执行单元空闲，就检查保持缓冲区中是否还有可处理的指令，如果有，就把指令从缓冲区中移出并执行之。这种设计存在一种隐含的作用，即程序的指令经常不按顺序执行。在多数情况下，硬件负责保证这种运算的结果与顺序执行指令时的结果相同，但是，仍然有部分令人烦恼的复杂情形被强加给操作系统处理，我们在后面会讨论这种情况。

### 多线程和多核芯片

多线程允许CPU保持两个不同的线程状态，然后在纳秒级的时间尺度内来回切换。(线程是一种轻量级进程，即
一个运行中的程序)例如，如果某个进程需要从内存中读出一个字(需要花费多个时钟周期)，多线程CPU则可以切换至另一个线程。多线程不提供真正的并行处理。在一个时刻只有一个进程在运行，但是线程的切换时间则减少到纳秒数量级。

多线程对操作系统而言是有意义的，因为每个线程在操作系统看来就像是单个的CPU。考虑一个实际有两个CPU的系统，每个CPU有两个线程。这样操作系统将把它看成是4个CPU。如果在某个特定时间点上，只有能够维持两个CPU忙碌的工作量，那么在同一个CPU上调度两个线程，而让另一个CPU完全空转，就没有优势了。这种选择远远不如在每个CPU上运行一个线程的效率高。

![image](https://ws3.sinaimg.cn/large/69d4185bly1g2t51igzq4j20bu09b41l.jpg)

除了多线程，还出现了包含2个或4个完整处理器或内核的CPU芯片。图1-8中的多核芯片上有效地装有4个小芯片，每个小芯片都是一个独立的CPU(后面将解释缓存)。Intel Xeon Phi和Tilera TilePro等处理器，已经炫技般地在一枚芯片上集成了60多个核。要使用这类多核芯片肯定需要多处理器操作系统。
其实在绝对数目方面，没什么能赢过现代的GPU (Graphics Processing Unit)。 GPU指的是由成千上万个微核组成的处理器。它们擅长处理大量并行的简单计算，比如在图像应用中渲染多边形。它们不太能胜任串行任务，并且很难编程。虽然GPU对操作系统很有用(比如加密或者处理网络传输)，但操作系统本身不太可能运行在GPU上。

### 存储器

![image](https://ws3.sinaimg.cn/large/69d4185bly1g2t57s0t8tj20ek057402.jpg)

**寄存器**

存储器系统的顶层是CPU中的寄存器。它们用与CPU相同的材料制成，所以和CPU-样快。显然，访问它们是没有时延的。其典型的存储容量是，在32位CPU中为32x32位，而在64位CPU中为64 x 64位。在这两种情形下，其存储容量都小于1 KB。程序必须在软件中自行管理这些寄存器( 即决定如何使用它们)。

**高速缓存**

下一层是高速缓存，它多数由硬件控制。主存被分割成**高速缓存行**(cache line)，其典型大小为64字节，地址0至63对应高速缓存行0，地址64至127对应高速缓存行1，以此类推。最常用的高速缓存行放置在CPU内部或者非常接近CPU的高速缓存中。当某个程序需要读一个存储字时，高速缓存硬件检查所需要的高速缓存行是否在高速缓存中。如果是，称为**高速缓存命中**，缓存满足了请求，就不需要通过总线把访问请求送往主存。高速缓存命中通常需要两个时钟周期。高速缓存未命中就必须访问内存，这要付出大量的时间代价。由于高速缓存的价格昂贵，所以其大小有限。有些机器具有两级甚至三级高速缓存，每一级高速缓存比前一-级慢且容量更大。

在任何缓存系统中，都有若千需要尽快考虑的问题，包括:
1) 何时把一个新的内容放入缓存。
2 )把新内容放在缓存的哪行上。
3) 在需要时，应该把哪个内容从缓存中移走。
4) 应该把新移走的内容放在某个较大存储器的何处。
并不是每个问题的解决方案都符合每种缓存处理。对于CPU缓存中的主存缓存行，每当有缓存未命中时，就会调入新的内容。通常通过所引用内存地址的高位计算应该使用的缓存行。例如，对于64字节的4096个缓存行以及32位地址，其中6~17位用来定位缓存行，而0~ 5位则用来确定缓存行中的字节。在这个例子中，被移走内容的位置就是新数据要进入的位置，但是在有的系统中未必是这样。最后，当将一个缓存行的内容重写进主存时(该内容被缓存后，可能会被修改)，通过该地址来唯一确定需 重写的主存位置。

缓存是一种好方法，所以现代CPU中设计了两个缓存。第一级或称为**L1缓存**总是在CPU中，通常用来将已解码的指令调入CPU的执行引擎。对于那些频繁使用的数据字，多数芯片安排有第二个L1缓存。典型的L1缓存大小为16KB。另外，往往还设计有二级缓存，称为**L2缓存**，用来存放近来使用过的若千兆字节的内存字。L1和L2缓存之间的差别在于时序。对L1缓存的访问，不存在任何延时：而对L2缓存的访问，则会延时1或2个时钟周期。

**主存**

在图1-9的层次结构中，再往下一层是主存。这是存储器系统的主力。主存通常称为**随机访问存储器**(Random Access Memory， RAM)。过去有时称之为**磁芯存储器**，因为在20世纪50年代和60年代，使用很小的可磁化的铁磁体制作主存。虽然它们已经绝迹了很多年，但名称还是传承了下来。目前，存储器的容量在几百兆字节到若干吉字节之间，并且其容量正在迅速增长。所有不能在高速缓存中得到满足的访问请求都会转往主存。
除了主存之外，许多计算机已经在使用少量的非易失性随机访问存储器。它们与RAM不同，在电源切断之后，非易失性随机访问存储器并不丢失其内容。**只读存储器**(Read Only Memory， ROM)在工厂中就被编程完毕，然后再也不能被修改。ROM速度快且便宜。在有些计算机中，用于启动计算机的引导加载模块就存放在ROM中。另外，一些I/O卡也采用ROM处理底层设备控制。
**EEPROM** ( Electrically Erasable PROM，电可擦除可编程ROM)和闪存(flash memory)也是非易失性的，但是与ROM相反，它们可以擦除和重写。不过重写它们需要比写入RAM更高数量级的时间，所以它们的使用方式与ROM相同，而其与众不同的特点使它们有可能通过字段重写的方式纠正所保存程序中的错误。

**磁盘**

![image](https://ws1.sinaimg.cn/large/69d4185bly1g2t5o6l7muj20bm08iace.jpg)

下一个层次是磁盘! (硬盘)。磁盘同RAM相比，每个二进制位的成本低了两个数量级，而且经常也有两个数量级大的容量。磁盘唯一的问题是随机访问数据时间大约慢了三个数量级。其低速的原因是因为磁盘是一种机械装置，如图1-10所示。

![image](https://wx2.sinaimg.cn/large/69d4185bly1g2t5u5aycyj20et0bh0vc.jpg)

在一个磁盘中有一个或多个金属盘片，它们以5400rpm、7200rpm、 10 800rpm或更高的速度旋转。从边缘开始有一个机械臂悬横在盘面上，这类似于老式播放塑料唱片33转唱机上的拾音臂。信息写在磁盘的一系列同心上。在任意一个给定臂的位置，每个磁头可以读取一段环形区域，称为**磁道**(track)。 把一个给定臂的位置上的所有磁道合并起来，组成了一个**柱面**(cylinder)。

每个磁道划分为若千扇区，扇区的典型值是512字节。在现代磁盘中，较外部的柱面比较内部的柱 面有更多的扇区。机械臂从一个柱面移到相邻的柱面大约需要lms。而随机移到一个柱面的典型时间为 5ms至10ms，其具体时间取决于驱动器。一且磁臂到达正确的磁道上，驱动器必须等待所需的扇区旋转 到磁头之下，这就增加了5ms至10ms的时延，其具体延时取决于驱动器的转速。一日所需要的扇区移到 磁头之下，就开始读写，低端硬盘的速率是50MB/s，而高速磁盘的速率是160 MB/s。

许多计算机支持-种著名的**虚拟内存**机制，这将在第3章中讨论。这种机制使得期望运行大于物理 内存的程序成为可能，其方法是将程序放在磁盘上，而将主存作为一种缓存，用来保存最频繁使用的部! 分程序。这种机制需要快速地映像内存地址，以便把程字生成的地址转换为有关字节在RAM中的物理 地址。这种映像由CPU中的一个称为**存储器管理单元**(Memory Management Unit， MMU)的部件来完 成，如图1-6所示。 

缓存和MMU的出现对系统的性能有着重要的影响。在多道程序系统中，从一个程序切换到另一个 程序，有时称为**上下文切换**(context switch)，有必要对来自缓存的所有修改过的块进行写回磁盘操作， 并修改MMU中的映像寄存器。但是这两种操作的代价很昂贵，所以程序员努力避免使用这些操作。我们稍后将看到这些操作产生的影响。

### 总线

![image](https://wx4.sinaimg.cn/large/69d4185bly1g2u3irraomj20hj0ce43o.jpg)

图中的系统有很多总线( 例如高速缓存、内存、PCle、 PCI、USB、SATA和DMI)，每条总线的传 输速度和功能都不同。操作系统必须了解所有总线的配置和管理。其中主要的总线是PCle ( Peripheral Component Interconnect Express)总线。

Intel发明的PCIe总线是陈旧的PCI总线的继承者，而PCI总线则是为了取代原来的ISA (IndustryStandard Architecture) 总线。数十Gb/s的传输能力使得PCIe比它的前身快得多。它们在本质上也十分不同。直到发明PCIe总线的2004年，大多数总线都是并行且共享的。**共享总线架构**(shared bus architecture)表示多个设备使用一些相同的导线传输数据。因此，当多个设备同时需要发送数据时，需要仲裁器决定哪个设备可以使用总线。PCIe恰好相反，它使用分离的端到端的链路。传统PCI使用的**并行总线架构**( parallel bus architecture) 表示通过多条导线发送数据的每个字。例如，在传统的PCI总线上，一个32位数据通过32条并行的导线发送。与之相反，PCIe使用**串行总线架构**(serial busarchitecture)，通过一条被称为数据通路的链路传递集合了所有位的一条消息，这非常像网络包。这样做简单了很多，因为不用再确保所有32位在同一时刻精确地到达目的地。通过将多个数据通路并行起来，并行性仍可有效利用。例如，可以使用32个数据通路并行传输32条消息。随着网卡和图形适配器这些外围设备速度的迅速增长，PCle标准每3~5年进行一次更新。例如，PCle 2.0规格的16个数据通路提供64Gb/s的速度，升级到PCIe 3.0后会提速2倍，而PCIe 4.0会再提速2倍。

在图中，CPU通过DDR3总线与内存对话，通过PCIe总线与外围图形设备对话，通过**DMI** (Direct Media Interface)总线经集成中心与所有其他设备对话。而集成中心通过通用串行总线与USB设备对话，通过SATA总线与硬盘和DVD驱动器对话，通过PCIe传输以太网络帧。我们已经提到过使用传统PCI总线的旧的PCI设备。



## 操作系统概念

### 进程

在所有操作系统中，一个重要的概念是**进程(process)**。 进程本质上是正在执行的一个程序。与每 个进程相关的是**地址空间(**address space)，这是从某个最小值的存储位置(通常是零)到某个最大值的 存储位置的列表。在这个地址空间中，进程可以进行读写。该地址空间中存放有可执行程序、程序的数 据以及程序的堆栈。与每个进程相关的还有资源集，通常包括寄存器(含有程序计数器和堆栈指针)、 打开文件的清单、突出的报警、有关进程清单，以及运行该程序所需要的所有其他信息。进程基本上是 容纳运行一个程序所需要所有信息的容器。

进程的概念将在第2章详细讨论，不过，对进程建立一种直观感觉的最便利方式是分析一一个多道程序设计系统。用户启动一个视频编辑程序，指示它按照某个格式转换小时的视频(有时会花费数小时)，然后离开去浏览网页。同时，一个被周期性唤醒、用来检查进来的电子邮件的后台进程会开始运行。这样，我们就有了(至少)三个活动进程:视频编辑器、Web浏览器以及电子邮件接收程序。操作系统周期性地挂起一个进程然后启动运行另一个进程，这可能是由于在过去的一两秒钟内，第一个进程已使用完分配给它的时间片。

一个进程暂时被挂起后，在随后的某个时刻里，该进程再次启动时的状态必须与先前暂停时完全相同，这就意味着在挂起时该进程的所有信息都要保存下来。例如，为了同时读入信息，进程打开了若干文件。与每个被打开文件有关的是指向当前位置的指针(即下一个将读出的字节或记录)。在一个进程暂时被挂起时，所有这些指针都必须保存起来，这样在该进程重新启动之后，所执行的读调用才能读到正确的数据。在许多操作系统中，与一个进程有关的所有信息，除了该进程自身地址空间的内容以外，均存放在操作系统的一张表中，称为**进程表**(process table)， 进程表是数组(或链表)结构，当前存在的每个进程都要占用其中一项。

与进程管理有关的最关键的系统调用是那些进行进程创建和进程终止的系统调用。考虑一个典型的例子。有一个称为**命令解释器**(command interpreter) 或 **shell** 的进程从终端上读命令。此时，用户刚键入一条命令要求编译一个程序。shell必须先创建一个新进程来执行编译程序。当执行编译的进程结束时，它执行一一个系统调用来终止自己。

![image](https://ws3.sinaimg.cn/large/69d4185bly1g2u5xed2v9j20a106q0u7.jpg)

若一个进程能够创建一个或多个进程(称为**子进程**)，而且这些进程又可以创建子进程，则很容易得到进程树，如图1-13所示。合作完成某些作业的相关进程经常需要彼此通信以便同步它们的行为。这种通信称为**进程间通信**(interprocess communication)，将在第2章中详细讨论。其他可用的进程系统调用包括:申请更多的内存(或释放不再需要的内存)、等待一个子进程结束、用另一个程序覆盖该程序等。



### 地址空间

每台计算机都有一些主存，用来保存正在执行的程序。在非常简单的操作系统中，内存中一次只能有一个程序。如果要运行第二个程序，第一个程序就必须被移出内存，再把第二个程序装入内存。

较复杂的操作系统允许在内存中同时运行多道程序。为了避免它们互相干扰(包括操作系统)，需要有某种保护机制。虽然这种机制必然是硬件形式的，但是由操作系统掌控。
上述的观点涉及对计算机主存的管理和保护。另种不同但是同样重要并与存储器有关的内容，是管理进程的地址空间。<u>通常，每个进程有一些可以使用的地址集合，典型值从0开始直到某个最大值。在最简单的情形下，一个进程可拥有的最大地址空间小于主存。在这种方式下，进程可以用满其地址空间，而且内存中也有足够的空间容纳该进程</u>。
但是，在许多32位或64位地址的计算机中，分别有 $2^{32}$ 或 $2^{64}$ 字节的地址空间。如果一个进程有比计算机拥有的主存还大的地址空间，而且该进程希望使用全部的内存，那怎么办呢?在早期的计算机中，这个进程只好“认命”了。<u>现在，有了一种称为虚拟内存的技术，正如前面已经介绍过的，操作系统可以把部分地址空间装人主存，部分留在磁盘上，并且在需要时来回交换它们。在本质上，操作系统创建了一个地址空间的抽象，作为进程可以引用地址的集合。该地址空间与机器的物理内存解耦，可能大于也可能小于该物理空间</u>。对地址空间和物理空间的管理组成了操作系统功能的一一个重要部分，整个第3章都与这个主题有关。



### 文件

实际上，支持操作系统的另一个关键概念是文件系统。如前所述，操作系统的一项主要功能是隐藏磁盘和其他I/O设备的细节特性，给提供程序员一个良好、清晰的独立于设备的抽象文件模型。显然，创建文件、删除文件、读文件和写文件等都需要系统调用。在文件可以读取之前，必须先在磁盘上定位和打开文件，在文件读过之后应该关闭该文件，有关的系统调用则用于完成这类操作。

为了提供保存文件的地方，大多数操作系统支持**目录**(directory)的概念，从而可把文件分类成组。比如，学生可给所选的每个课程创建一个目录(用于保存该课程所需的程序)，另设一个目录存放电子邮件，再有一个目录用于保存万维网主页。这就需要系统调用创建和删除目录、将已有的文件放入目录中、从目录中删除文件等。目录项可以是文件或者目录，这样就产生了层次结构一文件 系统，如图1-14所示。

![image](https://wx1.sinaimg.cn/large/69d4185bly1g2vg53bxdlj20jr0efdlz.jpg)

进程和文件层次都可以组织成树状结构，但这两种树状结构有不少不同之处。一般进程的树状结构层次不深(很少超过三层)，而文件树状结构的层次常常多达四层、五层或更多层。进程树层次结构是暂时的，通常最多存在几分钟，而目录层次则可能存在数年之久。进程和文件在所有权及保护方面也是有区别的。典型地，只有父进程能控制和访问子进程，而在文件和目录中通常存在一种机制，使文件所有者之外的其他用户也可以访问该文件。

UNIX中的另一个重要概念是安装文件系统。大多数台式机都有一个或多个光盘驱动器，可以插入CD-ROM、DVD和蓝光光盘。它们几乎都有USB接口，可以插入USB存储棒(实际是固态磁盘驱动器)。为了提供一个出色的方式处理可移动介质，UNIX允许把光盘上的文件系统接到主文件树上。考虑图1-15a的情形。在mount调用之前，根文件系统在硬盘上，而第二个文件系统在CD-ROM上，它们是分离且无关的。

![image](https://ws2.sinaimg.cn/large/69d4185bly1g2vgbrmcy4j20lp072dj9.jpg)

然而，不能使用CD-ROM上的文件系统，因为上面没有可指定的路径。UNIX不允许在路径前面加上驱动器名称或代码，那样做就完全成了设备相关类型了，这是操作系统应该消除的。代替的方法是，mount系统调用允许把在CD-ROM上的文件系统连接到程序所希望的根文件系统上。在图1-15b中，CD-ROM上的文件系统安装到了目录b上，这样就允许访问文件/b/x以及/b/y。如果CD-ROM已安装好，但目录b中有任何不能访问的文件，则是因为/b指向了CD-ROM的根目录。(在开始时，不能访问这些文件似乎并不是一个严重问题:文件系统几乎总是安装在空目录上。)如果系统有多个硬盘，它们可以都安装在单个树上。

在UNIX中，另一个重要的概念是**特殊文件**(special file)。 提供特殊文件是为了使I/O设备看起来像文件一般。这样，就像使用系统调用读写文件一样，I/O设备也可通过同样的系统调用进行读写。有两类特殊文件:**块特殊文件**(block special file)和**字符特殊文件**(character special file)。块特殊文件指那些由可随机存取的块组成的设备，如磁盘等。比如打开一个块特殊文件，然后读第4块，程序可以直接访问设备的第4块而不必考虑存放该文件的文件系统结构。类似地，字符特殊文件用于打印机、调制解调器和其他接收或输出字符流的设备。按照惯例，特殊文件保存在/dev目录中。例如，/dev/p是打印机(曾经称为行式打印机)。

![image](https://ws3.sinaimg.cn/large/69d4185bly1g2vgjqoxgkj207y03qjrz.jpg)

本小节中 讨论的最后一个特性既与进程有关也与文件有关:管道。管道(pipe) 是一种虚文件，它可连接两个进程，如图1-16所示。如果进程A和B希望通过管道对话，它们必须提前设置该管道。当进程A想对进程B发送数据时，它把数据写到管道上，仿佛管道就是输出文件一样。进程B可以通过读该管道而得到数据，仿佛该管道就是一一个输入文件一样。这样，在UNIX中两个进程之间的通信就非常类似于普通文件的读写了。更为强大的是，若进程想发现它所写入的输出文件不是真正的文件而是管道，则需要使用特殊的系统调用。

## 系统调用

记住下列事项是有益的。任何单CPU计算机-次只能执行.条指令。如果一个进程正在用户态运行一一个用户程序，并且需要一个系统服务，比如从一个文件读数据，那么它就必须执行.个陷阱或系统调用指令，将控制转移到操作系统。操作系统接着通过参数检查找出所需要的调用进程。然后，它执行系统调用，并把控制返回给在系统调用后面跟随着的指令。在某种意义上，进行系统调用就像进行一个特殊的过程调用，但是只有系统调用可以进人内核，而过程调用则不能。
为了使系统调用机制更清晰，我们简要地考察read系统调用。如上所述，它有三个参数:第一个参数指定文件，第二个指向缓冲区，第三个说明要读出的字节数。几乎与所有的系统调用样， 它的调用由C程序完成，方法是调用一个与该系统调用名称相同的库过程: read。 由C程序进行的调用形式如下:

```c
count = read(fd， buffer， nbytes)；
```

系统调用(以及库过程)在count中返回实际读出的字节数。这个值通常和nbytes相同，但也可能更小，例如，如果在读过程中遇到了文件尾的情形就是如此。

如果系统调用不能执行，不论是因为无效的参数还是磁盘错误，count都会被置为-1，而在全局变量errno中放入错误号。程序应该经常检查系统调用的结果，以了解是否出错。
系统调用是通过一系列的步骤实现的。为了更清楚地说明这个概念，考察上面的read调用。在准备调用这个实际用来进行read系统调用的read库过程时，调用程序首先把参数压进堆栈，如图1-17中步骤1~步骤3所示。

![image](https://ws4.sinaimg.cn/large/69d4185bly1g2vh7zi3n7j20hk0gbq9k.jpg)

### 用于进程管理的系统调用

![image](https://wx1.sinaimg.cn/large/69d4185bly1g2waa06zlcj208e07ydhb.jpg)

发在UNIX中的进程将其存储空间划分为三段:**正文段**(如程序代码)、**数据段**(如变量)以及**堆栈段**。数据向上增长而堆栈向下增长，如图1-20所示。夹在中间的是未使用的地址空间。堆栈在需要时自动地向中间增长，不过数据段的扩展是显式地通过系统调用brk进行的，在数据段扩充后，该系统调用指定-一个新地址。但是，这个调用不是POSIX标准中定义的，对于存储器的动态分配，鼓励程序员使用malloc库过程，而malloc的内部实现则不是一个适合标准化的主题，因为几乎没有程序员直接使用它，我们有理由怀疑是否会有人注意到brk实际不是属于POSIX的。



# 进程与线程

进程是操作系统提供的最古老的也是最重要的抽象概念之-。即使可以使用的CPU只有一个，但它们也具有支持(伪)并发操作的能力，它们将一个单独的CPU变换成多个虚拟的CPU。没有进程的抽象，现代计算将不复存在。

## 进程

所有现代的计算机经常会在同一时间做许多件事。习惯于在个人计算机上工作的人们也许不会十分注意这个事实，因此列举-.些例子可以更清楚地说明这一问题。先考虑:一个网络服务器，一些网页请求从各处进入。当一个请求进入时，服务器检查其需要的网页是否在缓存中。如果是，则把网页发送回去；如果不是，则启动一个磁盘请求以获取网页。然而，从CPU的角度来看，磁盘请求需要漫长的时间。当等待磁盘请求完成时，其他更多的请求将会进入。如果有多个磁盘存在，可以在满足第一个请求之前就接二连三地对其他的磁盘发出部分或全部请求。很明显，需要一些方法去模拟并控制这种并发。进程(特别是线程)在这里就可以发挥作用。

在任何多道程序设计系统中，CPU由一个进程快速切换至另-个进程，使每个进程各运行几十或几百毫秒。严格地说，在某一个瞬间，CPU只能运行一个进程。但在1秒钟内，它可能运行多个进程，这样就产生并行的错觉。有时人们所说的**伪并行**就是指这种情形，以此来区分**多处理器系统**(该系统有两个或多个CPU共享同一个物理内存)的真正硬件并行。人们很难对多个并行活动进行跟踪，因此，经过多年的努力，操作系统的设计者开发了用于描述并行的一种概念模型(顺序进程)，使得并行更容易处理。



### 进程模型

在进程模型中， 计算机上所有可运行的软件，通常也包括操作 系统，被组织成若干**顺序进程**(sequential process)，简称**进程**(process)。 一个进程就是-个正在执行程序的实例，包括程序计数器、寄存器和变量的当前值。从概念上说，每个进程拥有它自己的虚拟CPU。当然，实际上真正的CPU在各进程之间来回切换。但为了理解这种系统，考虑在(伪)并行情况下运行的进程集，要比试图跟踪CPU如何在程序间来回切换简单得多。正如在第1章所看到的，这种快速的切换称作**多道程序设计**。

![image-20190510224911328](/Users/weduoo/Library/Application Support/typora-user-images/image-20190510224911328.png)

在图2-1a中可以看到，在一台多道程序计算机的内存中有4道程序。在图2-1b中，这4道程序被抽象为4个各自拥有自已控制流程(即每个程序自己的逻辑程序计数器)的进程，并且每个程序都独立地运行。当然，实际上只有一个物理程序计数器，所以在每个程序运行时，它的逻辑程序计数器被装人实际的程序计数器中。当该程序执行结束(或暂停执行)时，物理程序计数器被保存在内存中该进程的逻辑程序计数器中。在图2-1c中可以看到，在观察足够长的一段时间后，所有的进程都运行了，但在任何一个给定的瞬间仅有一个进程真正在运行。

由于CPU在各进程之间来回快速切换，所以每个进程执行其运算的速度是不确定的。而且当同一进程再次运行时，其运算速度通常也不可再现。所以，在对进程编程时决不能对时序做任何想当然的假设。例如，考虑一个I/O进程，它用流式磁带机恢复备份的文件，它执行一个10000次的空循环以等待磁带机达到正常速度，然后发出命令读取第一个记录。如果CPU决定在空循环期间切换到其他进程，则磁带机进程可能在第一条记录通过磁头之后还未被再次运行。当一个进程具有此类严格的实时要求时，也就是一些特定事件一定要在所指定的若于毫秒内发生，那么必须采取特殊措施以保证它们一定在这段时间中发生。然而，通常大多数进程并不受CPU多道程字设计或其他进程相对速度的影响。

------

进程和程序间的区别是很微妙的，但非常重要。用一个比喻可以更容易理解这一点。想象一位有一手好厨艺的计算机科学家正在为他的女儿烘制生日蛋糕。他有做生日蛋糕的食谱，厨房里有所需的原料:面粉、鸡蛋、糖、香草汁等。在这个比喻中，做蛋糕的食谱就是程序(即用适当形式描述的算法)，计算机科学家就是处理器(CPU)， 而做蛋糕的各种原料就是输人数据。进程就是厨师阅读食谱、取来各种原料以及烘制蛋糕等-系列动作的总和。
现在假设计算机科学家的儿子哭着跑了进来，说他的头被一只蜜蜂蛰了。计算机科学家就记录下他照着食谱做到哪儿了(保存进程的当前状态)，然后拿出一本急救手册，按照其中的指示处理蛰伤。这里，处理机从一一个进程(做蛋糕)切换到另一个高优先级的进程(实施医疗救治)，每个进程拥有各自的程序(食谱和急救手册)。当蜜蜂蛰伤处理完之后，这位计算机科学家又回来做蛋糕，从他离开时的那一步继续做下去。
这里的关键思想是:一个进程是某种类型的个活动，它有程序、输入、输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另一个进程提供服务。
值得注意的是，如果一个程序运行了两遍，则算作两个进程。例如，人们可能经常两次启动同一个字处理软件，或在有两个可用的打印机的情况下同时打印两个文件。像“两个进程恰好运行同一个程序”这样的事实其实无关紧要，因为它们是不同的进程。操作系统能够使它们共享代码，因此只有一个副本放在内存中，但那只是一个技术性的细节，不会改变有两个进程正在运行的概念。

### 进程创建

4种主要事件会导致进程的创建:
1)系统初始化。
2)正在运行的程序执行了创建进程的系统调用。
3)用户请求创建一个新进程。
4)一个批处理作业的初始化。

启动操作系统时，通常会创建若千个进程。其中有些是前台进程，也就是同用户(人类)交互并且替他们完成工作的那些进程。其他的是后台进程，这些进程与特定的用户没有关系，相反，却具有某些专门的功能。例如，设计一个后台进程来接收发来的电子邮件，这个进程在一天的大 部分时间都在睡眠，但是当电子邮件到达时就突然被唤醒了。也可以设计另一个后台进程来接收对该机器中Web页面的访问请求，在请求到达时唤醒该进程以便服务该请求。停留在后台处理诸如电子邮件、Web页面、新闻、打印之类活动的进程称为**守护进程**(daemon)。 在大型系统中通常有很多守护进程。在UNIX日中，可以用ps程序列出正在运行的进程；在Windows中，可使用任务管理器。

在UNIX和Windows中，进程创建之后，父进程和子进程有各自不同的地址空间。如果其中某个进程在其地址空间中修改了一个字，这个修改对其他进程而言是不可见的。在UNIX中，子进程的初始地址空间是父进程的-一个副本，但是这里涉及两个不同的地址空间，不可写的内存区是共享的。某些UNIX的实现使程序正文在两者间共享，因为它不能被修改。或者，子进程共享父进程的所有内存，但这种情况下内存通过写时复制(copy-on-write) 共享，这意味着一旦两者之一想要修改部分内存，则这块内存首先被明确地复制，以确保修改发生在私有内存区域。再次强调，可写的内存是不可以共享的。但是，对于一个新创建的进程而言，确实有可能共享其创建者的其他资源，诸如打开的文件等。在Windows中，从一开始父进程的地址空间和子进程的地址空间就是不同的。

### 进程的终止

引起终止的几个条件：

1)正常退出(自愿的)。
2)出错退出(自愿的)。
3)严重错误(非自愿)。
4)被其他进程杀死(非自愿)。

进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所致。例如，执行了一条非法指令、引用不存在的内存，或除数是零等。有些系统中(如UNIX)， 进程可以通知操作系统，它希望自行处理某些类型的错误，在这类错误中，进程会收到信号(被中断)，而不是在这类错误出现时终止。

第四种终止进程的原因是，某个进程执行一个系统调用通知操作系统杀死某个其他进程。在UNIX中，这个系统调用是ill在Win32中对应的函数是TerminateProcess。在这两种情形中，“杀手”都必须获得确定的授权以便进行动作。在有些系统中，当一个进程终止时，不论是自愿的还是其他原因，由该进程所创建的所有进程也- -律立即被杀死。不过，UNIX和Windows都不是这种工作方式。

### 进程的层次结构

某些系统中，当进程创建了另一个进程后，父进程和子进程就以某种形式继续保持关联。子进程自身可以创建更多的进程，组成一个进程的层次结构。请注意，这与植物和动物的有性繁殖不同，进程只有一个父进程(但是可以有零个、一一个、两个或多个子进程)。

在UNIX中，进程和它的所有子进程以及后裔共同组成一个进程组。当用户从键盘发出一个信号时，该信号被送给当前与键盘相关的进程组中的所有成员(它们通常是在当前窗口创建的所有活动进程)。每个进程可以分别捕获该信号.忽略该信号或采取默认的动作，即被该信号杀死。

这里有另一个例子，可以用来说明进程层次的作用，考虑UNIX在启动时如何初始化自己。一个称为init的特殊进程出现在启动映像中。当它开始运行时，读入一个说明终端数量的文件。接着，为每个终端创建一个新进程。这些进程等待用户登录。如果有一一个用户登录成功，该登录进程就执行一个shell准备接收命令。所接收的这些命令会启动更多的进程，以此类推。这样，在整个系统中，所有的进程都属于以init为根的一棵树。

相反，Windows中没有进程层次的概念，所有的进程都是地位相同的。唯一类似于进程层次的暗示是在创建进程的时候，父进程得到一个特别的令牌(称为句柄)，该句柄可以用来控制子进程。但是，它有权把这个令牌传送给某个其他进程，这样就不存在进程层次了。在UNIX中，进程就不能剥夺其子继承的“继承权”。

### 进程的状态

尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间经常需要相互作用。一个进程的输出结果可能作为另一个进程的输人。在shell命令

```bash
cat chapter1 chapter2 chapter3 | grep tree
```

中，第一个进程运行cat，将三个文件连接并输出。第二个进程运行grep，它从输人中选择所有包含单词"tree”的那些行。根据这两个进程的相对速度(这取决于这两个程序的相对复杂度和各自所分配到的CPU时间)，可能发生这种情况: grep准备就绪可以运行，但输入还没有完成。于是必须阻塞grep， 直到输入到来。

当一个进程在逻辑上不能继续运行时，它就会被阻塞，典型的例子是它在等待可以使用的输入。还可能有这样的情况:一个概念上能够运行的进程被迫停止，因为操作系统调度另一个进程占用了CPU。这两种情况是完全不同的。在第一种情况下，进程挂起是程序自身固有的原因(在键入用户命令行之前，无法执行命令)。第二种情况则是由系统技术上的原因引起的(由于没有足够的CPU，所以不能使每个进程都有一台私用的处理器)。在图2-2中 可以看到显示进程的三种状态的状态图，这三种状态是:

![image](https://wx3.sinaimg.cn/large/69d4185bly1g2xqx0jm2tj20ej071jtv.jpg)

1) 运行态(该时刻进程实际占用CPU)。

2) 就绪态(可运行，但因为其他进程正在运行而暂时停止)。

3) 阻塞态(除非某种外部事件发 生，否则进程不能运行)。

转换2和3是由进程调度程序引起的，进程调度程序是操作系统的一部分，进程甚至感觉不到调度程序的存在。系统认为一个运行进程占用处理器的时间已经过长，决定让其他进程使用CPU时间时，会发生转换2。在系统已经让所有其他进程享有了它们应有的公平待遇而重新轮到第一个进程再次占用CPU运行时，会发生转换3。调度程序的主要工作就是决定应当运行哪个进程、何时运行及它应该运行多长时间，这是很重要的一点，我们将在本章的后面部分进行讨论。目前已经提出了许多算法，这些算法力图在整体效率和进程的竞争公平性之间取得平衡。我们将在本章稍后部分研究其中的一些问题。

当进程等待的一个外部事件发生时(如一-些输入到达)，则发生转换4。如果此时没有其他进程运行，则该进程将处于就绪态，等待CPU空闲并则该进程将处于就绪态，等待CPU空闲并且轮到它运行。

从这个观点引出了图2-3所示的模型。在图2-3中，操作系统的最底层是调度程序，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中。实际上，调度程序是一段非常短小的程序。操作系统的其他部分被简单地组织成进程的形式。不过，很少有真实的系统是以这样的理想方式构造的。

![image](https://wx3.sinaimg.cn/large/69d4185bly1g2xr34pfyzj20ev070wgr.jpg)



### 进程的实现

[cnblogs - 中断和中断处理程序](https://www.cnblogs.com/frankyou/p/8649435.html)

[Interrupts， Exceptions， and System Calls]([http://www.cse.iitm.ac.in/~chester/courses/15o_os/slides/5_Interrupts.pdf](http://www.cse.iitm.ac.in/~chester/courses/15o_os/slides/5_Interrupts.pdf))

为了实现进程模型，操作系统维护着一张表格(一个结构数组)，即**进程表**(process table)。每个进程占用一个进程表项。(有些作者称这些表项为**进程控制块**。)该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。

图2-4中展示了在一个典型系统中的关键字段。第一列中的字段与进程管理有关。其他两列分别与存储管理和文件管理有关。应该注意到进程表中的字段是与系统密切相关的，不过该图给出了所需要信息的大致介绍。

![image](https://wx2.sinaimg.cn/large/69d4185bly1g2xrh3d3rcj20h80bs43h.jpg)

在了解进程表后，就可以对在单个(或每一个) CPU上如何维持多个顺序进程的错觉做更多的阐述。与每一I/O类关联的是一个称作**中断向量**(interrupt vector)的位置(靠近内存底部的固定区域)。它包含中断服务程序的人口地址。假设当一个磁盘中断发生时，用户进程3正在运行，则中断硬件将程序计数器、程序状态字、有时还有一个或多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的地址。这些是硬件完成的所有操作，然后软件，特别是中断服务例程就接管一切剩余的工作。

> **什么是中断？**简单地说就是CPU在忙着作自己的事情，这时候硬件（比如说键盘按了一下）触发了一个电信号，这个信号**通过中断线**到达**中断控制器i8259A，i8259A**接受到这个信号后，向**CPU**发送**INT信号**申请CPU来执行刚才的硬件操作，并且将**中断类型号**也发给CPU，此时CPU保存当前正在做的事情（**REST指令**把程序计数器**PC**中的下一条待执行的指令的内存地址保存到**栈**）的情景现场，然后去处理这个申请，根据**中断类型号**找到它的**中断向量**（**即中断程序在内存中的地址**），然后去执行这段程序（这段程序已经写好，在内存中），执行完后再向i8259A发送一个**INTA**信号表示其已经处理完刚才的申请。此时CPU就可以继续做它刚才被打断做的事情了，将刚才保存的情景现场恢复出来，CPU继续执行接下来下面的程序。
>
> ——《cnblogs - 中断和中断处理程序》

所有的中断都从保存寄存器开始，对于当前进程而言，通常是保存在进程表项中。随后，会从堆栈中刪除由中断硬件机制存人堆栈的那部分信息，并将堆栈指针指向一个由进程处理程序所使用的临时堆栈。一些诸如保存寄存器值和设置堆栈指针等操作，无法用C语言这一类高级语言描述，所以这些操作通过一个短小的汇编语言例程来完成，通常该例程可以供所有的中断使用，因为无论中断是怎样引起的，有关保存寄存器的工作则是完全一样的。

![image](https://wx1.sinaimg.cn/large/69d4185bly1g2yl1j93loj20cc06sgo7.jpg)

当该例程结束后，它调用一个C过程处理某个特定的中断类型剩下的工作。(假定操作系统由C语言编写，通常这是所有真实操作系统的选择)。在完成有关工作之后，大概就会使某些进程就绪，接着调用调度程序，决定随后该运行哪个进程。随后将控制转给一段汇编语言代码，为当前的进程装入寄存器值以及内存映射并启动该进程运行。图2-5中总结了中断处理和调度的过程。值得注意的是，各种系统之间某些细节会有所不同。

### 多道程序设计模型

采用多道程序设计可以提高CPU的利用率。严格地说，如果进程用于计算的平均时间是进程在内存中停留时间的20%，且内存中同时有5个进程，则CPU将一直满负载运行。然而，这个模型在现实中过于乐观，因为它假设这5个进程不会同时等待I/O。

更好的模型是从概率的角度来看CPU的利用率。假设一个进程等待I/O操作的时间与其停留在内存中时间的比为p。当内存中同时有n个进程时，则所有n个进程都在等待I/O(此时CPU空转)的概率是$p^n$。CPU的利用率由下面的公式给出:
$$
CPU利用率= 1-p^n
$$
![image](https://wx4.sinaimg.cn/large/69d4185bly1g2yl74l33lj20e609q0vg.jpg)

图2-6以n为变量的函数表示了CPU的利用率，n 称为**多道程序设计的道数**(degree of multiprogramming)。

从图2-6中可以清楚地看到，如果进程花费80%的时间等待I/O，为使CPU的浪费低于10%，至少要有10个进程同时在内存中。当读者认识到一个等待用户从终端输入的交互式进程是处于IO等待状态时，那么很明显，80%甚至更多的I/O等待时间是普遍的。即使是在服务器中，做大量磁盘I/O操作的进程也会花费同样或更多的等待时间。

从完全精确的角度考虑，应该指出此概率模型只是描述了一个大致的状况。它假设所有n个进程是独立的，即内存中的5个进程中，3个运行，2个等待，是完全可接受的。但在单CPU中，不能同时运行3个进程，所以当CPU忙时，已就绪的进程也必须等待CPU。因而，进程不是独立的。更精确的模型应该用排队论构建，但我们的模型(当进程就绪时，给进程分配CPU，否则让CPU空转)仍然是有效的，即使真实曲线会与图2-6中所画的略有不同。

虽然图2-6的模型很简单、很粗略，它依然对预测CPU的性能很有效。例如，假设计算机有8GB内存，操作系统及相关表格占用2GB，每个用户程序也占用2GB。这些内存空间允许3个用户程序同时驻留在内存中。若80%的时间用于I/O等待，则CPU的利用率(忽略操作系统开销)大约是1-0.8，即大约49%。在增加8GB字节的内存后，可从3道程序设计提高到7道程序设计，因而CPU利用率提高到79%。换言之，第二个8GB内存提高了30%的吞吐量。

增加第三个8GB内存只能将CPU利用率从79%提高到91%，吞吐量的提高仅为12%。通过这一模型，计算机用户可以确定，第一次增加内存是一个划算的投资，而第二个则不是。

## 线程

在传统操作系统中，每个进程有一个地址空间和一个控制线程。事实上，这几乎就是进程的定义。不过，经常存在在同一个地址空间中准并行运行多个控制线程的情形，这些线程就像(差不多)分离的进程(共享地址空间除外)。

### 线程的使用

为什么人们需要在一个进程中再有一类进程?有若千理由说明产生这些迷你进程(称为线程)的必要性。下面我们来讨论其中一些理由。人们需要多线程的主要原因是，在许多应用中同时发生着多种活动。其中某些活动随着时间的推移会被阻塞。通过将这些应用程序分解成可以准并行运行的多个顺序线程，程序设计模型会变得更简单。

前面已经进行了有关讨论。准确地说，这正是之前关于进程模型的讨论。有了这样的抽象，我们才不必考虑中断、定时器和上下文切换，而只需考察并行进程。类似地，只是在有了多线程概念之后，我们才加入了一种新的元素:并行实体拥有共享同一个地址空间和所有可用数据的能力。对于某些应用而言，这种能力是必需的，而这正是多进程模型(它们具有不同的地址空间)所无法表达的。

第二个关于需要多线程的理由是，由于线程比进程更轻量级，所以它们比进程更容易(即更快)创建，也更容易撤销。在许多系统中，创建一个线程较创建一个进程要快10~100倍。在有大量线程需要动态和快速修改时，具有这一特性是很有用的。

需要多线程的第三个原因涉及性能方面的讨论。若多个线程都是CPU密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的I/O处理，拥有多个线程允许这些活动彼此重叠进行，从而会加快应用程序执行的速度。

最后，在多CPU系统中，多线程是有益的，在这样的系统中，真正的并行有了实现的可能。

------

通过考察一些典型例子，我们可以更清楚地看出引入多线程的好处。作为第一个例子，考虑一个字处理软件。字处理软件通常按照出现在打印页上的格式在屏幕上精确显示文档。特别地，所有的行分隔符和页分隔符都在正确的最终位置上，这样在需要时用户可以检查和修改文档(比如，消除孤行一在一页上不完整的顶部行和底部行，因为这些行不甚美观)。

假设用户正在写一本书。从作者的观点来看，最容易的方法是把整本书作为一个文件，这样一来，查询内容、完成全局替换等都非常容易。另一种方法是，把每一章都处理成单独一个文件。但是，在把每个小节和子小节都分成单个的文件之后，若必须对全书进行全局的修改时，那就真是麻烦了，因为有成百个文件必须一个个地编辑。例如，如果所建议的某个标准x x x x正好在书付印之前被批准了，于是“标准草案xx x x”一类的字眼就必须改为“标准xx x x”。如果整本书是一个文件，那么只要一个命令就可以完成全部的替换处理。相反，如果一本书分成了300个文件，那么就必须分别对每个文件进行编辑。

现在考虑，如果有一一个用户突然在一个有800页的文件的第页上删掉了一个语句之后，会发生什么情形。在检查了所修改的页面并确认正确后，这个用户现在打算接着在第600页上进行另-个修改，并键人一条命令通知字处理软件转到该页面(可能要查阅只在那里出现的一个短语)。于是字处理软件被强制对整本书的前600页重新进行格式处理，这是因为在排列该页前面的所有页面之前，字处理软件并不知道第600页的第一行应该在哪里。而在第600页的页面可以真正在屏幕上显示出来之前，计算机可能要拖延相当一段时间，从而令用户不甚满意。

多线程在这里可以发挥作用。假设字处理软件被编写成含有两个线程的程序。一个线程与用户交互，而另一个在后台重新进行格式处理。一旦在第1页中的语句被删除掉，交互线程就立即通知格式化线程对整本书重新进行处理。同时，交互线程继续监控键盘和鼠标，并响应诸如滚动第1页之类的简单命令，此刻，另一个线程正在后台疯狂地运算。如果有点运气的话，重新格式化会在用户请求查看第600页之前完成，这样，第600页页面就立即可以在屏幕上显示出来。

如果已经做到了这一步，那么为什么不再进一步增加个线程呢?许多字处理软件都有每隔若千分钟自动在磁盘上保存整个文件的特点，用于避免由于程序崩溃、系统崩溃或电源故障而造成用户整天的工作丢失的情况。第三个线程可以处理磁盘备份，而不必干扰其他两个线程。拥有三个线程的情形，如图2-7所示。

![image](https://ws2.sinaimg.cn/large/69d4185bly1g2yn1l1ulsj20hx0agq6o.jpg)

如果程序是单线程的，那么在进行磁盘备份时，来自键盘和鼠标的命令就会被忽略，直到备份工作完成为止。用户当然会认为性能很差。另一个方法是，为了获得好的性能，可以让键盘和鼠标事件中断磁盘备份，但这样却引入了复杂的中断驱动程序设计模型。如果使用三个线程，程序设计模型就很简单了。第一个线程只是和用户交互:第二个线程在得到通知时进行文档的重新格式化:第三个线程周期性地将RAM中的内容写到磁盘上。

很显然，在这里用三个不同的进程是不能工作的，这是因为三个线程都需要对同一个文件进行操作。由于多个线程可以共享公共内存，所以通过用三个线程替换三个进程，使得它们可以访问同一个正在编辑的文件，而三个进程是做不到的。

------

现在考虑另一个多线程发挥作用的例子:一个万维网服务器。对页面的请求发给服务器，而所请求的页面发回给客户机。在多数Web站点上，某些页面较其他页面相比，有更多的访问。例如，对Sony主页的访问就远远超过对深藏在页面树里的任何特定摄像机的技术说明书页面的访问。利用这一事实，Web服务器可以把获得大量访问的页面集合保存在内存中，避免到磁盘去调入这些页面，从而改善性能。这样的一-种页面集合称为**高速缓存**(cache)， 高速缓存也运用在其他许多场合中。例如在第1章中介绍的CPU缓存。

![image](https://wx3.sinaimg.cn/large/69d4185bly1g2zrhjkyjpj20d809atbr.jpg)

一种组织Web服务器的方式如图2-8所示。在这里，一个称为**分派程序**(dispatcher) 的线程从网络中读入工作请求。在检查请求之后，分派线程挑选一个空转的(即被阻塞的)**工作线程**(worker thread)，提交该请求，通常是在每个线程所配有的某个专门字中写人一个消息指针。接着分派线程唤醒睡眠的工作线程，将它从阻塞状态转为就绪状态。

在工作线程被唤醒之后，它检查有关的请求是否在Web页面高速缓存之中，这个高速缓存是所有线程都可以访问的。如果没有，该线程开始一个从磁盘调入页面的read操作，并且阻塞直到该磁盘操作完成。当上述线程阻塞在磁盘操作上时，为了完成更多的工作，分派线程可能挑选另一个线程运行，也可能把另一个当前就绪的工作线程投人运行。

现在考虑在没有多线程的情形下，如何编写Web服务器。一种可能的方式是，使其像一个线程- -样运行。Web服务器的主循环获得请求，检查请求，并且在取下一个请求之前完成整个工作。在等待磁盘操作时，服务器就空转，并且不处理任何到来的其他请求。如果该Web服务器运行在唯一的机器上，通常情形都是这样，那么在等待磁盘操作时CPU只能空转。结果导致每秒钟只有很少的请求被处理。可见线程较好地改善了Web服务器的性能，而且每个线程是按通常方式顺序编程的。

到现在为止，我们有了两个可能的设计方案:多线程Web服务器和单线程Web服务器。假设没有多线程可用，而系统设计者又认为由于单线程所造成的性能降低是不能接受的，那么如果可以使用**read**系统调用的非阻塞版本，还存在第三种可能的设计。在请求到来时，这个唯一的线程对请求进行考察。如果该请求能够在高速缓存中得到满足，那么一切都好，如果不能，则启动一个非阻塞的磁盘操作。
服务器在表格中记录当前请求的状态，然后去处理下一个事件。下一个事件可能是-一个新工作的请求，或是磁对先前操作的回答。如果是新工作的请求，就开始该工作。如果是磁盘的回答，就从表格中取出对应的信息，并处理该回答。对于非阻塞磁盘I/O而言，这种回答多数会以信号或中断的形式出现。
在这一设计中，前面两个例子中的“顺序进程”模型消失了。每次服务器从为某个请求工作的状态切换到另一个状态时，都必须显式地保存或重新装人相应的计算状态。事实上，我们以一种困难的方式模拟了线程及其堆栈。这里，每个计算都有一个被保存的状态，存在一个会发生且使得相关状态发生改变的事件集合，我们把这类设计称为**有限状态机**(finite-state machine)。有限状态机这一概念广 泛地应用在计算机科学中。

现在很清楚多线程必须提供的是什么了。多线程使得顺序进程的思想得以保留下来，这种顺序进程阻塞了系统调用( 如磁盘I/O)，但是仍旧实现了并行性。对系统调用进行阻塞使程序设计变的较为简单，而且并行性改善了性能。单线程服务器虽然保留了阻塞系统调用的简易性，但是却放弃了性能。第三种处理方法运用了非阻塞调用和中断，通过并行性实现了高性能，但是给编程增加了困难。在图2-10中给出了上述模式的总结。

![image](https://ws2.sinaimg.cn/large/69d4185bly1g2zrozpjucj20g104itah.jpg)

有关多线程作用的第三个例子是那些必须处理极大量数据的应用。通常的处理方式是，读进一块数据，对其处理，然后再写出数据。这里的问题是，如果只能使用阻塞系统调用，那么在数据进人和数据输出时，会阻塞进程。在有大量计算需要处理的时候，让CPU空转显然是浪费，应该尽可能避免。
多线程提供了一种解决方案，有关的进程可以用一个输入线程、-.个处理线程和-个输出线程构造。输入线程把数据读人到输人缓冲区中；处理线程从输入缓冲区中取出数据，处理数据，并把结果放到输出缓冲区中:输出线程把这些结果写到磁盘上。按照这种工作方式，输入、处理和输出可以全部同时进行。当然，这种模型只有当系统调用只阻塞调用线程而不是阻塞整个进程时，才能正常工作。

### 经典的线程模型

既然已经清楚为什么线程会有用以及如何使用它们，不如让我们用更进一步的眼光来审查一下上面的想法。进程模型基于两种独立的概念:资源分组处理与执行。有时，将这两种概念分开会更好，这就引人了“线程”这一概念。下面先介绍经典的线程模型；之后我们会来研究“模糊进程与线程分界线”的Linux线程模型。

理解进程的一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。这些资源中包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把它们都放到进程中可以更容易管理。
另一个概念是，进程拥有一个执行的线程，通常简写为**线程**(thread)。 在线程中有一个程序计数器，用来记录接着要执行哪一条指令。线程拥有寄存器，用来保存线程当前的工作变量。线程还拥有一个堆栈，用来记录执行历史，其中每一帧保存了一个已调用的但是还没有从中返回的过程。尽管线程必须在某个进程中执行，但是线程和它的进程是不同的概念，并且可以分别处理。进程用于把资源集中到一起，而线程则是在CPU上被调度执行的实体。

线程给进程模型增加了一项内容，即在同一个进程环境中，允许彼此之间有较大独立性的多个线程执行。在同一个进程中并行运行多个线程，是对在同一台计算机上并行运行多个进程的模拟。在前一种情形下，多个线程共享同一个地址空间和其他资源。而在后一种情形中，多个进程共享物理内存、磁盘、打印机和其他资源。由于线程具有进程的某些性质，所以有时被称为**轻量级进程**(lightweight process)。**多线程**这个术语，也用来描述在同一个进程中允许多个线程的情形。正如在第1章中看到的，一些CPU已经有直接硬件支持多线程，并允许线程切换在纳秒级完成。

在图2-11a中，可以看到三个传统的进程。每个进程有自己的地址空间和单个控制线程。相反，在图2-11b中，可以看到一个进程带有三个控制线程。尽管在两种情形中都有三个线程，但是在图2-11a中，每一个线程都在不同的地址空间中运行，而在图2-11b中，这三个线程全部在相同的地址空间中运行。
当多线程进程在单CPU系统中运行时，线程轮流运行。从图2-1中，我们已经看到了进程的多道程序设计是如何工作的。通过在多个进程之间来回切换，系统制造了不同的顺序进程并行运行的假象。多线程的工作方式也是类似的。CPU在线程之间的快速切换，制造了线程并行运行的假象，好似它们在一个比实际CPU慢一-些的CPU上同时运行。在个有三个计算密集型线程的进程中，线程以并行方式运行，每个线程在一个CPU上得到了真实CPU速度的三分之一。

![image](https://wx4.sinaimg.cn/large/69d4185bly1g2zs02g39gj20ht08f77k.jpg)

进程中的不同线程不像不同进程之间那样存在很大的独立性。所有的线程都有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于各个线程都可以访问进程地址空间中的每-一个内存地址，所以一个线程可以读、写或甚至清除另一个线程的堆栈。线程之间是没有保护的，原因是: 1)不可能，2)也没有必要。这与不同进程是有差别的。不同的进程会来自不同的用户，它们彼此之间可能有敌意，一个进程总是由某个用户所拥有，该用户创建多个线程应该是为了它们之间的合作而不是彼此间争斗。除了共享地址空间之外，所有线程还共享同一个打开文件集、子进程、定时器以及相关信号等，如图2-12所示。这样，对于三个没有关系的线程而言，应该使用图2-11a的结构，而在三个线程实际完成同一个作业，并彼此积极密切合作的情形中，图2-11b则比较合适。

![image](https://ws2.sinaimg.cn/large/69d4185bly1g2zs35l2smj20nf06fwi1.jpg)

图2-12中，第一列表项是进程的属性，而不是线程的属性。例如，如果一个线程打开了一个文件，该文件对该进程中的其他线程都可见，这些线程可以对该文件进行读写。由于资源管理的单位是进程而非线程，所以这种情形是合理的。如果每个线程有其自己的地址空间、打开文件、即将发生的定时器等，那么它们就应该是不同的进程了。<u>线程概念试图实现的是，共享一组资源的多个线程的执行能力，以便这些线程可以为完成某一任务而共同工作</u>。

和传统进程一样(即只有一个线程的进程)，线程可以处于若干种状态的任何一个:运行、阻塞、就绪或终止。正在运行的线程拥有CPU并且是活跃的。被阻塞的线程正在等待某个释放它的事件。例如，当一个线程执行从键盘读入数据的系统调用时，该线程就被阻塞直到键入了输人为止。线程可以被阻塞，以便等待某个外部事件的发生或者等待其他线程来释放它。就绪线程可被调度运行，并且只要轮到它就很快可以运行。线程状态之间的转换和进程状态之间的转换是一样的，如图2-2所示。

![image](https://wx4.sinaimg.cn/large/69d4185bly1g2zs9n7gkzj20cf09dq4y.jpg)

认识到每个线程有其自己的堆栈很重要，如图2-13所示。每个线程的堆栈有一帧，供各个被调用但是还没有从中返回的过程使用。在该栈帧中存放了相应过程的局部变量以及过程调用完成之后使用的返回地址。例如，如果过程X调用过程Y，而Y又调用Z，那么当Z执行时，供X、Y和Z使用的栈帧会全部存在堆栈中。通常每个线程会调用不同的过程，从而有一个各自不同的执行历史，这就是为什么每个线程需要有自己的堆栈的原因。

------

通常而言，线程是有益的，但是线程也在程序设计模式中引入了某种程度的复杂性。考虑一下UNIX中的fork系统调用。如果父进程有多个线程，那么它的子进程也应该拥有这些线程吗?如果不是，则该子进程可能会工作不正常，因为在该子进程中的线程都是绝对必要的。

然而，如果子进程拥有了与父进程一样的多个线程，如果父进程在read系统调用(比如键盘)上 被阻塞了会发生什么情况?是两个线程被阻塞在键盘上(一个属于父进程，另一个属于子进程)吗?在键入一行输入之后，这两个线程都得到该输人的副本吗?还是仅有父进程得到该输人的副本?或是仅有子进程得到?类似的问题在进行网络连接时也会出现。

另一类问题和线程共享许多数据结构的事实有关。如果-一个线程关闭了某个文件，而另一个线程还在该文件上进行读操作时会怎样?假设有一个线程注意到几乎没有内存了，并开始分配更多的内存。在工作一半的时候，发生线程切换，新线程也注意到几乎没有内存了，并且也开始分配更多的内存。这样，内存可能会被分配两次。不过这些问题通过努力是可以解决的。总之，要使多线程的程序正确工作，就需要仔细思考和设计。

### POSIX 线程

为实现可移植的线程程序，IEEE在IEEE标准1003.1c中定义了线程的标准。它定义的线程包叫作**pthread**。 大部分UNIX系统都支持该标准。城2所有pthread线程都有某些特性。每一个都含有一个标识符、一组寄存器(包括程序计数器)和一组存储在结构中的属性。这些属性包括堆栈大小、调度参数以及其他线程需要的项目。

![image](https://wx4.sinaimg.cn/large/69d4185bly1g2zsu9eoxyj20kw07kwie.jpg)

创建一个新线程需要使用pthread\_create调用。新创建的线程的线程标识符会作为函数值返回。这种调用有意看起来很像fork系统调用，其中线程标识符起着PID的作用，而这么做的目的主要是为了标识在其他调用中引用的线程。

当一个线程完成分配给它的工作时，可以通过调用pthread\_exit来终止。这个调用终止该线程并释放它的栈。

一般一个线程在继续运行前需要等待另一个线程完成它的工作并退出。可以通过pthread\_join线程调用来等待别的特定线程的终止。而要等待线程的线程标识符作为一个参数给出。

有时会出现这种情况:一个线程逻辑上没有阻塞，但感觉上它已经运行了足够长时间并且希望给另外一个线程机会去运行。这时可以通过调用pthread\_yield完成这一目标。而进程中没有这种调用，因为假设进程间会有激烈的竞争性，并且每--个进程都希望获得它所能得到的所有的CPU时间。但是，由于同一进程中的线程可以同时工作，并且它们的代码总是由同一个程序员编写的，因此，有时程序员希望它们能互相给对方一些机会去运行。
下面两个线程调用是处理属性的。pthread\_attr\_init建 立关联一个线程的属性结构并初始化成默认值。这些值(例如优先级)可以通过修改属性结构中的城值来改变。
最后，pthread\_attr\_destroy 刪除一个线程的属性结构，释放它占用的内存。它不会影响调用它的线程。这些线程会继续存在。

### 在用户空间实现线程

[为什么CPU需要时钟才能工作？](https://www.zhihu.com/question/21981280)



有两种主要的方法实现线程包:在用户空间中和在内核中。这两种方法互有利弊，不过混合实现方式也是可能的。我们现在介绍这些方法，并分析它们的优点和缺点。
第一种方法是把整个线程包放在用户空间中，内核对线程包一无所知。从内核角度考虑，就是按正常的方式管理，即单线程进程。*这种方法第一个也是最明显的优点是，用户级线程包可以在不支持线程的操作系统上实现。过去所有的操作系统都属于这个范围，即使现在也有一些操作系统还是不支持线程*。

所有的这类实现都有同样的通用结构，如图2-16a所示。 线程在一一个运行时系统的上层运行，该运行时系统是一个管理线程的过程的集合。前面已经介绍过其中的四个过程: pthread\_create， pthrea\_ exit， pthread\_join和pthread\_yield。 不过，一般还会有更多的过程。

![image](https://wx2.sinaimg.cn/large/69d4185bly1g2zt4tcdoij20jd0bln2u.jpg)

在用户空间管理线程时，每个进程需要有其专用的**线程表**(threadtable)，用来跟踪该进程中的线程。这些表和内核中的进程表类似，不过它仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态等。该线程表由运行时系统管理。当- 一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程所需的信息，与内核在进程表中存放进程的信息完全一样。

当某个线程做了一些会引起在本地阻塞的事情之后，例如，等待进程中另一个线程完成某项工作，它调用一个运行时系统的过程，这个过程检查该线程是否必须进人阻塞状态。如果是，它在线程表中保存该线程的寄存器(即它本身的)，查看表中可运行的就绪线程，并把新线程的保存值重新装入机器的寄存器中。只要堆栈指针和程序计数器一被切换，新的线程就又自动投入运行。如果机器有一条保存所有寄存器的指令和另-条装入全部寄存器的指令，那么整个线程的切换可以在几条指令内完成。进行类似于这样的线程切换至少比陷入内核要快一个数量级(或许更多)，这是使用用户级线程包的极大的优点。

不过，线程与进程有一个关键的差别。I在线程完成运行时，例如，在它调用`thread_yield`时 ，`pthread_yield`代码可以把该线程的信息保存在线程表中，进而，它可以调用线程调度程序来选择另一个要运行的线程。保存该线程状态的过程和调度程序都只是本地过程，所以启动它们比进行内核调用效率更高。另一方面，不需要陷入内核，不需要上下文切换，也不需要对内存高速缓存进行刷新，这就使得线程调度非常快捷。

用户级线程还有另一个优点。它允许每个进程有自己定制的调度算法。例如，在某些应用程序中，那些有垃圾收集线程的应用程序就不用担心线程会在不合适的时刻停止，这是一个长处。用户级线程还具有较好的可扩展性，这是因为在内核空间中内核线程需要一些固定表格空间和堆栈空间，如果内核线程的数量非常大，就会出现问题。

------

尽管用户级线程包有更好的性能，但它也存在一些明显的问题。其中第:个问题是如何实现阻塞系统调用。假设在还没有任何击键之前，-一个线程读取键盘。让该线程实际进行该系统调用是不可接受的，因为这会停止所有的线程。使用线程的一个主要目标是，首先要允许每个线程使用阻塞调用，但是还要避免被阻塞的线程影响其他的线程。有了阻塞系统调用，这个目标不是轻易地能够实现的。
系统调用可以全部改成非阻塞的(例如，如果没有被缓冲的字符，对键盘的read操作可以只返回0字节)，但是这需要修改操作系统，所以这个办法也不吸引人。而且，用户级线程的一个长处就是它可以在现有的操作系统上运行。另外，改变read操作的语义需要修改许多用户程序。
在这个过程中，还有一种可能的替代方案，就是如果某个调用会阻塞，就提前通知。在某些UNIX版本中，有一个系统调用select可以允许调用者通知预期的read是否会阻塞。若有这个调用，那么库过程read就可以被新的操作替代，首先进行select调用，然后只有在安全的情形下(即不会阻塞)才进行read调用。如果read调用会被阻塞，有关的调用就不进行，代之以运行另一个线程。到了下次有关的运行系统取得控制权之后，就可以再次检查看看现在进行read调用是否安全。这个处理方法需要重写部分系统调用库，所以效率不高也不优雅，不过没有其他的可选方案了。在系统调用周围从事检查的这类代码称为**包装器**(jacket或wrapper)。

与阻塞系统调用问题有些类似的是缺页中断问题，我们将在第3章讨论这些问题。此刻可以认为，把计算机设置成这样一种工作方式，即并不是所有的程序都一次性放在内存中。如果某个程序调用或者跳转到了一条不在内存的指令上，就会发生页面故障，而操作系统将到磁盘上取回这个丢失的指令(和该指令的“邻居们")，这就称为页面故障。在对所需的指令进行定位和读入时，相关的进程就被阻塞。如果有一个线程引起页面故障，内核由于甚至不知道有线程存在，通常会把整个进程阻塞直到磁盘I/O完成为止，尽管其他的线程是可以运行的。

用户级线程包的另一个问题是，如果一个线程开始运行，那么在该进程中的其他线程就不能运行，除非第一个线程自动放弃CPU。在一个单独的进程内部，没有时钟中断，所以不可能用轮转调度(轮流)的方式调度线程。除非某个线程能够按照自己的意志进入运行时系统，否则调度程序就没有任何机会。

对线程永久运行问题的一个可能的解决方案是让运行时系统请求每秒次的时钟信号(中断)，但是这样对程序也是生硬和无序的。不可能总是高频率地发生周期性的时钟中断，即使可能，总的开销也是可观的。而且，线程可能也需要时钟中断，这就会扰乱运行时系统使用的时钟。

再者，也许针对用户级线程的最大负面争论意见是，程序员通常在经常发生线程阻塞的应用中才希望使用多个线程。例如，在多线程Web服务器里。这些线程持续地进行系统调用，而一旦发生内核陷阱进行系统调用，如果原有的线程已经阻塞，就很难让内核进行线程的切换，如果要让内核消除这种情形，就要持续进行select系统调用，以便检查read系统调用是否安全。对于那些基本上是CPU密集型而且极少有阻塞的应用程序而言，使用多线程的目的又何在呢?由于这样的做法并不能得到任何益处，所以没有人会真正提出使用多线程来计算前n个素数或者下象棋等一类工作。

### 在内核实现线程

![image](https://wx2.sinaimg.cn/large/69d4185bly1g2zt4tcdoij20jd0bln2u.jpg)

现在考虑内核支持和管理线程的情形。如图2-16b所示，此时不再需要运行时系统了。另外，每个进程中也没有线程表。相反，在内核中有用来记录系统中所有线程的线程表。当某个线程希望创建一个新线程或撤销一个已有线程时，它进行一个系统调用，这个系统调用通过对线程表的更新完成线程创建或撤销工作。

内核的线程表保存了每个线程的寄存器、状态和其他信息。这些信息和在用户空间中(在运行时系统中)的线程是一样的，但是现在保存在内核中。这些信息是传统内核所维护的每个单线程进程信息(即进程状态)的子集。另外，内核还维护了传统的进程表，以便跟踪进程的状态。

所有能够阻塞线程的调用都以系统调用的形式实现，这与运行时系统过程相比，代价是相当可观的。当一个线程阻塞时，内核根据其选择，可以运行同一个进程中的另一个线程(若有一个就绪线程)或者运行另一个进程中的线程。而在用户级线程中，运行时系统始终运行自己进程中的线程，直到内核剥夺它的CPU (或者没有可运行的线程存在了)为止。

由于在内核中创建或撤销线程的代价比较大，某些系统采取“环保”的处理方式，回收其线程。当某个线程被撤销时，就把它标志为不可运行的，但是其内核数据结构没有受到影响。稍后，在必须创建一个新线程时，就重新启动某个旧线程，从而节省了一些开销。在用户级线程中线程回收也是可能的，但是由于其线程管理的代价很小，所以没有必要进行这项工作。

内核线程不需要任何新的、非阻塞系统调用。另外，如果某个进程中的线程引起了页面故障，内核可以很方便地检查该进程是否有任何其他可运行的线程，如果有，在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行。这样做的主要缺点是系统调用的代价比较大，所以如果线程的操作(创建、终止等)比较多，就会带来很大的开销。

虽然使用内核线程可以解决很多问题，但是也不会解决所有的问题。例如，当一个多线程进程创建新的进程时，会发生什么?新进程是拥有与原进程相同数量的线程，还是只有一个线程?在很多情况下，最好的选择取决于进程计划下步做什么。如果它要调用exec来启动一个新的程序，或许一个线程是正确的选择；但是如果它继续执行，则最好复制所有的线程。

另一个话题是信号。回忆一下，信号是发给进程而不是线程的，至少在经典模型中是这样的。当一个信号到达时，应该由哪一个线程处理它?线程可以“注册”它们感兴趣的某些信号，因此当一个信号到达的时候，可把它交给需要它的线程。但是如果两个或更多的线程注册了相同的信号，会发生什么?这只是线程引起的问题中的两个，但是还有更多的问题。

### 混合实现

人们已经研究了各种试图将用户级线程的优点和内核级线程的优点结合起来的方法。-种方法是使用内核级线程，然后将用户级线程与某些或者全部内核线程多路复用起来，如图2-17所示。如果采用这种方法，编程人员可以决定有多少个内核级线程和多少个用户级线程彼此多路复用。这一模型带来最大的灵活度。

![image](https://ws3.sinaimg.cn/large/69d4185bly1g30vg1jsd9j20cw08bdi9.jpg)

采用这种方法，内核只识别内核级线程，并对其进行调度。其中- -些内核级线程会被多个用户级线程多路复用。如同在没有多线程能力操作系统中某个进程中的用户级线程一样，可以创建、撤销和调度这些用户级线程。在这种模型中，每个内核级线程有一个可以轮流使用的用户级线程集合。

### 弹出式线程

在分布式系统中经常使用线程。一个有意义的例子是如何处理到来的消息，例如服务请求。传统的方法是将进程或线程阻塞在一个receive系统调用上，等待消息到来。当消息到达时，该系统调用接收消息，并打开消息检查其内容，然后进行处理。

不过，也可能有另一种完全不同的处理方式，在该处理方式中，-一个消息的到达导致系统创建一个处理该消息的线程，这种线程称为弹出式线程，如图2-18所示。弹出式线程的关键好处是，由于这种线程相当新，没有历史一一没有必须存 储的寄存器、堆栈诸如此类的内容，每个线程从全新开始，每一个线程彼此之间都完全一样。这样，就有可能快速创建这类线程。对该新线程指定所要处理的消息。使用弹出式线程的结果是，消息到达与处理开始之间的时间非常短。

![image](https://wx4.sinaimg.cn/large/69d4185bly1g30voen19nj20jh0atwj6.jpg)

在使用弹出式线程之前，需要提前进行计划。例如， 哪个进程中的线程先运行?如果系统支持 在内核上下文中运行线程，线程就有可能在那里运行(这是图2-18中没有画出内核的原因)。在内核空间中运行弹出式线程通常比在用户空间中容易且快捷，而且内核空间中的弹出式线程可以很容易访问所有的表格和I/O设备，这些也许在中断处理时有用。而另一方面，出错的内核线程会比出错的用户线程造成更大的损害。例如，如果某个线程运行时间太长，又没有办法抢占它，就可能造成进来的信息丢失。

## 进程间通讯

进程经常需要与其他进程通信。例如，在-一个shell管道中，第一个进程的输出必须传送给第二个进程，这样沿着管道传递下去。因此在进程之间需要通信，而且最好使用一种结构良好的方式而不要使用中断。在下面几节中，我们就来讨论一些有关**进程间通信**(Inter Process Communication， IPC)的问题。

简要地说，有三个问题。第一个问题与上面的叙述有关，即一个进程如何把信息传递给另一个。*第二个*要处理的问题是，确保两个或更多的进程在关键活动中不会出现交叉，例如，在飞机订票系统中的两个进程为不同的客户试图争夺飞机上的最后一个座位。*第三*个问题与正确的顺序有关( 如果该顺序是有关联的话)，比如，如果进程A产生数据而进程B打印数据，那么B在打印之前必须等待，直到A已经产生一些数据。我们将从下一节开始考察所有这三个问题。

有必要说明，这三个问题中的两个问题对于线程来说是同样适用的。第一个问题(即传递信息)对线程而言比较容易，因为它们共享-一个地址空间(在不同地址空间需要通信的线程属于不同进程之间通信的情形)。但是另外两个问题(需要梳理清楚并保持恰当的顺序)同样适用于线程。同样的问题可用同样的方法解决。下面开始讨论进程间通信问题，不过请记住，同样的问题和解决方法也适用于线程。

### 竞争条件

在一些操作系统中，协作的进程可能共享一些彼此都能读写的公用存储区。这个公用存储区可能在内存中(可能是在内核数据结构中)，也可能是一个共享文件。这里共享存储区的位置并不影响通信的本质及其带来的问题。为了理解实际中进程间通信如何工作，我们考虑一个简单但很普遍的例子:一个假脱机打印程序。当一个进程需要打印一个文件时，它将文件名放在一个特殊的假脱机目录(spooler directory)下。另一个进程(打印机守护进程)则周期性地检查是否有文件需要打印，若有就打印并将该文件名从目录下删掉。

![image](https://ws4.sinaimg.cn/large/69d4185bly1g30w0aqaa8j20c108oabq.jpg)

设想假脱机目录中有许多槽位，编号依次为0， 1，2，…… ，”每个槽位存放一个文件名。同时假设有两个共享变量: out，指向下一个要打印的文件； in， 指向目录中下一个空闲槽位。可以把这两个变量保存在一个所有进程都能访问的文件中，该文件的长度为两个字。在某一时刻，0号至3号槽位空(其中的文件已经打印完毕)，4号至6号槽位被占用(其中存有排好队列的要打印的文件名)。几乎在同一时刻，进程A和进程B都决定将一个文件排队打印，这种情况如图2-21所示。

在Murphy法则(任何可能出错的地方终将出错)生效时，可能发生以下的情况。进程A读到in的值为7，将7存在一个局部变量`next_free_slot`中。此时发生-次时钟中断，CPU认为进程A已运行了足够长的时间，决定切换到进程B。进程B也读取in，同样得到值为7，于是将7存在B的局部变量`next_ free_ slot`中。 在这一时刻两个进程都认为下一个可用槽位是7。进程B现在继续运行，它将其文件名存在槽位7中并将in的值更新为8。然后它离开，继续执行其他操作。

最后进程A接着从上次中断的地方再次运行。它检查变量`next_ free_ slot`， 发现其值为7，于是将打印文件名存入7号槽位，这样就把进程B存在那里的文件名覆盖掉。然后它将`next_ free_ slot`加1， 得到值为8，就将8存到in中。此时，假脱机目录内部是致的，所以打印机守护进程发现不了任何错误，但进程B却永远得不到任何打印输出。类似这样的情况，**即两个或多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序，称为竞争条件(race condition)**。调试包含有竞争条件的程序是一件很头痛的事。大多数的测试运行结果都很好，但在极少数情况下会发生一些无法解释的奇怪现象。不幸的 是，多核增长带来的并行使得竞争条件越来越普遍。

### 临界区

怎样避免竞争条件?实际上凡涉及共享内存、共享文件以及共享任何资源的情况都会引发与前面类似的错误，要避免这种错误，关键是要找出某种途径来阻止多个进程同时读写共享的数据。换言之，我们需要的是**互斥**(mutual exclusion)，即以某种手段确保当一个进程在使用一个共享变量或文件时，其他进程不能做同样的操作。前述问题的症结就在于，在进程A对共享变量的使用未结束之前进程B就使用它。为实现互斥而选择适当的原语是任何操作系统的主要设计内容之一。

避免竞争条件的问题也可以用一种抽象的方式进行描述。一个进程的一部分时间做内部计算或另外一些不会引发竞争条件的操作。在某些时候进程可能需要访问共享内存或共享文件，或执行另外一些会导致竞争的操作。**我们把对共享内存进行访问的程序片段称作临界区域(critical region)或临界区( criticalsection)**。如果我们能够适当地安排，使得两个进程不可能同时处于临界区中，就能够避免竞争条件。

尽管这样的要求避免了竞争条件，但它还不能保证使用共享数据的并发进程能够正确和高效地进行协作。对于一个好的解决方案，需要满足以下4个条件:

1） 任何两个进程不能同时处于其临界区。
2）不应对CPU的速度和数量做任何假设。
3）临界区外运行的进程不得阻塞其他进程。
4）不得使进程无限期等待进入临界区。

![image](https://wx4.sinaimg.cn/large/69d4185bly1g30wazk83fj20hh0a9gp8.jpg)

从抽象的角度看，人们所希望的进程行为如图2-22所示。图2-22中进程A在$T_1$，时刻进入临界区。稍后，在$T_2$时刻进程B试图进人临界区，但是失败了，因为另一个进程已经在该临界区内，而一个时刻只允许一个进程在临界区内。随后，B被暂时挂起直到$T_3$，时刻A离开临界区为止，从而允许B立即进入。最后，B离开(在时刻$T_4$)，回到了在临界区中没有进程的原始状态。

###  忙等待的互斥

本节将讨论几种实现互斥的方案。在这些方案中，当一个进程在临界区中更新共享内存时，其他进程将不会进入其临界区，也不会带来任何麻烦。

#### 屏蔽中断

在单处理器系统中，最简单的方法是使每个进程在刚刚进入临界区后立即屏蔽所有中断，并在就要离开之前再打开中断。屏蔽中断后，时钟中断也被屏蔽。CPU只有发生时钟中断或其他中断时才会进行进程切换，这样，在屏蔽中断之后CPU将不会被切换到其他进程。于是，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不必担心其他进程介入。

这个方案并不好，因为把屏蔽中断的权力交给用户进程是不明智的。设想一下，若一个进程屏蔽中断后不再打开中断，其结果将会如何?整个系统可能会因此终止。而且，如果系统是多处理器(有两个或可能更多的处理器)，则屏蔽中断仅仅对执行disable指令的那个CPU有效。其他CPU仍将继续运行，并可以访问共享内存。

另一方面，对内核来说，当它在更新变量或列表的几条指令期间将中断屏蔽是很方便的。当就绪进程队列之类的数据状态不一.致时发生中断，则将导致竞争条件。所以结论是:屏蔽中断对于操作系统本身而言是一项很有用的技术，但对于用户进程则不是一种合适的通用互斥机制。

由于多核芯片的数量越来越多，即使在低端PC上也是如此。因此，通过屏蔽中断来达到互斥的可能性一甚至在内核中 变得日 益减少了。双核现在已经相当普遍，四核当前在高端机器中存在，而且离八或十六(核)也不久远了。在一个多核系统中(例如，多处理器系统)，屏蔽一个CPU的中断不会阻止其他CPU干预第- - 个CPU所做的操作。结果是人们需要更加复杂的计划。

#### 锁变量

作为第二种尝试，可以寻找一种软件解决方案。设想有一个共享(锁)变量，其初始值为0。当一个进程想进入人其临界区时，它首先测试这把锁。如果该锁的值为0，则该进程将其设置为I并进入临界区。若这把锁的值已经为1，则该进程将等待直到其值变为0。于是，0就表示临界区内没有进程，1表示已经有某个进程进人临界区。

但是，这种想法也包含了与假脱机目录一样的疏漏。假设一个进程读出锁变量的值并发现它为0，而恰好在它将其值设置为1之前，另一个进程被调度运行，将该锁变量设置为1。当第一个进程再次运行时，它同样也将该锁设置为1，则此时同时有两个进程进入临界区中。

可能读者会想，先读出锁变量，紧接着在改变其值之前再检查-遍它的值，这样便可以解决问题。但这实际上无济于事，如果第二个进程恰好在第一个进程完成第二次检查之后修改了锁变量的值，则同样还会发生竞争条件。

#### 严格轮换法

第三种互斥的方法如图2-23所示。几乎与本书中所有其他程序一样，这里的程序段用C语言编写。之所以选择C语言是由于实际的操作系统普遍用C语言编写(或偶尔用C++)，而基本上不用像Java、Modula3或Pascal这样的语言。对于编写操作系统而言，C语言是强大、有效、可预知和有特性的语言。而对于Java，它就不是可预知的，因为它在关键时刻会用完存储器，而在不合适的时候会调用垃圾收集程序回收内存。在C语言中，这种情形就不可能发生，因为C语言中不需要进行空间回收。

在图2-23中，整型变量turn，初始值为0，用于记录轮到哪个进程进入临界区，并检查或更新共享内存。开始时，进程0检查turn，发现其值为0，于是进入临界区。进程1也发现其值为0，所以在一个等待循环中不停地测试turn，看其值何时变为1。连续测试一个变量直到某个值出现为止，称为**忙等待**(busywaiting)。由于这种方武浪费CPU时间，所以通常应该避免。只有在有理由认为等待时间是非常短的情形下，才使用忙等待。用于忙等待的锁，称为**自旋锁**(spin lock)。

![image](https://ws1.sinaimg.cn/large/69d4185bly1g30x85upboj20p0067whs.jpg)

进程0离开临界区时，它将turn的值设置为1，以便允许进程1进入其临界区。假设进程I很快便离开了临界区，则此时两个进程都处于临界区之外，turn的值又被设置为0。现在进程0很快就执行完其整个循环，它退出临界区，并将turn的值设置为1。此时，turn的值为1， 两个进程都在其临界区外执行。

突然，进程0结束了非临界区的操作并且返回到循环的开始。但是，这时它不能进入临界区，因为turn的当前值为1，而此时进程1还在忙于非临界区的操作，进程0只有继续while循环，直到进程1把turn的值改为0。这说明，在一个进程比另一个慢了很多的情况下，轮流进人临界区并不是一个好办法。

这种情况违反了前面叙述的条件3:进程0被一个临界区之外的进程阻塞。再回到前面假脱机目录的问题，如果现在将临界区与读写假脱机目录相联系，则进程0有可能因为进程1在做其他事情而被禁止打印另一个文件。

实际上，该方案要求两个进程严格地轮流进人它们的临界区，如假脱机文件等。任何一个进程都不可能在一轮中打印两个文件。尽管该算法的确避免了所有的竞争条件，但由于它违反了条件3，所以不能作为一个很好的备选方案。

#### TSL 指令

现在来看需要硬件支持的一种方案。某些计算机中，特别是那些设计为多处理器的计算机，都有下面一条指令:

```basic
TSL RX, LOCK
```

称为**测试并加锁**(test and set lock),它将一个内存字lock读到寄存器RX中，然后在该内存地址上存一.个非零值。读字和写字操作保证是不可分割的，即该指令结束之前其他处理器均不允许访问该内存字。执行TSL指令的CPU将锁住内存总线，以禁止其他CPU在本指令结東之前访问内存。

着重说明一下，锁住存储总线不同于屏蔽中断。屏蔽中断，然后在读内存字之后跟着写操作并不能阻止总线上的第二个处理器在读操作和写操作之间访问该内存字。事实上，在处理器1上屏蔽中断对处理器2根本没有任何影响。让处理器2远离内存直到处理器1完成的唯一方法就是锁住总线， 这需要一个特殊的硬件设施(基本上，一根总线就可以确保总线由锁住它的处理器使用，而其他的处理器不能用)。

为了使用TSL指令，要使用一个共享变量lock来协调对共享内存的访问。当lock 为0时，任何进程都可以使用TSL指令将其设置为1,并读写共享内存。当操作结束时，进程用一条普通的move指令将lock的值重新设置为0。

### 睡眠与唤醒

Peterson解法和TSL或XCHG解法都是正确的，但它们都有忙等待的缺点。这些解法在本质上是这样的: 当一个进程想进入临界区时，先检查是否允许进入，若不允许，则该进程将原地等待，直到允许为止。

这种方法不仅浪费了CPU时间，而且还可能引起预想不到的结果。考虑一台计算机有两个进程，H优先级较高，L优先级较低。调度规则规定，只要H处于就绪态它就可以运行。在某时刻，L处于临界区中，此时H变到就绪态，准备运行(例如，一条I/O操作结束)。现在H开始忙等待，但由于当H就绪时L不会被调度，也就无法离开临界区，所以H将永远忙等待下去。这种情况有时被称作**优先级反转问题**(priority inversion problem)。

现在来考察几条进程间通信原语，它们在无法进入临界区时将阻塞，而不是忙等待。最简单的是sleep和wakeup。sleep是一个将引起调用进程阻塞的系统调用，即被挂起，直到另外一个进程将其唤醒。wakeup调用有一个参数，即要被唤醒的进程。另一种方法是让sleep和wakeup各有一个参数，即有一个用于匹配sleep和wakeup的内存地址。

**生产者—消费者问题**

作为使用这些原语的一个例子，我们考虑**生产者—消费者**(producer-consumer) 问题，也称作**有界缓冲区**(bounded-buffer) 问题。两个进程共享一个公共的固定大小的缓冲区。 其中一个是生产者，将信息放入缓冲区;另一个是消费者，从缓冲区中取出信息。(也可以把这个问题一般化 为m个生产者和n个消费者问题，但是这里只讨论一个生产者和一个消费者的情况，这样可以简化解决方案。)

问题在于当缓冲区已满，而此时生产者还想向其中放入一个新的数据项的情况。其解决办法是让生产者睡眠，待消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样地，当消费者试图从缓冲区中取数据而发现缓冲区为空时，消费者就睡眠，直到生产者向其中放入一些数据时再将其唤醒。

这个方法听起来很简单，但它包含与前边假脱机目录问题一.样的竞争条件。为了跟踪缓冲区中的数据项数，需要一个变量count。如果缓冲区最多存放N个数据项，则生产者代码将首先检查count是否达到N,若是，则生产者睡眠;否则生产者向缓冲区中放入一个数据项并增量count的值。

消费者的代码与此类似:首先测试count是否为0,若是，则睡眠;否则从中取走一个 数据项并递减count的值。每个进程同时也检测另一个进程是否应被唤醒，若是则唤醒之。生产者和消费者的代码如下所示。

```c
#define N 100					/*缓冲区中的槽数目*/
int count = 0;					/*缓冲区中的数据项数目*/
void producer(void)
{
	int item;					/*无限循环*/
	while (TRUE) {
		item = produce item( );	/*产生下一新数据项*/
		if (count == N) sleep();/*如果缓冲区满了，就进入休眠状态
		insert_item(item);		/*将(新)数据项放入缓冲区中*/
		count = count + 1; 		/*将缓冲区的数据项计数器增1 */
		if (count == 1) wakeup(consumer);/*缓冲区空吗? */
	}
}
void consumer(void)
{
	int item;					/*无限循环*/
	while (TRUE) {				/*如果缓冲区空，则进入休眠状态*/
		if (count == 0) sleep();/*从缓冲区中取出一个数据项*/
		item = remove_ item( );
		count = count - 1;		/*将缓冲区的数据项计数器减I*/
		if (count == N - 1) wakeup(producer); /* 缓冲区满吗? */
		consume item(item);		/*打印数据项*/
	}
}
```

现在回到竞争条件的问题。这里有可能会出现竞争条件，其原因是对count的访问未加限制。有可能出现以下情况:缓冲区为空，消费者刚刚读取count的值发现它为0。此时调度程序决定暂停消费者并启动运行生产者。生产者向缓冲区中加入一个数据项，coun加1。 现在count的值变成了1。它推断认为由于count刚才为0，所以消费者此时-定在睡眠，于是生产者调用wakeup来唤醒消费者。

但是，消费者此时在逻辑上并未睡眠，所以wakeup信号丢失。当消费者下次运行时，它将测试先前读到的count值，发现它为0，于是睡眠。生产者迟早会填满整个缓冲区，然后睡眠。这样一来，两个进程都将永远睡眠下去。

问题的实质在于发给一个(尚)未睡眠进程的wakeup信号丢失了。如果它没有丢失，则一切都很正常。一种快速的弥补方法是修改规则，加上一个唤醒等待位。当一个wakeup信号发送给一个清醒的进程信号时，将该位置1。随后，当该进程要睡眠时，如果唤醒等待位为1，则将该位清除，而该进程仍然保持清醒。喚醒等待位实际上就是wakeup信号的一个小仓库。

尽管在这个简单例子中用唤醒等待位的方法解决了问题，但是我们可以很容易就构造出一一些例子，其中有三个或更多的进程，这时一个唤醒等待位就不够使用了。于是我们可以再打一个补丁，加入第二个唤醒等待位，甚至是8个、32个等，但原则上讲，这并没有从根本上解决问题。

### 信号量















