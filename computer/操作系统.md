# 操作系统

## 简介

操作系统的主要任务是记录哪个程序在使用什么资源，对资源请求进行分配，评估使用代价，并且为不同的程序和用户调解互相冲突的资源请求。
资源管理包括用以下两种不同方式实现多路复用(共享)资源: 在时间上复用和在空间上复用。当一种资源在时间上复用时，不同的程序或用户轮流使用它。先是第一个获得资源的使用，然后下一个，以此类推。例如，若在系统中只有一个CPU，而多个程序需要在该CPU上运行，操作系统则首先把该CPU分配给某个程序，在它运行了足够长的时间之后，另一个程序得到CPU，然后是下一个，如此进行下去，最终，轮到第-一个程序再次运行。至于资源是如何实现时间复用的一谁应该是下一个以及运行多长时间等一-则 是操作系统的任务。还有一个有关时间复用的例子是打印机的共享。当多个打印作业在一台打印机上排队等待打印时，必须决定将轮到打印的是哪个作业。

另一类复用是空间复用。每个客户都得到资源的部分，从而取代了客户排队。例如，通常在若干运行程序之间分割内存，这样每一个运行程序都可同时人驻内存(例如，为了轮流使用CPU)。假设有足够的内存可以存放多个程序，那么在内存中同时存放若千个程序的效率，比把所有内存都分给一个程序的效率要高得多，特别是，如果一个程序只需要整个内存的一小部分，结果更是这样。当然，如此的做法会引起公平、保护等问题，这有赖于操作系统解决它们。有关空间复用的其他资源还有磁盘。在许多系统中，一个磁盘同时为许多用户保存文件。分配磁盘空间并记录谁正在使用哪个磁盘块，是操作系统的典型任务。

**多道程序设计**

若当前作业因等待磁带或其他I/O操作而暂停， CPU就只能简单地踏步直至该I/O完成。对于CPU操作密集的科学计算问题，I/O操作较少，因此浪费的时间很少。然而，对于商业数据处理，I/O操作等待的时间通常占到80%~90%，所以必须采取某种措施减少(昂贵的)CPU空闲时间的浪费。
解决方案是将内存分几个部分，每一部分存放不同的作业，如图1-5所示

![image](https://wx2.sinaimg.cn/large/69d4185bly1g2swpz9qzoj207507i3zf.jpg)

当一个作业等待I/O操作完成时，另一个作业可以使用CPU。如果内存中可以同时存放足够多的作业，则CPU利用率可以接近100%。在内存中同时驻留多个作业需要特殊的硬件来对其进行保护，以避免作业的信息被窃取或受到攻击。

## 硬件

一台机计算机的组成

![image](https://ws2.sinaimg.cn/large/69d4185bly1g2sxa1hah3j20hx09r0wh.jpg)

### 处理器

计算机的“大脑”是CPU，它从内存中取出指令并执行之。在每个CPU基本周期中，首先从内存中取出指令，解码以确定其类型和操作数，接着执行之，然后取指、解码并执行下一条指令。按照这一方式，程序被执行完成。

每个CPU都有一套可执行的专门指令集。所以，x86处理器不能执行ARM程序，而ARM处理器也不能执行x86程序。由于用来访问内存以得到指令或数据的时间要比执行指令花费的时间长得多，因此，所有的CPU内都有一些用来保存关键变量和临时数据的寄存器。这样，通常在指令集中提供一些指令，用以将一个字从内存调入寄存器，以及将-一个字从寄存器存人内存。其他的指令可以把来自寄存器、内存的操作数组合，或者用两者产生一个结果，如将两个字相加并把结果存在寄存器或内存中。

除了用来保存变量和临时结果的通用寄存器之外，多数计算机还有一些对程序员可见的专用寄存器。其中之一是**程序计数器**，它保存了将要取出的下一条指令的内存地址。在指令取出之后，程序计数器就被更新以便指向后继的指令。
另一个寄存器是**堆栈指针**，它指向内存中当前栈的顶端。该栈包含了每个执行过程的栈帧。一个过程的栈帧中保存了有关的输入参数、局部变量以及那些没有保存在寄存器中的临时变量。

当然还有**程序状态字**(Program Status Word， PSW)寄存器。这个寄存器包含了条件码位( 由比较指令设置)、CPU优先级、模式(用户态或内核态)，以及各种其他控制位。用户程序通常读入整个PSW，但是，只对其中的少量字段写人。在系统调用和I/O中，PSW的作用很重要。
操作系统必须知晓所有的寄存器。在时间多路复用(time multiplexing) CPU中，操作系统经常会中止正在运行的某个程序并启动(或再启动)另一个程序。每次停止一个运行着的程序时，操作系统必须保存所有的寄存器值，这样在稍后该程序被再次运行时，可以把这些寄存器重新装入。

------

为了改善性能，CPU设计师早就放弃了同时读取、解码和执行- 条指令的简单模型。许多现代CPU具有同时取出多条指令的机制。例如，一个CPU可以有单独的取指单元、解码单元和执行单元，于是当它执行指令n时，还可以对指令n+ 1解码，并且读取指令n + 2。这样的机制称为流水线(pipeline)， 图1-7a是一个有着三个阶段的流水线示意图。更长的流水线也是常见的。在多数的流水线设计中，一旦一条指令被取进流水线中，它就必须被执行完毕，即便前一条取出的指令是条件转移，它也必须被执行完毕。流水线使得编译器和操作系统的编写者很头疼，因为它造成了在机器中实现这些软件的复杂性问题，而机器必须处理这些问题。

![image](https://wx1.sinaimg.cn/large/69d4185bly1g2t4tmmr9zj20jl07bq5w.jpg)

比流水线更先进的设计是超标量CPU，如图1-7b所示。在这种设计中，有多个执行单元，例如，一个CPU用于整数算术运算，一个CPU用于浮点算术运算，一个CPU用于布尔运算。两个或更多的指令被同时取出、解码并装人暂存缓冲区中，直至它们执行完毕。只要有一个执行单元空闲，就检查保持缓冲区中是否还有可处理的指令，如果有，就把指令从缓冲区中移出并执行之。这种设计存在一种隐含的作用，即程序的指令经常不按顺序执行。在多数情况下，硬件负责保证这种运算的结果与顺序执行指令时的结果相同，但是，仍然有部分令人烦恼的复杂情形被强加给操作系统处理，我们在后面会讨论这种情况。

### 多线程和多核芯片

多线程允许CPU保持两个不同的线程状态，然后在纳秒级的时间尺度内来回切换。(线程是一种轻量级进程，即
一个运行中的程序)例如，如果某个进程需要从内存中读出一个字(需要花费多个时钟周期)，多线程CPU则可以切换至另一个线程。多线程不提供真正的并行处理。在一个时刻只有一个进程在运行，但是线程的切换时间则减少到纳秒数量级。

多线程对操作系统而言是有意义的，因为每个线程在操作系统看来就像是单个的CPU。考虑一个实际有两个CPU的系统，每个CPU有两个线程。这样操作系统将把它看成是4个CPU。如果在某个特定时间点上，只有能够维持两个CPU忙碌的工作量，那么在同一个CPU上调度两个线程，而让另一个CPU完全空转，就没有优势了。这种选择远远不如在每个CPU上运行一个线程的效率高。

![image](https://ws3.sinaimg.cn/large/69d4185bly1g2t51igzq4j20bu09b41l.jpg)

除了多线程，还出现了包含2个或4个完整处理器或内核的CPU芯片。图1-8中的多核芯片上有效地装有4个小芯片，每个小芯片都是一个独立的CPU(后面将解释缓存)。Intel Xeon Phi和Tilera TilePro等处理器，已经炫技般地在一枚芯片上集成了60多个核。要使用这类多核芯片肯定需要多处理器操作系统。
其实在绝对数目方面，没什么能赢过现代的GPU (Graphics Processing Unit)。 GPU指的是由成千上万个微核组成的处理器。它们擅长处理大量并行的简单计算，比如在图像应用中渲染多边形。它们不太能胜任串行任务，并且很难编程。虽然GPU对操作系统很有用(比如加密或者处理网络传输)，但操作系统本身不太可能运行在GPU上。

### 存储器

![image](https://ws3.sinaimg.cn/large/69d4185bly1g2t57s0t8tj20ek057402.jpg)

**寄存器**

存储器系统的顶层是CPU中的寄存器。它们用与CPU相同的材料制成，所以和CPU-样快。显然，访问它们是没有时延的。其典型的存储容量是，在32位CPU中为32x32位，而在64位CPU中为64 x 64位。在这两种情形下，其存储容量都小于1 KB。程序必须在软件中自行管理这些寄存器( 即决定如何使用它们)。

**高速缓存**

下一层是高速缓存，它多数由硬件控制。主存被分割成**高速缓存行**(cache line)，其典型大小为64字节，地址0至63对应高速缓存行0，地址64至127对应高速缓存行1，以此类推。最常用的高速缓存行放置在CPU内部或者非常接近CPU的高速缓存中。当某个程序需要读一个存储字时，高速缓存硬件检查所需要的高速缓存行是否在高速缓存中。如果是，称为**高速缓存命中**，缓存满足了请求，就不需要通过总线把访问请求送往主存。高速缓存命中通常需要两个时钟周期。高速缓存未命中就必须访问内存，这要付出大量的时间代价。由于高速缓存的价格昂贵，所以其大小有限。有些机器具有两级甚至三级高速缓存，每一级高速缓存比前一-级慢且容量更大。

在任何缓存系统中，都有若千需要尽快考虑的问题，包括:
1) 何时把一个新的内容放入缓存。
2 )把新内容放在缓存的哪行上。
3) 在需要时，应该把哪个内容从缓存中移走。
4) 应该把新移走的内容放在某个较大存储器的何处。
并不是每个问题的解决方案都符合每种缓存处理。对于CPU缓存中的主存缓存行，每当有缓存未命中时，就会调入新的内容。通常通过所引用内存地址的高位计算应该使用的缓存行。例如，对于64字节的4096个缓存行以及32位地址，其中6~17位用来定位缓存行，而0~ 5位则用来确定缓存行中的字节。在这个例子中，被移走内容的位置就是新数据要进入的位置，但是在有的系统中未必是这样。最后，当将一个缓存行的内容重写进主存时(该内容被缓存后，可能会被修改)，通过该地址来唯一确定需 重写的主存位置。

缓存是一种好方法，所以现代CPU中设计了两个缓存。第一级或称为**L1缓存**总是在CPU中，通常用来将已解码的指令调入CPU的执行引擎。对于那些频繁使用的数据字，多数芯片安排有第二个L1缓存。典型的L1缓存大小为16KB。另外，往往还设计有二级缓存，称为**L2缓存**，用来存放近来使用过的若千兆字节的内存字。L1和L2缓存之间的差别在于时序。对L1缓存的访问，不存在任何延时：而对L2缓存的访问，则会延时1或2个时钟周期。

**主存**

在图1-9的层次结构中，再往下一层是主存。这是存储器系统的主力。主存通常称为**随机访问存储器**(Random Access Memory， RAM)。过去有时称之为**磁芯存储器**，因为在20世纪50年代和60年代，使用很小的可磁化的铁磁体制作主存。虽然它们已经绝迹了很多年，但名称还是传承了下来。目前，存储器的容量在几百兆字节到若干吉字节之间，并且其容量正在迅速增长。所有不能在高速缓存中得到满足的访问请求都会转往主存。
除了主存之外，许多计算机已经在使用少量的非易失性随机访问存储器。它们与RAM不同，在电源切断之后，非易失性随机访问存储器并不丢失其内容。**只读存储器**(Read Only Memory， ROM)在工厂中就被编程完毕，然后再也不能被修改。ROM速度快且便宜。在有些计算机中，用于启动计算机的引导加载模块就存放在ROM中。另外，一些I/O卡也采用ROM处理底层设备控制。
**EEPROM** ( Electrically Erasable PROM，电可擦除可编程ROM)和闪存(flash memory)也是非易失性的，但是与ROM相反，它们可以擦除和重写。不过重写它们需要比写入RAM更高数量级的时间，所以它们的使用方式与ROM相同，而其与众不同的特点使它们有可能通过字段重写的方式纠正所保存程序中的错误。

**磁盘**

![image](https://ws1.sinaimg.cn/large/69d4185bly1g2t5o6l7muj20bm08iace.jpg)

下一个层次是磁盘! (硬盘)。磁盘同RAM相比，每个二进制位的成本低了两个数量级，而且经常也有两个数量级大的容量。磁盘唯一的问题是随机访问数据时间大约慢了三个数量级。其低速的原因是因为磁盘是一种机械装置，如图1-10所示。

![image](https://wx2.sinaimg.cn/large/69d4185bly1g2t5u5aycyj20et0bh0vc.jpg)

在一个磁盘中有一个或多个金属盘片，它们以5400rpm、7200rpm、 10 800rpm或更高的速度旋转。从边缘开始有一个机械臂悬横在盘面上，这类似于老式播放塑料唱片33转唱机上的拾音臂。信息写在磁盘的一系列同心上。在任意一个给定臂的位置，每个磁头可以读取一段环形区域，称为**磁道**(track)。 把一个给定臂的位置上的所有磁道合并起来，组成了一个**柱面**(cylinder)。

每个磁道划分为若千扇区，扇区的典型值是512字节。在现代磁盘中，较外部的柱面比较内部的柱 面有更多的扇区。机械臂从一个柱面移到相邻的柱面大约需要lms。而随机移到一个柱面的典型时间为 5ms至10ms，其具体时间取决于驱动器。一且磁臂到达正确的磁道上，驱动器必须等待所需的扇区旋转 到磁头之下，这就增加了5ms至10ms的时延，其具体延时取决于驱动器的转速。一日所需要的扇区移到 磁头之下，就开始读写，低端硬盘的速率是50MB/s，而高速磁盘的速率是160 MB/s。

许多计算机支持-种著名的**虚拟内存**机制，这将在第3章中讨论。这种机制使得期望运行大于物理 内存的程序成为可能，其方法是将程序放在磁盘上，而将主存作为一种缓存，用来保存最频繁使用的部! 分程序。这种机制需要快速地映像内存地址，以便把程字生成的地址转换为有关字节在RAM中的物理 地址。这种映像由CPU中的一个称为**存储器管理单元**(Memory Management Unit， MMU)的部件来完 成，如图1-6所示。 

缓存和MMU的出现对系统的性能有着重要的影响。在多道程序系统中，从一个程序切换到另一个 程序，有时称为**上下文切换**(context switch)，有必要对来自缓存的所有修改过的块进行写回磁盘操作， 并修改MMU中的映像寄存器。但是这两种操作的代价很昂贵，所以程序员努力避免使用这些操作。我们稍后将看到这些操作产生的影响。

### 总线

![image](https://wx4.sinaimg.cn/large/69d4185bly1g2u3irraomj20hj0ce43o.jpg)

图中的系统有很多总线( 例如高速缓存、内存、PCle、 PCI、USB、SATA和DMI)，每条总线的传 输速度和功能都不同。操作系统必须了解所有总线的配置和管理。其中主要的总线是PCle ( Peripheral Component Interconnect Express)总线。

Intel发明的PCIe总线是陈旧的PCI总线的继承者，而PCI总线则是为了取代原来的ISA (IndustryStandard Architecture) 总线。数十Gb/s的传输能力使得PCIe比它的前身快得多。它们在本质上也十分不同。直到发明PCIe总线的2004年，大多数总线都是并行且共享的。**共享总线架构**(shared bus architecture)表示多个设备使用一些相同的导线传输数据。因此，当多个设备同时需要发送数据时，需要仲裁器决定哪个设备可以使用总线。PCIe恰好相反，它使用分离的端到端的链路。传统PCI使用的**并行总线架构**( parallel bus architecture) 表示通过多条导线发送数据的每个字。例如，在传统的PCI总线上，一个32位数据通过32条并行的导线发送。与之相反，PCIe使用**串行总线架构**(serial busarchitecture)，通过一条被称为数据通路的链路传递集合了所有位的一条消息，这非常像网络包。这样做简单了很多，因为不用再确保所有32位在同一时刻精确地到达目的地。通过将多个数据通路并行起来，并行性仍可有效利用。例如，可以使用32个数据通路并行传输32条消息。随着网卡和图形适配器这些外围设备速度的迅速增长，PCle标准每3~5年进行一次更新。例如，PCle 2.0规格的16个数据通路提供64Gb/s的速度，升级到PCIe 3.0后会提速2倍，而PCIe 4.0会再提速2倍。

在图中，CPU通过DDR3总线与内存对话，通过PCIe总线与外围图形设备对话，通过**DMI** (Direct Media Interface)总线经集成中心与所有其他设备对话。而集成中心通过通用串行总线与USB设备对话，通过SATA总线与硬盘和DVD驱动器对话，通过PCIe传输以太网络帧。我们已经提到过使用传统PCI总线的旧的PCI设备。



## 操作系统概念

### 进程

在所有操作系统中，一个重要的概念是**进程(process)**。 进程本质上是正在执行的一个程序。与每 个进程相关的是**地址空间(**address space)，这是从某个最小值的存储位置(通常是零)到某个最大值的 存储位置的列表。在这个地址空间中，进程可以进行读写。该地址空间中存放有可执行程序、程序的数 据以及程序的堆栈。与每个进程相关的还有资源集，通常包括寄存器(含有程序计数器和堆栈指针)、 打开文件的清单、突出的报警、有关进程清单，以及运行该程序所需要的所有其他信息。进程基本上是 容纳运行一个程序所需要所有信息的容器。

进程的概念将在第2章详细讨论，不过，对进程建立一种直观感觉的最便利方式是分析一一个多道程序设计系统。用户启动一个视频编辑程序，指示它按照某个格式转换小时的视频(有时会花费数小时)，然后离开去浏览网页。同时，一个被周期性唤醒、用来检查进来的电子邮件的后台进程会开始运行。这样，我们就有了(至少)三个活动进程:视频编辑器、Web浏览器以及电子邮件接收程序。操作系统周期性地挂起一个进程然后启动运行另一个进程，这可能是由于在过去的一两秒钟内，第一个进程已使用完分配给它的时间片。

一个进程暂时被挂起后，在随后的某个时刻里，该进程再次启动时的状态必须与先前暂停时完全相同，这就意味着在挂起时该进程的所有信息都要保存下来。例如，为了同时读入信息，进程打开了若干文件。与每个被打开文件有关的是指向当前位置的指针(即下一个将读出的字节或记录)。在一个进程暂时被挂起时，所有这些指针都必须保存起来，这样在该进程重新启动之后，所执行的读调用才能读到正确的数据。在许多操作系统中，与一个进程有关的所有信息，除了该进程自身地址空间的内容以外，均存放在操作系统的一张表中，称为**进程表**(process table)， 进程表是数组(或链表)结构，当前存在的每个进程都要占用其中一项。

与进程管理有关的最关键的系统调用是那些进行进程创建和进程终止的系统调用。考虑一个典型的例子。有一个称为**命令解释器**(command interpreter) 或 **shell** 的进程从终端上读命令。此时，用户刚键入一条命令要求编译一个程序。shell必须先创建一个新进程来执行编译程序。当执行编译的进程结束时，它执行一一个系统调用来终止自己。

![image](https://ws3.sinaimg.cn/large/69d4185bly1g2u5xed2v9j20a106q0u7.jpg)

若一个进程能够创建一个或多个进程(称为**子进程**),而且这些进程又可以创建子进程，则很容易得到进程树，如图1-13所示。合作完成某些作业的相关进程经常需要彼此通信以便同步它们的行为。这种通信称为**进程间通信**(interprocess communication)，将在第2章中详细讨论。其他可用的进程系统调用包括:申请更多的内存(或释放不再需要的内存)、等待一个子进程结束、用另一个程序覆盖该程序等。



### 地址空间

每台计算机都有一些主存，用来保存正在执行的程序。在非常简单的操作系统中，内存中一次只能有一个程序。如果要运行第二个程序，第一个程序就必须被移出内存，再把第二个程序装入内存。

较复杂的操作系统允许在内存中同时运行多道程序。为了避免它们互相干扰(包括操作系统)，需要有某种保护机制。虽然这种机制必然是硬件形式的，但是由操作系统掌控。
上述的观点涉及对计算机主存的管理和保护。另种不同但是同样重要并与存储器有关的内容，是管理进程的地址空间。<u>通常，每个进程有一些可以使用的地址集合，典型值从0开始直到某个最大值。在最简单的情形下，一个进程可拥有的最大地址空间小于主存。在这种方式下，进程可以用满其地址空间，而且内存中也有足够的空间容纳该进程</u>。
但是，在许多32位或64位地址的计算机中，分别有 $2^{32}$ 或 $2^{64}$ 字节的地址空间。如果一个进程有比计算机拥有的主存还大的地址空间，而且该进程希望使用全部的内存，那怎么办呢?在早期的计算机中，这个进程只好“认命”了。<u>现在，有了一种称为虚拟内存的技术，正如前面已经介绍过的，操作系统可以把部分地址空间装人主存，部分留在磁盘上，并且在需要时来回交换它们。在本质上，操作系统创建了一个地址空间的抽象，作为进程可以引用地址的集合。该地址空间与机器的物理内存解耦，可能大于也可能小于该物理空间</u>。对地址空间和物理空间的管理组成了操作系统功能的一一个重要部分，整个第3章都与这个主题有关。



### 文件

实际上，支持操作系统的另一个关键概念是文件系统。如前所述，操作系统的一项主要功能是隐藏磁盘和其他I/O设备的细节特性，给提供程序员一个良好、清晰的独立于设备的抽象文件模型。显然，创建文件、删除文件、读文件和写文件等都需要系统调用。在文件可以读取之前，必须先在磁盘上定位和打开文件，在文件读过之后应该关闭该文件，有关的系统调用则用于完成这类操作。

为了提供保存文件的地方，大多数操作系统支持**目录**(directory)的概念，从而可把文件分类成组。比如，学生可给所选的每个课程创建一个目录(用于保存该课程所需的程序)，另设一个目录存放电子邮件，再有一个目录用于保存万维网主页。这就需要系统调用创建和删除目录、将已有的文件放入目录中、从目录中删除文件等。目录项可以是文件或者目录，这样就产生了层次结构一文件 系统，如图1-14所示。

![image](https://wx1.sinaimg.cn/large/69d4185bly1g2vg53bxdlj20jr0efdlz.jpg)

进程和文件层次都可以组织成树状结构，但这两种树状结构有不少不同之处。一般进程的树状结构层次不深(很少超过三层)，而文件树状结构的层次常常多达四层、五层或更多层。进程树层次结构是暂时的，通常最多存在几分钟，而目录层次则可能存在数年之久。进程和文件在所有权及保护方面也是有区别的。典型地，只有父进程能控制和访问子进程，而在文件和目录中通常存在一种机制，使文件所有者之外的其他用户也可以访问该文件。

UNIX中的另一个重要概念是安装文件系统。大多数台式机都有一个或多个光盘驱动器，可以插入CD-ROM、DVD和蓝光光盘。它们几乎都有USB接口，可以插入USB存储棒(实际是固态磁盘驱动器)。为了提供一个出色的方式处理可移动介质，UNIX允许把光盘上的文件系统接到主文件树上。考虑图1-15a的情形。在mount调用之前，根文件系统在硬盘上，而第二个文件系统在CD-ROM上，它们是分离且无关的。

![image](https://ws2.sinaimg.cn/large/69d4185bly1g2vgbrmcy4j20lp072dj9.jpg)

然而，不能使用CD-ROM上的文件系统，因为上面没有可指定的路径。UNIX不允许在路径前面加上驱动器名称或代码，那样做就完全成了设备相关类型了，这是操作系统应该消除的。代替的方法是，mount系统调用允许把在CD-ROM上的文件系统连接到程序所希望的根文件系统上。在图1-15b中，CD-ROM上的文件系统安装到了目录b上，这样就允许访问文件/b/x以及/b/y。如果CD-ROM已安装好，但目录b中有任何不能访问的文件，则是因为/b指向了CD-ROM的根目录。(在开始时，不能访问这些文件似乎并不是一个严重问题:文件系统几乎总是安装在空目录上。)如果系统有多个硬盘，它们可以都安装在单个树上。

在UNIX中，另一个重要的概念是**特殊文件**(special file)。 提供特殊文件是为了使I/O设备看起来像文件一般。这样，就像使用系统调用读写文件一样，I/O设备也可通过同样的系统调用进行读写。有两类特殊文件:**块特殊文件**(block special file)和**字符特殊文件**(character special file)。块特殊文件指那些由可随机存取的块组成的设备，如磁盘等。比如打开一个块特殊文件，然后读第4块，程序可以直接访问设备的第4块而不必考虑存放该文件的文件系统结构。类似地，字符特殊文件用于打印机、调制解调器和其他接收或输出字符流的设备。按照惯例，特殊文件保存在/dev目录中。例如，/dev/p是打印机(曾经称为行式打印机)。

![image](https://ws3.sinaimg.cn/large/69d4185bly1g2vgjqoxgkj207y03qjrz.jpg)

本小节中 讨论的最后一个特性既与进程有关也与文件有关:管道。管道(pipe) 是一种虚文件，它可连接两个进程，如图1-16所示。如果进程A和B希望通过管道对话，它们必须提前设置该管道。当进程A想对进程B发送数据时，它把数据写到管道上，仿佛管道就是输出文件一样。进程B可以通过读该管道而得到数据，仿佛该管道就是一一个输入文件一样。这样，在UNIX中两个进程之间的通信就非常类似于普通文件的读写了。更为强大的是，若进程想发现它所写入的输出文件不是真正的文件而是管道，则需要使用特殊的系统调用。

## 系统调用

记住下列事项是有益的。任何单CPU计算机-次只能执行.条指令。如果一个进程正在用户态运行一一个用户程序，并且需要一个系统服务，比如从一个文件读数据，那么它就必须执行.个陷阱或系统调用指令，将控制转移到操作系统。操作系统接着通过参数检查找出所需要的调用进程。然后，它执行系统调用，并把控制返回给在系统调用后面跟随着的指令。在某种意义上，进行系统调用就像进行一个特殊的过程调用，但是只有系统调用可以进人内核，而过程调用则不能。
为了使系统调用机制更清晰，我们简要地考察read系统调用。如上所述，它有三个参数:第一个参数指定文件，第二个指向缓冲区，第三个说明要读出的字节数。几乎与所有的系统调用样， 它的调用由C程序完成，方法是调用一个与该系统调用名称相同的库过程: read。 由C程序进行的调用形式如下:

```c
count = read(fd, buffer, nbytes);
```

系统调用(以及库过程)在count中返回实际读出的字节数。这个值通常和nbytes相同，但也可能更小，例如，如果在读过程中遇到了文件尾的情形就是如此。

如果系统调用不能执行，不论是因为无效的参数还是磁盘错误，count都会被置为-1，而在全局变量errno中放入错误号。程序应该经常检查系统调用的结果，以了解是否出错。
系统调用是通过一系列的步骤实现的。为了更清楚地说明这个概念，考察上面的read调用。在准备调用这个实际用来进行read系统调用的read库过程时，调用程序首先把参数压进堆栈，如图1-17中步骤1~步骤3所示。

![image](https://ws4.sinaimg.cn/large/69d4185bly1g2vh7zi3n7j20hk0gbq9k.jpg)

