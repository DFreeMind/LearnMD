<h1>目录<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#布局" data-toc-modified-id="布局-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>布局</a></span><ul class="toc-item"><li><span><a href="#雅各比矩阵" data-toc-modified-id="雅各比矩阵-1.1"><span class="toc-item-num">1.1&nbsp;&nbsp;</span>雅各比矩阵</a></span></li><li><span><a href="#海森矩阵" data-toc-modified-id="海森矩阵-1.2"><span class="toc-item-num">1.2&nbsp;&nbsp;</span>海森矩阵</a></span></li></ul></li><li><span><a href="#基本求导规则" data-toc-modified-id="基本求导规则-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>基本求导规则</a></span><ul class="toc-item"><li><span><a href="#标量对向量" data-toc-modified-id="标量对向量-2.1"><span class="toc-item-num">2.1&nbsp;&nbsp;</span>标量对向量</a></span></li><li><span><a href="#向量对标量" data-toc-modified-id="向量对标量-2.2"><span class="toc-item-num">2.2&nbsp;&nbsp;</span>向量对标量</a></span></li><li><span><a href="#向量对向量" data-toc-modified-id="向量对向量-2.3"><span class="toc-item-num">2.3&nbsp;&nbsp;</span>向量对向量</a></span></li><li><span><a href="#标量对矩阵" data-toc-modified-id="标量对矩阵-2.4"><span class="toc-item-num">2.4&nbsp;&nbsp;</span>标量对矩阵</a></span></li><li><span><a href="#矩阵对标量" data-toc-modified-id="矩阵对标量-2.5"><span class="toc-item-num">2.5&nbsp;&nbsp;</span>矩阵对标量</a></span></li></ul></li><li><span><a href="#维度分析" data-toc-modified-id="维度分析-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>维度分析</a></span><ul class="toc-item"><li><span><a href="#第一种" data-toc-modified-id="第一种-3.1"><span class="toc-item-num">3.1&nbsp;&nbsp;</span>第一种</a></span></li><li><span><a href="#第二种" data-toc-modified-id="第二种-3.2"><span class="toc-item-num">3.2&nbsp;&nbsp;</span>第二种</a></span></li><li><span><a href="#第三种" data-toc-modified-id="第三种-3.3"><span class="toc-item-num">3.3&nbsp;&nbsp;</span>第三种</a></span></li></ul></li><li><span><a href="#常用求导公式" data-toc-modified-id="常用求导公式-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>常用求导公式</a></span><ul class="toc-item"><li><span><a href="#常用" data-toc-modified-id="常用-4.1"><span class="toc-item-num">4.1&nbsp;&nbsp;</span>常用</a></span></li><li><span><a href="#向量对向量" data-toc-modified-id="向量对向量-4.2"><span class="toc-item-num">4.2&nbsp;&nbsp;</span>向量对向量</a></span></li><li><span><a href="#标量对向量" data-toc-modified-id="标量对向量-4.3"><span class="toc-item-num">4.3&nbsp;&nbsp;</span>标量对向量</a></span></li><li><span><a href="#向量对标量" data-toc-modified-id="向量对标量-4.4"><span class="toc-item-num">4.4&nbsp;&nbsp;</span>向量对标量</a></span></li><li><span><a href="#标量对矩阵" data-toc-modified-id="标量对矩阵-4.5"><span class="toc-item-num">4.5&nbsp;&nbsp;</span>标量对矩阵</a></span></li><li><span><a href="#矩阵对标量" data-toc-modified-id="矩阵对标量-4.6"><span class="toc-item-num">4.6&nbsp;&nbsp;</span>矩阵对标量</a></span></li></ul></li></ul></div>
# 布局
【参考】
- [github.io - 闲话矩阵求导](http://xuehy.github.io/blog/2014/04/18/2014-04-18-matrixcalc/index.html)
- [csdn - （Math）矩阵求导](https://blog.csdn.net/mounty_fsc/article/details/51588794)

矩阵求导有两种布局，分子布局(numerator layout)和分母布局(denominator layout)。为了阐明这两种布局的区别，我们先来看最简单的求导规则。首先是向量 y 对标量 x 求导，我们假定所有的向量都是列向量：
$$
\large{
\begin{split}
\mathbf{y}=\begin{bmatrix}y_{1}\\
y_{2}\\
\vdots\\
y_{m}
\end{bmatrix}
\end{split}
}
$$
在分子布局下：
$$
\large{
\begin{split}
\frac{\partial\mathbf{y}}{\partial x}=\begin{bmatrix}\frac{\partial y_{1}}{\partial x}\\
\frac{\partial y_{2}}{\partial x}\\
\vdots\\
\frac{\partial y_{m}}{\partial x}
\end{bmatrix}
\end{split}
}
$$

而在分母布局下：
$$
\large{
\begin{split}
\frac{\partial\mathbf{y}}{\partial x}=\begin{bmatrix}\frac{\partial y_{1}}{\partial x} & \frac{\partial y_{2}}{\partial x} & \cdots & \frac{\partial y_{m}}{\partial x}\end{bmatrix}
\end{split}
}
$$

出现这种情况取决于把谁看做是列向量，以 x、y均为列向量为例：
- 分子布局(Numerator layout)是把分子看做列向量，分母看做行向量，即 y 为列向量$$\large{\frac{\partial \boldsymbol{y}}{\partial \boldsymbol{x}^T}}$$ 即Jacobian formulation。
- 分母布局(Denominator layout)是把分母看做列向量，分子看做行向量，即 x 为列向量$$\large{\frac{\partial \boldsymbol{y}^T}{\partial \boldsymbol{x}}}$$ 即Hessian formulation。

即，是什么布局则其保持不变，令一个做一下转置，对于矩阵求导亦是如此。

需要注意的是：
- 并非所有书与论文从头为都是统一那个分子布局或者分母分的，往往是结合起来使用，根据上下文来确认。
- 分母布局与分子布局呈转置关系

**以下求导如若没有指明，则均是分母布局**。

## 雅各比矩阵
【参考】
- [Derivatives of Functions of Two or More Variables](http://www.tcd.ie/Economics/staff/paredesm/~EC2040/Lecture12.pdf)

由布局部分可知，分子布局即使雅各比（Jacobian）矩阵形式。雅各比矩阵与一组方程，假设我们有两个方程，有两个未知量，即：
$$
\large{
\begin{split}
y_1 &= f_1(x_1,x_2) \\
y_2 &= f_2(x_2,x_2)
\end{split}
}
$$

每个方程都有两个一阶偏导数，那么两个方程就有 2×2=4 个一阶偏导数。那么 2×2 个一阶偏导数的雅各比矩阵形式如下：
$$
\large{
J= 
\begin{bmatrix}
\frac{\partial y_1}{\partial x_1} & \frac{\partial y_1}{\partial x_2} \\
\frac{\partial y_2}{\partial x_1} & \frac{\partial y_2}{\partial x_2} \\
\end{bmatrix}
}
$$

可知，雅各比矩阵的每一行都是一个方程对其每个变量的偏导数。

如下示例：若$y_1 = x_1x_2, y_2 = x_1+x_2$，那么雅各比矩阵即为：

$$
\large{
J= 
\begin{bmatrix}
x_2 & x_1 \\
1 & 1 
\end{bmatrix}
}
$$

如果泛化到 n 个方程组和 n 个变量时形式为：
$$
\large{
\begin{split}
y_1 &= f_1(x_1,x_2,\cdots,x_n) \\
y_2 &= f_2(x_1,x_2,\cdots,x_n) \\
\vdots \\
y_n &= f_n(x_1,x_2,\cdots,x_n) \\
\end{split}
\quad \Rightarrow \quad
J= 
\begin{bmatrix}
\frac{\partial y_1}{\partial x_1} & \frac{\partial y_1}{\partial x_2} & \cdots & \frac{\partial y_1}{\partial x_n} \\
\frac{\partial y_2}{\partial x_1} & \frac{\partial y_2}{\partial x_2} & \cdots & \frac{\partial y_2}{\partial x_n}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{\partial y_n}{\partial x_1} & \frac{\partial y_n}{\partial x_2} & \cdots & \frac{\partial y_n}{\partial x_n}\\
\end{bmatrix}
}
$$

为什么雅各比矩阵形式是矩阵导数的分子形式呢？如下图：
![image](https://ws3.sinaimg.cn/large/69d4185bly1fx1pr5dp6yj206304aglo.jpg)

表示矩阵导数的第一行的取值。

## 海森矩阵

海森矩阵（Hessian matrix）只与一个方程关联，如$y = f(x_1,x_2)$:
- 她有 2 个一阶偏导数：$\frac{\partial y}{x_1}, \frac{\partial y}{x_2}$
- 有 2×2 个二阶偏导数：$\frac{\partial^2 y}{\partial x_1\partial x_1} , \frac{\partial^2 y}{\partial x_2\partial x_1}, \frac{\partial^2 y}{\partial x_1\partial x_2} , \frac{\partial^2 y}{\partial x_2\partial x_2}$

海森矩阵是二阶偏导数，其中每一行是一阶偏导数分别对变量的求导，即第一行是一阶偏导对第一个变量的求导，第二行则是对第二个变量的求导，形式如下：
$$
\large{
H= 
\begin{bmatrix}
\frac{\partial^2 y}{\partial x_1\partial x_1} & \frac{\partial^2 y}{\partial x_2\partial x_1} \\
\frac{\partial^2 y}{\partial x_1\partial x_2} & \frac{\partial^2 y}{\partial x_2\partial x_2} \\
\end{bmatrix}
}
$$

如，$y = x_1^4 + x_2^2x_1^2 + x_2^3$，那么海森矩阵就为：
$$
\large{
H= 
\begin{bmatrix}
12x_1^2 + 2x_2^2 & 4x_1x_2 \\
4x_1x_2 & 2x_1^2 + 6x_2  \\
\end{bmatrix}
}
$$

将其推广到 n 个变量时，即$y = f(x_1,x_2,\cdots,x_n)$，那么他将有 n 个一阶导数，n×n 个二阶导数，那么海森矩阵形式如下：
$$
\large{
H= 
\begin{bmatrix}
\frac{\partial^2 y}{\partial x_1\partial x_1} & \frac{\partial^2 y}{\partial x_2\partial x_1} & \cdots &  \frac{\partial^2 y}{\partial x_n\partial x_1}\\
\frac{\partial^2 y}{\partial x_1\partial x_2} & \frac{\partial^2 y}{\partial x_2\partial x_2} & \cdots &  \frac{\partial^2 y}{\partial x_n\partial x_2}\\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial^2 y}{\partial x_1\partial x_n} & \frac{\partial^2 y}{\partial x_2\partial x_n} & \cdots &  \frac{\partial^2 y}{\partial x_n\partial x_n}
\end{bmatrix}
}
$$

海森矩阵式是二阶导数，为什么分母的形式是海森矩阵形式呢？这里我们可以把向量 $\boldsymbol{y}$ 中的每个值是变量的一阶导数，那么海森矩阵的形式就是导数的分母形式，如下图：
![image](https://ws4.sinaimg.cn/large/69d4185bly1fx1pvm94d8j2064041dfw.jpg)

表示矩阵导数的第一行的值。可以看到转置一下刚好是分子形式。

# 基本求导规则
【参考】
- [Vector and Matrix Calculus](https://www.kamperh.com/notes/kamper_matrixcalculus13.pdf)

【补充】
- [The Matrix Calculus You Need For Deep Learning](https://explained.ai/matrix-calculus/index.html)

总的来说，涉及矩阵和向量的求导不外乎五大类别，
- 向量对标量
- 标量对向量
- 向量对向量
- 矩阵对标量
- 标量对矩阵

如下表格：
![image](https://ws4.sinaimg.cn/large/69d4185bly1fx1q4khtm5j20n2066gmk.jpg)

## 标量对向量
即 $f:\mathbb{R}^n \rightarrow \mathbb{R}，\boldsymbol{x} \in \mathbb{R}^n$，求得分子形式的结果被称为梯度（gradient），也有的部分布局，两者都成为梯度。

$$
\large{
\begin{split}
\underbrace{\frac{\partial y}{\partial\boldsymbol{x}}=
\begin{bmatrix}
\frac{\partial y}{\partial x_{1}}&
\frac{\partial y}{\partial x_{2}}&
\cdots&
\frac{\partial y}{\partial x_{m}}
\end{bmatrix}}_{分子布局} & \qquad 
\underbrace{\frac{\partial y}{\partial\boldsymbol{x}}=
\begin{bmatrix}
\frac{\partial y}{\partial x_{1}}\\
\frac{\partial y}{\partial x_{2}}\\
\vdots\\
\frac{\partial y}{\partial x_{m}}
\end{bmatrix}}_{分母布局} 
\end{split}\tag{1}
}
$$

## 向量对标量
即 $f:\mathbb{R}^n \rightarrow \mathbb{R}^m，x \in \mathbb{R}, f(x) = [f_1(x),f_2(x),\cdots,f_m(x)]^T$

$$
\large{
\begin{split}
\underbrace{\frac{\partial\boldsymbol{y}}{\partial x}=
\begin{bmatrix}
\frac{\partial y_{1}}{\partial x}\\
\frac{\partial y_{2}}{\partial x}\\
\vdots\\
\frac{\partial y_{m}}{\partial x} 
\end{bmatrix}}_{分子布局} & \qquad
\underbrace{\frac{\partial\boldsymbol{y}}{\partial x}=
\begin{bmatrix}
\frac{\partial y_{1}}{\partial x} & 
\frac{\partial y_{2}}{\partial x} & 
\cdots & 
\frac{\partial y_{m}}{\partial x}
\end{bmatrix}}_{分母布局}
\end{split}\tag{2}
}
$$

## 向量对向量
即 $f:\mathbb{R}^n \rightarrow \mathbb{R}^m，\boldsymbol{x} \in \mathbb{R}^n, f(x) = [f_1(x),f_2(x),\cdots,f_m(x)]^T$

$$
\large{
\begin{split}
\boldsymbol{x}=\begin{bmatrix}x_{1}\\
x_{2}\\
\vdots\\
x_{n}
\end{bmatrix} \qquad 
\boldsymbol{y}=\begin{bmatrix}y_{1}\\
y_{2}\\
\vdots\\
y_{m}
\end{bmatrix}
\end{split}
}
$$
有：
$$
\large{
\begin{split}
\underbrace{\frac{\partial\boldsymbol{y}}{\partial\boldsymbol{x}}=
\begin{bmatrix}
\frac{\partial y_{1}}{\partial x_{1}} & \frac{\partial y_{1}}{\partial x_{2}} & \cdots & \frac{\partial y_{1}}{\partial x_{n}}\\
\frac{\partial y_{2}}{\partial x_{1}} & \frac{\partial y_{2}}{\partial x_{2}} & \cdots & \frac{\partial y_{2}}{\partial x_{n}}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{\partial y_{m}}{\partial x_{1}} & \frac{\partial y_{m}}{\partial x_{2}} & \cdots & \frac{\partial y_{m}}{\partial x_{n}}
\end{bmatrix}}_{分子布局}
&\qquad
\underbrace{\frac{\partial\boldsymbol{y}}{\partial\boldsymbol{x}}=\begin{bmatrix}\frac{\partial y_{1}}{\partial x_{1}} & \frac{\partial y_{2}}{\partial x_{1}} & \cdots & \frac{\partial y_{m}}{\partial x_{1}}\\
\frac{\partial y_{1}}{\partial x_{2}} & \frac{\partial y_{2}}{\partial x_{2}} & \cdots & \frac{\partial y_{m}}{\partial x_{2}}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{\partial y_{1}}{\partial x_{n}} & \frac{\partial y_{2}}{\partial x_{n}} & \cdots & \frac{\partial y_{m}}{\partial x_{n}}
\end{bmatrix}}_{分母布局}
\end{split}\tag{3}
}
$$

## 标量对矩阵
即 $f:\mathbb{R}^{m×n} \rightarrow \mathbb{R}，\boldsymbol{X} \in \mathbb{R}^{m×n}$

$$
\large{
\begin{split}
\underbrace{\frac{\partial y}{\partial\boldsymbol{X}}=
\begin{bmatrix}\frac{\partial y}{\partial x_{11}} & \frac{\partial y}{\partial x_{21}} & \cdots & \frac{\partial y}{\partial x_{q1}}\\
\frac{\partial y}{\partial x_{12}} & \frac{\partial y}{\partial x_{22}} & \cdots & \frac{\partial y}{\partial x_{q2}}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{\partial y}{\partial x_{1p}} & \frac{\partial y}{\partial x_{2p}} & \cdots & \frac{\partial y}{\partial x_{qp}}
\end{bmatrix}}_{分子布局}
&\qquad
\underbrace{\frac{\partial y}{\partial\boldsymbol{X}}=
\begin{bmatrix}\frac{\partial y}{\partial x_{11}} & \frac{\partial y}{\partial x_{12}} & \cdots & \frac{\partial y}{\partial x_{1q}}\\
\frac{\partial y}{\partial x_{21}} & \frac{\partial y}{\partial x_{22}} & \cdots & \frac{\partial y}{\partial x_{2q}}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{\partial y}{\partial x_{p1}} & \frac{\partial y}{\partial x_{p2}} & \cdots & \frac{\partial y}{\partial x_{pq}}
\end{bmatrix}}_{分母布局}
\end{split}\tag{4}
}
$$

## 矩阵对标量
只有分子布局

$$
\large{
\begin{split}
\underbrace{\frac{\partial\boldsymbol{y}}{\partial x}=
\begin{bmatrix}
\frac{\partial y_{11}}{\partial x} & \frac{\partial y_{12}}{\partial x} & \cdots & \frac{\partial y_{1m}}{\partial x}\\
\frac{\partial y_{21}}{\partial x} & \frac{\partial y_{22}}{\partial x} & \cdots & \frac{\partial y_{2m}}{\partial x}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{\partial y_{n1}}{\partial x} & \frac{\partial y_{n2}}{\partial x} & \cdots & \frac{\partial y_{nm}}{\partial x}
\end{bmatrix}}_{分子布局}
\end{split}\tag{5}
}
$$

# 维度分析

接下来我们来看一些常见的求导，首先是 $\frac{\partial\boldsymbol{Ax}}{\partial\boldsymbol{x}}$ ，注意到 $(\boldsymbol{Ax})_{i}=a_{i1}x_{1}+a_{i2}x_{2}+\cdots+a_{in}x_{n}$ ，即
$$
\large{
\begin{split}
\boldsymbol{Ax} = 
\begin{bmatrix}
(\boldsymbol{Ax})_1 \\
(\boldsymbol{Ax})_2 \\
\vdots \\
(\boldsymbol{Ax})_m
\end{bmatrix} &\qquad，再有\;\; 
\boldsymbol{x} = 
\begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{bmatrix}
\end{split}
}
$$

于是利用向量对向量求导法则，我们有：
$$
\large{
\begin{split}
\frac{\partial\mathbf{(\mathbf{Ax}})}{\partial\mathbf{x}}=
\begin{bmatrix}\frac{\partial(\mathbf{Ax})_{1}}{\partial x_{1}} & \frac{\partial(\mathbf{Ax})_{2}}{\partial x_{1}} & \cdots & \frac{\partial(\mathbf{Ax})_{m}}{\partial x_{1}}\\
\frac{\partial(\mathbf{Ax})_{1}}{\partial x_{2}} & \frac{\partial(\mathbf{Ax})_{2}}{\partial x_{2}} & \cdots & \frac{\partial(\mathbf{Ax})_{m}}{\partial x_{2}}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{\partial(\mathbf{Ax})_{1}}{\partial x_{n}} & \frac{\partial(\mathbf{Ax})_{2}}{\partial x_{n}} & \cdots & \frac{\partial(\mathbf{Ax})_{m}}{\partial x_{n}}
\end{bmatrix}
=
\begin{bmatrix}a_{11} & a_{21} & \cdots & a_{m1}\\
a_{12} & a_{22} & \cdots & a_{m2}\\
\vdots & \vdots & \ddots & \vdots\\
a_{1n} & a_{2n} & \cdots & a_{mn}
\end{bmatrix}=\mathbf{A}^{\mathrm{T}}
\end{split}
}
$$

理论上对于任意的表达式，我们都可以通过定义出发，利用上面这种形式推导得到。但是对于一些复杂的求导，这个时候恐怕逐项展开分析就不是很靠谱了。我们先来看求导分类的前三类，对于这三类问题，我们来看一个非常强大的方法，通过分析维度来得到结果。

## 第一种

考虑 $\large{\frac{\partial\boldsymbol{Au}}{\partial\boldsymbol{x}}}$ , A 与 x 无关，所以 A 肯定可以先提出求导式，至于去哪了暂时不清楚。假如 $\large{\boldsymbol{A}\in\mathbb{R}^{m\times n},\boldsymbol{u}\in\mathbb{R}^{n\times1},\boldsymbol{x}\in\mathbb{R}^{p\times1}}$。我们知道最后结果肯定和 $\large{\frac{\partial\boldsymbol{u}}{\partial\boldsymbol{x}}}$ 有关，注意到 $\large{\frac{\partial\boldsymbol{u}}{\partial\boldsymbol{x}}\in\mathbb{R}^{p\times n}}$ ,于是 A 只能转置以后添在后面，因此：
$$
\large{
\begin{split}
\frac{\partial\boldsymbol{Au}}{\partial\boldsymbol{x}}=\frac{\partial\boldsymbol{u}}{\partial\boldsymbol{x}}\mathbf{A}^{\mathrm{T}}
\end{split}\tag{6}
}
$$

同样对于 $\large{\frac{\partial a\boldsymbol{u}}{\partial\boldsymbol{x}},a}$ 和 x 相关的标量，假定 $\large{\boldsymbol{u}\in\mathbb{R}^{m\times1},\boldsymbol{x}\in\mathbb{R}^{n\times1}}$ ,根据乘积法则（非精确版本），前一个部分肯定是 $\large{a\frac{\partial\boldsymbol{u}}{\partial\boldsymbol{x}}}$ , 后一部分为 $\large{\frac{\partial a}{\partial\boldsymbol{x}}\in\mathbb{R}^{n\times1}}$ 和 u 的某种形式的积,分析维度发现只能是 $\large{\frac{\partial a}{\partial\boldsymbol{x}}\boldsymbol{u}^{\mathrm{T}}}$ 。于是：
$$
\large{
\begin{split}
\frac{\partial a\boldsymbol{u}}{\partial\boldsymbol{x}}=a\frac{\partial\boldsymbol{u}}{\partial\boldsymbol{x}}+\frac{\partial a}{\partial\boldsymbol{x}}\boldsymbol{u}^{\mathrm{T}}
\end{split}\tag{7}
}
$$

我们发现，虽然乘积法则的精准形式无法应用于矩阵求导中，然而这种非精确的乘积法则可以准确的告诉我们哪些项一定会出现在结果中，然后通过分析维度，我们就可以写出结果。

## 第二种

再看 $\large{\frac{\partial\boldsymbol{x}^{\mathrm{T}}\boldsymbol{Ax}}{\partial\boldsymbol{x}}}$ ,其中 A 和 x 无关，为了分析这个问题，我们考虑一个更一般的问题：
$$
\large{
\begin{split}
\frac{\partial\boldsymbol{x}^{\mathrm{T}}\boldsymbol{Ay}}{\partial\boldsymbol{x}},\mathbf{x}\in\mathbb{R}^{m\times1},\boldsymbol{y}\in\mathbb{R}^{n\times1}
\end{split}
}
$$

我们利用非精确的乘积法则，可以将这个分成两部分：
$$
\large{
\begin{split}
\frac{\partial\text{(}\boldsymbol{x}^{\mathrm{T}}\boldsymbol{A)y}}{\partial\boldsymbol{x}}
\end{split}
}
$$
于是结果和两部分相关，分别为：
$$
\large{
\begin{split}
\frac{\partial\boldsymbol{y}}{\partial\boldsymbol{x}}\in\mathbb{R}^{m\times n}
,&\quad
\frac{\partial\boldsymbol{x}^{\mathrm{T}}\mathbf{A}}{\partial\boldsymbol{x}}=\boldsymbol{A}\in\mathbb{R}^{m\times n}
\end{split}
}
$$

同样通过分析维度以及式（6）（7），我们可以得到：
$$
\large{
\begin{split}
\frac{\partial\text{(}\boldsymbol{x}^{\mathrm{T}}\boldsymbol{A)y}}{\partial\boldsymbol{x}} 
&= \frac{\partial\text{(}\boldsymbol{x}^{\mathrm{T}}\boldsymbol{A)}}{\partial\boldsymbol{x}} \cdot \boldsymbol{y}  + \frac{\partial\boldsymbol{y}}{\partial\boldsymbol{x}} \cdot (\boldsymbol{x}^{\mathrm{T}}\boldsymbol{A})^{\mathrm{T}} \\
&= \boldsymbol{A \cdot y} + \frac{\partial\boldsymbol{y}}{\partial\boldsymbol{x}}\mathbf{A}^{\mathrm{T}}\boldsymbol{x}
\end{split}\tag{8}
}
$$

因此：
$$
\large{
\begin{split}
\frac{\partial\mathbf{x}^{\mathrm{T}}\mathbf{Ax}}{\partial\mathbf{x}}=(\mathbf{A}^{\mathrm{T}}+\mathbf{A})\mathbf{x}
\end{split}\tag{9}
}
$$

## 第三种

最后看一个式子:
$$
\large{
\begin{split}
\frac{\partial\boldsymbol{a}^{\mathsf{T}}\boldsymbol{xx}^{\mathsf{T}}\boldsymbol{b}}{\partial\boldsymbol{x}},\boldsymbol{a,b,x}\in\mathbb{R}^{m\times1} &\;\; 有 \;\; 
\frac{\partial\boldsymbol{a}^{\mathsf{T}}\boldsymbol{xx}^{\mathsf{T}}\boldsymbol{b}}{\partial\boldsymbol{x}}=\frac{\partial(\boldsymbol{a}^{\mathsf{T}}\boldsymbol{x)(x}^{\mathsf{T}}\boldsymbol{b)}}{\partial\boldsymbol{x}}
\end{split}
}
$$

可知：
$$
\large{
\begin{split}
\frac{\partial(\boldsymbol{a}^{\mathsf{T}}\boldsymbol{x)}}{\partial\boldsymbol{x}}=\boldsymbol{a},&\;
\frac{\partial(\boldsymbol{x}^{\mathsf{T}}\boldsymbol{b)}}{\partial\boldsymbol{x}}=\boldsymbol{b}
\end{split}
}
$$

所以(注意到 $a^Tx\in ℝ，x^Tb\in ℝ$ 因此在求导结果中既可以转置，也可以不转置，如下面第一部分进行了转置，第二部分则没有)
$$
\large{
\begin{split}
\frac{\partial\boldsymbol{a}^{\mathsf{T}}\boldsymbol{xx}^{\mathsf{T}}\boldsymbol{b}}{\partial\boldsymbol{x}}
&=\frac{\partial(\boldsymbol{a}^{\mathsf{T}}\boldsymbol{x)(x}^{\mathsf{T}}\boldsymbol{b)}}{\partial\boldsymbol{x}}\\
&=\boldsymbol{a}(\boldsymbol{x}^{\mathsf{T}}\boldsymbol{b})^\mathsf{T}+\boldsymbol{ba}^{\mathsf{T}}\boldsymbol{x}\\
&=(\boldsymbol{ab}^{\mathrm{T}}+\boldsymbol{ba}^{\mathrm{T}})\boldsymbol{x}
\end{split}\tag{10}
}
$$

# 常用求导公式
【参考】
- [wikipedia - Matrix calculus](https://en.wikipedia.org/wiki/Matrix_calculus)

## 常用
以下布局均使用分母布局，u 和 v均是 x 的函数

$$
\large{
\begin{split}
\frac{\partial(\boldsymbol{u}(x) + \boldsymbol{v}(x))}{\partial \boldsymbol{x}} &= \frac{\partial \boldsymbol{u}(x)}{\partial \boldsymbol{x}} + \frac{\partial \boldsymbol{v}(x)}{\partial \boldsymbol{x}} \\
\frac{\partial \boldsymbol{Ax}}{\partial \boldsymbol{x}} &= \boldsymbol{A}^{\mathsf{T}} \\
\frac{\partial \boldsymbol{a}}{\partial \boldsymbol{x}} &= \boldsymbol{0} \\
\frac{\partial \boldsymbol{x}^T\boldsymbol{Ab}}{\partial \boldsymbol{x}} &= \boldsymbol{Ab} \\
\frac{\partial \boldsymbol{x}^T\boldsymbol{Ax}}{\partial \boldsymbol{x}} &= \boldsymbol{(A+A^T)x} \\
\frac{\partial \boldsymbol{x}^T\boldsymbol{Ax}}{\partial \boldsymbol{x}} &= \boldsymbol{2Ax} \;如果A是对称的
\end{split}
}
$$

## 向量对向量

![image](https://wx4.sinaimg.cn/large/69d4185bly1fx10s168pnj20jp0enwgj.jpg)

## 标量对向量

![image](https://ws1.sinaimg.cn/large/69d4185bly1fx115whvmlj20sw0gutbl.jpg)
![image](https://wx1.sinaimg.cn/large/69d4185bly1fx116kdzqyj20sv0huwhi.jpg)

## 向量对标量

![image](https://wx1.sinaimg.cn/large/69d4185bly1fx2rcs64rjj20m90f9mzr.jpg)

## 标量对矩阵

![image](https://ws2.sinaimg.cn/large/69d4185bly1fx2rjb2batj20sx0i1goy.jpg)

## 矩阵对标量

![image](https://ws2.sinaimg.cn/large/69d4185bly1fx2rkwgd1gj20sx0g241g.jpg)
